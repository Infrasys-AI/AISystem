1
00:00:00,000 --> 00:00:02,000
字幕生成: BLACK 字幕校对: 杨绎

2
00:00:04,175 --> 00:00:07,040
Hello,大家好,我是 ZOMI

3
00:00:07,040 --> 00:00:10,320
今天来到 AI 编译器系列的 PyTorch 里面

4
00:00:11,160 --> 00:00:12,120
接下来的内容

5
00:00:12,240 --> 00:00:14,200
将会围绕着 PyTorch 2.0

6
00:00:14,200 --> 00:00:15,800
最新的一些特性

7
00:00:15,800 --> 00:00:18,480
Torch Dynamo 里面关于编译器的东西

8
00:00:18,800 --> 00:00:20,200
可以看到其实上一节

9
00:00:20,400 --> 00:00:23,720
已经去分享了 PyTorch 2.0 的一些新特性

10
00:00:23,720 --> 00:00:25,440
并且对它进行了一个试用

11
00:00:25,440 --> 00:00:28,880
这一节将会围绕着它的第一个最重要的特性

12
00:00:28,880 --> 00:00:30,480
就是获取计算图

13
00:00:30,480 --> 00:00:31,440
Torch Dynamo

14
00:00:31,440 --> 00:00:34,160
然后首先去进行深入的解读

15
00:00:34,280 --> 00:00:36,600
这里面在讲 Torch Dynamo 的时候

16
00:00:36,600 --> 00:00:38,600
已经到了最后一个内容了

17
00:00:38,600 --> 00:00:39,960
在讲 Dynamo 之前

18
00:00:40,080 --> 00:00:42,920
其实 PyTorch 关于获取计算图

19
00:00:42,920 --> 00:00:44,400
或者说获取静态图

20
00:00:44,560 --> 00:00:46,480
其实是尝试了非常多的方法

21
00:00:46,480 --> 00:00:48,880
包括 GIT,GITscript,GITtrace

22
00:00:48,880 --> 00:00:51,280
TorchFX,PyTorch 的 LazyTensor

23
00:00:51,280 --> 00:00:53,080
不同的方式也尝试过

24
00:00:53,080 --> 00:00:55,560
最后现在比较好的解决方案

25
00:00:55,560 --> 00:00:56,880
就是 Torch Dynamo

26
00:00:57,000 --> 00:00:58,320
接下来看一下

27
00:00:58,320 --> 00:01:01,360
PyTorch 是如何获取计算图的

28
00:01:02,040 --> 00:01:04,600
在讲 PyTorch 如何获取计算图之前

29
00:01:04,720 --> 00:01:06,400
看一下 PyTorch 的一个

30
00:01:06,400 --> 00:01:07,240
ego model

31
00:01:07,240 --> 00:01:08,640
就是 ego 的模式

32
00:01:08,760 --> 00:01:10,000
因为 PyTorch 里面

33
00:01:10,120 --> 00:01:13,120
它一开始是没有一个计算图的概念

34
00:01:13,120 --> 00:01:14,960
里面都是动态去执行的

35
00:01:14,960 --> 00:01:16,080
它是一个动态图

36
00:01:16,080 --> 00:01:18,960
PyTorch 每编译解析一行代码的时候

37
00:01:19,440 --> 00:01:22,680
系统就会下发对应的算子到 GPU

38
00:01:22,680 --> 00:01:24,920
或者 NPU 的硬件里面去执行的

39
00:01:24,920 --> 00:01:26,440
这个就是 ego 的模式

40
00:01:26,480 --> 00:01:28,520
里面只有一个动态图的概念

41
00:01:28,520 --> 00:01:29,880
实际上是没有图的

42
00:01:29,880 --> 00:01:31,240
只是一个虚拟的概念

43
00:01:31,240 --> 00:01:33,760
然后直接把写的这句语句

44
00:01:33,760 --> 00:01:36,040
下发到硬件上面去执行

45
00:01:36,040 --> 00:01:37,680
这个就是 ego model

46
00:01:37,680 --> 00:01:38,880
就是 ego 的模式

47
00:01:39,560 --> 00:01:40,520
后面有些 PPT

48
00:01:40,640 --> 00:01:43,080
其实我是在 PyTorch conference 里面的

49
00:01:43,080 --> 00:01:43,680
一些讲义

50
00:01:43,800 --> 00:01:44,560
现在来看看

51
00:01:44,560 --> 00:01:46,400
为什么需要去关注

52
00:01:46,400 --> 00:01:48,120
PyTorch 的一个图模式

53
00:01:48,240 --> 00:01:50,520
PyTorch 用动态图不是做得挺好的吗

54
00:01:50,720 --> 00:01:52,040
它没有图的概念的时候

55
00:01:52,040 --> 00:01:53,240
大家用的很爽

56
00:01:53,240 --> 00:01:54,720
为什么要关注图模式

57
00:01:55,680 --> 00:01:57,600
下面就给了三个需求

58
00:01:57,600 --> 00:01:59,200
第一个就是芯片的设计师

59
00:01:59,200 --> 00:02:01,160
第二个就是产品化的工程师

60
00:02:01,160 --> 00:02:03,440
第三个就是编译器的工程师

61
00:02:03,440 --> 00:02:05,080
我觉得这句话是很有意思的

62
00:02:05,280 --> 00:02:06,800
没有图你就没有编译

63
00:02:06,800 --> 00:02:08,880
确实以前是没有编译的

64
00:02:08,880 --> 00:02:11,920
随着最近这两三年 AI 大规模的落地

65
00:02:11,920 --> 00:02:15,440
所以不得不去考虑静态图的一个问题

66
00:02:15,440 --> 00:02:16,960
就是你要得到静态图

67
00:02:16,960 --> 00:02:20,080
你肯定要从 PyTorch 原生的代码里面

68
00:02:20,080 --> 00:02:21,600
去获取一张图

69
00:02:22,120 --> 00:02:24,280
获取计算图主要有两种方式

70
00:02:24,280 --> 00:02:25,880
一种是基于追踪 trace 的

71
00:02:25,880 --> 00:02:27,840
一种是基于源码解析的

72
00:02:27,840 --> 00:02:29,760
在计算图系列的时候

73
00:02:29,760 --> 00:02:31,720
其实已经详细的去展开了

74
00:02:31,720 --> 00:02:33,960
这里面简单的带过一下

75
00:02:34,160 --> 00:02:36,400
基于追踪就是直接执行用户的代码

76
00:02:36,400 --> 00:02:39,400
然后把算子的调用的序列记录下来

77
00:02:39,840 --> 00:02:41,120
第二种基于源码解析

78
00:02:41,280 --> 00:02:43,640
就是用 PyTorch 的 python 的代码

79
00:02:43,640 --> 00:02:46,040
然后通过建立抽象语法树

80
00:02:46,360 --> 00:02:48,960
转换成为计算图两种方式

81
00:02:49,120 --> 00:02:50,200
基于 trace 的方式

82
00:02:50,360 --> 00:02:51,600
PyTorch 的一个常识

83
00:02:51,600 --> 00:02:53,240
就是 PyTorch 的 FX

84
00:02:53,360 --> 00:02:54,960
而基于源码解析的话

85
00:02:54,960 --> 00:02:56,640
PyTorch 最大的一个常识

86
00:02:57,040 --> 00:02:59,480
就是 PyTorch 的 JIT 两种

87
00:02:59,840 --> 00:03:01,640
基于追踪其实很简单

88
00:03:01,640 --> 00:03:03,560
里面 PyTorch 的就是通过 FX

89
00:03:03,560 --> 00:03:04,840
SymbioticTrace

90
00:03:05,160 --> 00:03:06,040
通过这个方式

91
00:03:06,040 --> 00:03:08,160
然后去解析刚才写的一些

92
00:03:08,400 --> 00:03:09,680
网络模型的代码

93
00:03:10,120 --> 00:03:12,040
它的优点就是可以支持 Python 的

94
00:03:12,040 --> 00:03:12,800
动态控制流

95
00:03:12,800 --> 00:03:14,680
但是缺点场景很受限

96
00:03:14,680 --> 00:03:16,320
只能支持某几种模式

97
00:03:16,320 --> 00:03:18,600
因为它是基于一个源码的 trace

98
00:03:18,920 --> 00:03:21,520
你既然是 trace 或者便利源码

99
00:03:21,720 --> 00:03:23,040
你肯定有一些 if else

100
00:03:23,040 --> 00:03:23,800
或者有一些 while

101
00:03:23,800 --> 00:03:24,800
或者有一些情况

102
00:03:24,800 --> 00:03:27,440
你是没办法去完完全全的便利的

103
00:03:27,440 --> 00:03:28,960
这个时候可能会失去

104
00:03:28,960 --> 00:03:30,960
源程序的一些控制的结构

105
00:03:30,960 --> 00:03:33,120
或者只是做一些有限的追踪

106
00:03:34,000 --> 00:03:35,000
基于源代码的解析

107
00:03:35,000 --> 00:03:36,960
就是类似于 torch JIT

108
00:03:37,120 --> 00:03:39,240
这个就是 JIT 的一种使用方式

109
00:03:39,240 --> 00:03:42,240
把上面的代码通过一个装饰器去声明

110
00:03:42,240 --> 00:03:43,560
后面通过装饰器

111
00:03:43,720 --> 00:03:45,840
就把这段代码进行一个源码转换

112
00:03:46,680 --> 00:03:47,640
基于源码转换

113
00:03:47,920 --> 00:03:49,240
它的优点就是可以支持

114
00:03:49,240 --> 00:03:50,920
更多的一个动态的情况

115
00:03:50,920 --> 00:03:52,800
但是缺点也是很明显的

116
00:03:53,640 --> 00:03:54,840
有一些 python 的源代码

117
00:03:55,000 --> 00:03:56,320
不能够完完全全的

118
00:03:56,320 --> 00:03:58,440
变成静态图的表示

119
00:03:58,440 --> 00:04:00,560
因为使用 python 所表达的东西

120
00:04:00,560 --> 00:04:02,200
实在是太灵活了

121
00:04:02,200 --> 00:04:03,760
基于这一点又引出了

122
00:04:03,760 --> 00:04:05,320
第三点的一个问题

123
00:04:05,320 --> 00:04:08,160
就是可能会回退到 host 跟 devices

124
00:04:08,160 --> 00:04:09,400
不断去调用慢码

125
00:04:09,400 --> 00:04:11,280
因为我有些语句是不支持的

126
00:04:11,280 --> 00:04:13,680
所以我只能使用 python 语言去执行

127
00:04:13,680 --> 00:04:15,560
所以说 Pytorch 2.0 之前

128
00:04:15,840 --> 00:04:17,320
在 Dynamo 出现之前

129
00:04:17,440 --> 00:04:19,160
它做了非常大量的尝试

130
00:04:19,520 --> 00:04:21,240
下面分为四个点去介绍

131
00:04:21,240 --> 00:04:22,720
第一个就是 TorchFX

132
00:04:22,720 --> 00:04:24,160
第二个就是 TorchSquid

133
00:04:24,160 --> 00:04:25,840
第三个就是 LazyTensor

134
00:04:25,840 --> 00:04:27,840
最后才是 TorchDynamo

135
00:04:28,280 --> 00:04:30,800
第四个才会去看看 Dynamo

136
00:04:31,000 --> 00:04:32,040
在讲 Dynamo 之前

137
00:04:32,160 --> 00:04:33,920
会去横向的比较

138
00:04:33,920 --> 00:04:36,240
这四种的静态图的获取的方式

139
00:04:36,240 --> 00:04:37,360
有什么不一样

140
00:04:38,200 --> 00:04:40,600
Pytorch 对于静态图的获取这个特性

141
00:04:40,800 --> 00:04:42,880
在 Pytorch 1.3 这个版本里面

142
00:04:42,880 --> 00:04:45,160
已经有了一个最初的尝试了

143
00:04:45,480 --> 00:04:46,760
这里面有两种方式

144
00:04:46,760 --> 00:04:48,720
主要是通过装饰符去实现的

145
00:04:49,040 --> 00:04:51,520
第一种就是 Torch.git.squid

146
00:04:51,520 --> 00:04:54,320
第二种就是 Torch.git.trace

147
00:04:54,320 --> 00:04:55,600
两种不同的方式

148
00:04:55,840 --> 00:04:57,520
Squid 就是源码转换

149
00:04:57,520 --> 00:04:59,040
Trace 就是局域跟踪

150
00:04:59,040 --> 00:05:01,040
两种其实 Pytorch 都实现了

151
00:05:01,640 --> 00:05:04,080
但是这种实现并不是说最好的

152
00:05:04,080 --> 00:05:05,760
或者它有很多的问题

153
00:05:05,760 --> 00:05:07,520
将会在后面去展开

154
00:05:07,760 --> 00:05:10,200
下面来看看它第二个重要的特点

155
00:05:10,640 --> 00:05:12,520
TorchSquid 从 Pytorch 的代码

156
00:05:12,520 --> 00:05:14,600
创建一个可序列化的模型

157
00:05:14,880 --> 00:05:16,280
既然你可序列化了

158
00:05:16,480 --> 00:05:19,000
所以 TorchSquid 主要是用在推理场景

159
00:05:19,000 --> 00:05:21,520
加载到没有 python 依赖的进程里面

160
00:05:21,520 --> 00:05:23,280
去做一个推理的加速

161
00:05:23,280 --> 00:05:25,200
简单一句话的去概括

162
00:05:25,600 --> 00:05:27,120
TorchSquid 的最大的作用

163
00:05:27,120 --> 00:05:29,720
就是把使用 Pytorch 写的代码

164
00:05:29,720 --> 00:05:31,480
变成一个计算图

165
00:05:31,480 --> 00:05:33,720
丢给 AI 编译器编译完之后

166
00:05:33,720 --> 00:05:35,000
再去执行

167
00:05:35,440 --> 00:05:37,000
现在来看一下

168
00:05:37,000 --> 00:05:39,880
Pytorch Inference 里面相关的一些讲义

169
00:05:40,080 --> 00:05:41,760
它有两种方式

170
00:05:41,760 --> 00:05:42,960
Torch.git.trace

171
00:05:42,960 --> 00:05:44,320
Torch.git.squid

172
00:05:44,520 --> 00:05:45,880
把 ego mode

173
00:05:45,880 --> 00:05:47,240
变成 Squid mode

174
00:05:47,240 --> 00:05:48,800
然后在产品里面

175
00:05:48,800 --> 00:05:50,480
真正的部署起来

176
00:05:51,080 --> 00:05:53,880
两种方式都是直接调用一个 API 的

177
00:05:53,880 --> 00:05:55,800
但是 Torch.git.trace

178
00:05:56,000 --> 00:05:58,080
就是空字流没办法表达

179
00:05:58,080 --> 00:05:59,520
而 Torch.git.squid

180
00:05:59,640 --> 00:06:01,640
同样把网络模型丢进来就行了

181
00:06:01,640 --> 00:06:02,560
调用一个 API

182
00:06:02,560 --> 00:06:05,440
这里面空字流就可以保存下来

183
00:06:05,440 --> 00:06:08,160
个人其实更倾向用 Squid 这种方式

184
00:06:08,160 --> 00:06:09,600
因为用 trace 的方式

185
00:06:09,880 --> 00:06:10,920
你还是要注意一点

186
00:06:10,920 --> 00:06:12,880
使用方式的或者使用技巧

187
00:06:13,040 --> 00:06:14,280
下面这些代码

188
00:06:14,480 --> 00:06:16,160
就是 Torch.git.squid 的 IR

189
00:06:16,160 --> 00:06:17,440
它的 IR 的定义

190
00:06:17,440 --> 00:06:20,080
这是其中一个图生成的 IR

191
00:06:20,520 --> 00:06:22,440
里面主要支持三个特性

192
00:06:22,440 --> 00:06:23,920
第一个就是静态的类型

193
00:06:23,920 --> 00:06:26,080
第二个就是结构化的空字流

194
00:06:26,080 --> 00:06:28,720
第三个就是默认使用函数式的表达

195
00:06:28,840 --> 00:06:29,840
接着 Torch.git.squid

196
00:06:29,960 --> 00:06:32,000
就会做一些相关的优化

197
00:06:32,200 --> 00:06:33,240
第一个我能看得懂的

198
00:06:33,480 --> 00:06:34,800
肯定是 Fusion

199
00:06:34,800 --> 00:06:36,080
就是算子的融合

200
00:06:36,080 --> 00:06:37,760
其他我是没有去细看

201
00:06:37,760 --> 00:06:39,800
它到底是怎么一个编译过程的

202
00:06:39,800 --> 00:06:41,720
我后面再慢慢的打开

203
00:06:42,120 --> 00:06:43,200
有了 Torch.squid

204
00:06:43,200 --> 00:06:44,600
去把 PyTorch 的动态图

205
00:06:44,600 --> 00:06:45,600
变成静态图之后

206
00:06:45,800 --> 00:06:47,560
就可以交给 Torch.git

207
00:06:47,560 --> 00:06:48,480
去做一个 forward

208
00:06:48,480 --> 00:06:50,160
就是真正的优化编译

209
00:06:50,360 --> 00:06:51,960
优化编译则分为三个流程

210
00:06:51,960 --> 00:06:54,320
第一个流程就是信息状态的收集

211
00:06:54,320 --> 00:06:55,160
收集完状态之后

212
00:06:55,320 --> 00:06:56,680
就开始给编译器

213
00:06:56,680 --> 00:06:57,920
做一个编译的优化

214
00:06:58,080 --> 00:06:59,480
刚才可以看到编译优化

215
00:06:59,480 --> 00:07:01,560
第一个就是融合 Fusion

216
00:07:01,560 --> 00:07:02,600
编译优化完之后

217
00:07:02,760 --> 00:07:03,960
就给 interpreter

218
00:07:03,960 --> 00:07:05,400
就是解析器

219
00:07:05,400 --> 00:07:07,080
做一些解析执行

220
00:07:08,280 --> 00:07:10,080
简单的了解完 Torch.squid 之后

221
00:07:10,360 --> 00:07:12,000
Torch.squid 不会讲得太深

222
00:07:12,000 --> 00:07:13,040
其实里面最重要的

223
00:07:13,040 --> 00:07:14,960
就是 Torch.squid 的一个 IR 的表

224
00:07:14,960 --> 00:07:16,560
是你怎么去定义这个 IR

225
00:07:16,560 --> 00:07:17,960
把 PyTorch 的动态图

226
00:07:17,960 --> 00:07:19,280
转成静态图

227
00:07:19,440 --> 00:07:20,200
现在来看看

228
00:07:20,200 --> 00:07:22,040
Torch.squid 的一些 points and cons

229
00:07:22,040 --> 00:07:23,560
就是它的优缺点

230
00:07:23,760 --> 00:07:25,120
它的优点就是很明确

231
00:07:25,120 --> 00:07:26,200
可以第一次尝试

232
00:07:26,200 --> 00:07:29,360
把动态图转成静态图

233
00:07:29,360 --> 00:07:31,920
然后对静态图使用 Torch.git

234
00:07:31,920 --> 00:07:33,720
做一个编译优化执行的

235
00:07:33,920 --> 00:07:35,440
这是第一个尝试

236
00:07:35,440 --> 00:07:37,720
所以它会引入很多问题

237
00:07:37,920 --> 00:07:38,520
问题有什么

238
00:07:38,720 --> 00:07:39,680
问题看一下

239
00:07:39,720 --> 00:07:40,960
问题就是静态图

240
00:07:41,120 --> 00:07:43,240
它只能够表达正向图

241
00:07:43,240 --> 00:07:45,040
神经网络还有求导

242
00:07:45,040 --> 00:07:47,800
还有反向传播的功能

243
00:07:47,920 --> 00:07:49,520
所以它只能表示正向

244
00:07:49,520 --> 00:07:50,640
不能表示反向

245
00:07:50,640 --> 00:07:52,240
也不能表示动态 shift

246
00:07:52,240 --> 00:07:54,040
使用的场景是非常有限的

247
00:07:54,040 --> 00:07:55,120
第二个就是刚才

248
00:07:55,120 --> 00:07:56,240
为什么没有讲那个 IR

249
00:07:56,600 --> 00:07:58,080
因为 Torch.squid 的 IR

250
00:07:58,080 --> 00:07:59,680
是非常复杂难学

251
00:07:59,680 --> 00:08:02,080
想要修改或者增加相关硬的 parts

252
00:08:02,200 --> 00:08:03,240
对开发者来说

253
00:08:03,240 --> 00:08:04,560
成本是很高的

254
00:08:04,560 --> 00:08:06,120
就是不容易学

255
00:08:06,800 --> 00:08:08,200
因此也没有讲

256
00:08:08,200 --> 00:08:09,160
因为 Torch.squid

257
00:08:09,160 --> 00:08:11,280
它不是拍 Torch 最好的一种

258
00:08:11,440 --> 00:08:13,600
动态图转为静态图的方案

259
00:08:13,600 --> 00:08:15,040
只是简单的带过

260
00:08:15,040 --> 00:08:17,480
Dynamo 才是最终的目标

261
00:08:19,480 --> 00:08:19,920
好了

262
00:08:19,920 --> 00:08:20,680
谢谢各位

263
00:08:21,120 --> 00:08:21,920
卷的不行了

264
00:08:21,920 --> 00:08:22,760
卷的不行了

265
00:08:22,760 --> 00:08:24,200
记得一键三连加关注

266
00:08:24,600 --> 00:08:25,960
所有的内容都会开源

267
00:08:25,960 --> 00:08:27,800
在下面这条链接里面

268
00:08:28,160 --> 00:08:29,120
摆了个摆

