1
00:00:00,000 --> 00:00:04,200
字幕生成：qiaokai 字幕校对：mkwei

2
00:00:05,333 --> 00:00:08,100
哈喽大家好我是 ZOMI

3
00:00:08,166 --> 00:00:10,133
欢迎来到今天的课程

4
00:00:10,133 --> 00:00:11,133
那今天的课程呢

5
00:00:11,133 --> 00:00:12,666
主要是给大家汇报一下

6
00:00:12,666 --> 00:00:13,966
AI 编译器里面的

7
00:00:13,966 --> 00:00:15,133
前端优化里面的

8
00:00:15,133 --> 00:00:17,400
第一节图层的 IR

9
00:00:17,566 --> 00:00:18,733
了解到图层 IR

10
00:00:18,733 --> 00:00:20,566
今天呢就来复习一下

11
00:00:20,566 --> 00:00:22,566
之前讲到过的内容

12
00:00:22,566 --> 00:00:24,166
就是计算图

13
00:00:24,200 --> 00:00:25,666
那在计算图这里面呢

14
00:00:25,666 --> 00:00:27,766
看看今天会讲哪几个内容

15
00:00:27,766 --> 00:00:28,300
今天呢

16
00:00:28,300 --> 00:00:30,600
主要是讲计算图的基本构成

17
00:00:30,800 --> 00:00:31,933
在 AI 框架基础呢

18
00:00:31,933 --> 00:00:34,133
其实已经详细地去介绍过

19
00:00:34,133 --> 00:00:36,366
计算图的相关的知识

20
00:00:36,566 --> 00:00:37,533
那这里面呢

21
00:00:37,533 --> 00:00:40,133
会有一个专门的内容去讲计算图的

22
00:00:40,133 --> 00:00:42,200
我说哎在这了找到计算图

23
00:00:42,200 --> 00:00:44,900
会讲讲计算图的整体的介绍

24
00:00:44,900 --> 00:00:47,333
然后跟自动微分什么关系

25
00:00:47,333 --> 00:00:49,400
图的调度还要怎么表示控制流

26
00:00:49,466 --> 00:00:51,766
在这里面呢重新的回顾一下

27
00:00:51,800 --> 00:00:52,266
接着呢

28
00:00:52,266 --> 00:00:55,333
去看看静态的计算图和动态的计算图

29
00:00:55,466 --> 00:00:57,000
那现在大部分 AI 框架呀

30
00:00:57,000 --> 00:00:58,666
都是从动态的计算图

31
00:00:58,666 --> 00:01:00,166
转到静态的计算图

32
00:01:00,166 --> 00:01:01,300
那像 MindSpore 这种呢

33
00:01:01,300 --> 00:01:03,766
就是一开始是先支持静态的计算图

34
00:01:03,800 --> 00:01:07,400
最后呢支持动静统一的动静态计算图

35
00:01:07,400 --> 00:01:08,333
这种方式

36
00:01:08,333 --> 00:01:08,933
那接着呢

37
00:01:08,933 --> 00:01:11,600
来看看 AI 框架是怎么产生

38
00:01:11,900 --> 00:01:12,733
这个计算图的

39
00:01:12,733 --> 00:01:14,466
就讲了很多计算图

40
00:01:14,466 --> 00:01:15,700
它到底是怎么来的

41
00:01:15,800 --> 00:01:16,466
最后呢

42
00:01:16,466 --> 00:01:19,100
去讲讲有了这个计算图之后呢

43
00:01:19,166 --> 00:01:22,000
对 AI 编译器到底有什么作用

44
00:01:22,533 --> 00:01:25,000
好了现在接着往下走

45
00:01:27,100 --> 00:01:27,500
第一个呢

46
00:01:27,500 --> 00:01:30,166
先看看计算图的基本构成

47
00:01:30,200 --> 00:01:31,600
其实计算图比较简单

48
00:01:31,600 --> 00:01:33,800
现在来看看它的一个主要的作用

49
00:01:33,800 --> 00:01:35,300
主要是用来表示

50
00:01:35,333 --> 00:01:37,300
深度学习的一个推理训练的

51
00:01:37,300 --> 00:01:38,500
过程当中的

52
00:01:38,500 --> 00:01:39,366
计算逻辑

53
00:01:39,700 --> 00:01:42,766
主要是表达整个网络模型的

54
00:01:42,766 --> 00:01:44,300
那可以看到计算图呢

55
00:01:44,300 --> 00:01:46,866
主要是由基本的数据结构张量

56
00:01:46,866 --> 00:01:49,500
还有算子去组成的

57
00:01:49,533 --> 00:01:52,166
在计算图他即然是一个图嘛

58
00:01:52,166 --> 00:01:54,133
那他肯定会有节点和边

59
00:01:54,133 --> 00:01:57,066
那这个节点呢就是算子

60
00:01:57,166 --> 00:01:58,733
节点跟节点之间

61
00:01:58,733 --> 00:02:00,466
就是算子跟算子之间呢

62
00:02:00,466 --> 00:02:01,300
会有一个连接

63
00:02:01,300 --> 00:02:02,133
有一条边

64
00:02:02,133 --> 00:02:03,766
那这个边流动的数据呢

65
00:02:03,766 --> 00:02:05,000
就是张量

66
00:02:05,566 --> 00:02:06,666
所以会说

67
00:02:06,666 --> 00:02:09,066
计算图的一个最基本的构成呢

68
00:02:09,066 --> 00:02:10,366
就是由 Tensor

69
00:02:10,366 --> 00:02:12,600
还有基本的运算单元

70
00:02:12,766 --> 00:02:14,466
算子来去组成的

71
00:02:14,533 --> 00:02:16,866
算子这个概念呢也是来自于这

72
00:02:16,866 --> 00:02:19,500
而 AI 框架呢是产生计算图的

73
00:02:19,500 --> 00:02:22,100
所以所以经常谈到的算子啊

74
00:02:22,100 --> 00:02:24,666
还是 AI 框架的一个概念

75
00:02:24,933 --> 00:02:26,400
真正在硬件底层

76
00:02:26,400 --> 00:02:28,566
或者是用 CUDA 写一些

77
00:02:28,700 --> 00:02:30,266
算子表达的时候呢

78
00:02:30,266 --> 00:02:32,300
叫做 CUDA 的 Kernel

79
00:02:33,200 --> 00:02:35,766
刚才那个概念呢大家可以忘记它

80
00:02:35,766 --> 00:02:37,566
你理解为都算算子就行了

81
00:02:37,566 --> 00:02:38,700
你都叫算子吧

82
00:02:38,800 --> 00:02:40,200
反正也无所谓了

83
00:02:40,200 --> 00:02:43,533
然后后面呢即然是一个图嘛

84
00:02:43,533 --> 00:02:45,666
那这个图肯定会有一个自己的概念

85
00:02:45,666 --> 00:02:49,000
这里面呢主要是基于一个 DAG 的图

86
00:02:49,866 --> 00:02:51,733
那 DAG 呢就是有向无环图

87
00:02:51,733 --> 00:02:52,500
可以看到啊

88
00:02:52,500 --> 00:02:54,733
下面这个就是有向无环图的演示

89
00:02:54,733 --> 00:02:56,866
从上面 input 输入数据

90
00:02:56,866 --> 00:02:58,400
然后经过算子

91
00:02:58,600 --> 00:03:00,266
经过边下一个算子

92
00:03:00,266 --> 00:03:01,933
经过边下一个算子

93
00:03:01,966 --> 00:03:03,000
而这条边呢

94
00:03:03,000 --> 00:03:05,400
流传的数据呢就是 Tensor

95
00:03:05,500 --> 00:03:06,300
最后输出

96
00:03:06,300 --> 00:03:09,333
而经常会遇到反向传播的时候

97
00:03:09,333 --> 00:03:10,900
也是一个有向无环图

98
00:03:10,900 --> 00:03:14,200
可以看到这里面是一个有向的顺序

99
00:03:14,200 --> 00:03:16,366
它是每一次都有自己的顺序的

100
00:03:16,533 --> 00:03:18,600
但是呢它没有形成一个环

101
00:03:18,666 --> 00:03:21,266
最后他会进行一个输出

102
00:03:21,500 --> 00:03:24,133
而在这里面呢有两点需要注意的

103
00:03:24,133 --> 00:03:26,866
就是会遇到特殊的操作和

104
00:03:26,866 --> 00:03:27,900
特殊的边

105
00:03:27,900 --> 00:03:29,333
而这个所谓的特殊呢

106
00:03:29,333 --> 00:03:31,866
主要是指控制流

107
00:03:31,966 --> 00:03:32,766
控制流呢

108
00:03:32,766 --> 00:03:35,866
是在计算图里面比较难表示的

109
00:03:36,100 --> 00:03:37,866
下面呢来看看 AI 框架呢

110
00:03:37,866 --> 00:03:40,133
是怎么样去生成计算图的

111
00:03:40,133 --> 00:03:42,133
计算图跟自动微分有什么关系啊

112
00:03:42,133 --> 00:03:43,933
知道刚才讲的计算图呢

113
00:03:43,933 --> 00:03:45,566
是一个有向的无环图

114
00:03:45,566 --> 00:03:47,266
那在平时写代码的时候呢

115
00:03:47,266 --> 00:03:49,933
一般只写了一个正向的图

116
00:03:49,933 --> 00:03:52,933
或者做了一个神经网络对正向的表达

117
00:03:53,133 --> 00:03:53,600
实际上呢

118
00:03:53,600 --> 00:03:55,133
AI 框架会帮去

119
00:03:55,133 --> 00:03:57,300
自动建好反向图

120
00:03:57,333 --> 00:03:59,500
然后整体呢变成一个计算图

121
00:03:59,500 --> 00:04:01,200
下发给 AI 编译器的

122
00:04:01,466 --> 00:04:04,966
AI 框架生成一个计算图有第一种方式

123
00:04:04,966 --> 00:04:06,533
就是静态的计算图

124
00:04:06,566 --> 00:04:08,766
静态计算图呢这个比较好表示啊

125
00:04:08,766 --> 00:04:10,666
因为现在有一个嗯

126
00:04:10,666 --> 00:04:12,600
用 MindSpore 写的一些伪代码

127
00:04:12,600 --> 00:04:14,400
用 MindSpore 写完这个伪代码呢

128
00:04:14,400 --> 00:04:16,533
之后呢会把这些代码呢

129
00:04:16,533 --> 00:04:18,900
通过 AI 框架的前端定义

130
00:04:19,100 --> 00:04:20,466
就是调用这些接口

131
00:04:20,466 --> 00:04:21,466
nn.SequentialCell

132
00:04:21,466 --> 00:04:23,566
nn.ReLU、nn.Dense

133
00:04:23,566 --> 00:04:25,200
然后基于 Python 的代码呢

134
00:04:25,200 --> 00:04:26,566
做一个源码的转换

135
00:04:26,566 --> 00:04:29,200
对这些原码呢进行一个分析和重构

136
00:04:29,200 --> 00:04:31,500
变成静态的计算图

137
00:04:31,500 --> 00:04:32,933
那这个静态的计算图呢

138
00:04:32,933 --> 00:04:36,000
实际上它只是一个特殊的数据结构

139
00:04:36,000 --> 00:04:39,133
所以说 AI 框架呢生成静态图

140
00:04:39,133 --> 00:04:40,133
主要是

141
00:04:40,133 --> 00:04:43,100
用 AI 框架所提供的前端的 API

142
00:04:43,100 --> 00:04:43,933
对这些 API

143
00:04:43,933 --> 00:04:45,300
进行分析重构

144
00:04:45,300 --> 00:04:48,266
然后变成特殊的静态图的数据结构

145
00:04:48,533 --> 00:04:49,133
那下面呢

146
00:04:49,133 --> 00:04:50,000
第二种方式

147
00:04:50,000 --> 00:04:52,733
就是 AI 框架生成动态计算图

148
00:04:52,733 --> 00:04:54,166
这是第二种方式

149
00:04:54,166 --> 00:04:55,133
动态图呢

150
00:04:55,133 --> 00:04:57,900
主要是利用 Python 自身的一个解析器

151
00:04:57,900 --> 00:04:59,100
对代码进行解析

152
00:04:59,100 --> 00:05:00,766
然后利用框架本身的一个

153
00:05:00,766 --> 00:05:01,933
算子分发能力

154
00:05:01,966 --> 00:05:03,266
然后去执行

155
00:05:03,266 --> 00:05:04,266
那很简单

156
00:05:04,500 --> 00:05:07,000
PyTorch 是最典型的就是动态的计算图

157
00:05:07,000 --> 00:05:08,666
利用 Python 去写完代码

158
00:05:08,700 --> 00:05:11,400
通过 autograd 这个函数呢建立了反向图

159
00:05:11,400 --> 00:05:13,933
反向图之后呢就变成整一个计算图了

160
00:05:13,933 --> 00:05:15,533
或者变成一个算子序列

161
00:05:15,533 --> 00:05:17,766
然后不断的去分发到硬件

162
00:05:17,766 --> 00:05:19,800
去执行并且返回结果

163
00:05:20,000 --> 00:05:21,366
这种呢就是动态图

164
00:05:21,366 --> 00:05:23,500
它使用的是命令式编程的范式

165
00:05:23,500 --> 00:05:25,100
那这个命令式编程的范式

166
00:05:25,100 --> 00:05:25,933
是什么意思呢

167
00:05:26,166 --> 00:05:26,866
这个内容呢

168
00:05:26,866 --> 00:05:29,133
也在 AI 框架基础里面

169
00:05:29,133 --> 00:05:30,366
详细的展开过的

170
00:05:30,366 --> 00:05:31,966
有兴趣的也可以去了解

171
00:05:32,400 --> 00:05:34,866
PyTorch 呢用了命令式编程的方式呢

172
00:05:34,866 --> 00:05:37,566
使用前端的语言去构造网络的

173
00:05:37,700 --> 00:05:40,366
优点很明显灵活易用嘛

174
00:05:40,400 --> 00:05:42,200
然后也可以充分的发挥

175
00:05:42,266 --> 00:05:45,133
Python 语言的原生的控制流

176
00:05:45,200 --> 00:05:47,400
那缺点呢就是没有编译器

177
00:05:47,400 --> 00:05:48,333
这里面没有编译器

178
00:05:48,333 --> 00:05:51,500
所以没有办法的去提升这些性能

179
00:05:51,566 --> 00:05:52,166
现在呢

180
00:05:52,166 --> 00:05:55,166
来看看动态图和静态图的一个

181
00:05:55,166 --> 00:05:55,966
对比

182
00:05:56,066 --> 00:05:58,700
那下面这个图呢就是一个具体的对比

183
00:05:58,700 --> 00:06:00,366
可以一般来说呢

184
00:06:00,366 --> 00:06:01,466
在推理场景

185
00:06:01,466 --> 00:06:03,533
基本上都会把它变成一个计算图

186
00:06:03,533 --> 00:06:06,200
就可以看到的模型权重文件

187
00:06:06,200 --> 00:06:09,200
那这个权重文件呢不仅仅只有权重

188
00:06:09,366 --> 00:06:11,600
他大部分呢都会带有图的信息

189
00:06:11,600 --> 00:06:14,500
而动态图呢一般是用在训练场景的

190
00:06:14,500 --> 00:06:15,533
我训练完之后我这

191
00:06:15,533 --> 00:06:17,533
个图就就没了消亡掉了

192
00:06:17,533 --> 00:06:19,400
在内存里面也没有办法去保存了

193
00:06:19,400 --> 00:06:21,700
而且静态图呢可以做一些编译优化

194
00:06:21,700 --> 00:06:23,900
这也是拍 PyTorch2.0 推出的一个

195
00:06:23,900 --> 00:06:24,866
很重要的特性

196
00:06:25,000 --> 00:06:28,000
可以把 PyTorch 的动态图变成一个静态图

197
00:06:28,066 --> 00:06:30,733
Dynamo 的特性呢其实是做的非常好的

198
00:06:30,866 --> 00:06:33,300
ZOMI 呢在 AI 编译器之 PyTorch 里面呢

199
00:06:33,300 --> 00:06:36,366
就详细的去展开过这个特性

200
00:06:36,400 --> 00:06:38,866
后面呢还会补充更多的内容

201
00:06:38,866 --> 00:06:39,533
那这里面呢

202
00:06:39,533 --> 00:06:42,533
先跳到主流的业务

203
00:06:42,533 --> 00:06:44,800
还是讲讲 AI 编译器

204
00:06:49,100 --> 00:06:50,400
下面呢看一下

205
00:06:50,400 --> 00:06:52,733
之前其实已经多次的去强调过

206
00:06:52,733 --> 00:06:54,466
动态图转为静态图

207
00:06:54,466 --> 00:06:55,966
主要是有两种方式

208
00:06:55,966 --> 00:06:57,766
第一种是基于 trace 的

209
00:06:57,766 --> 00:06:59,366
就是基于追踪的方式呢

210
00:06:59,366 --> 00:07:01,333
第二种就是基于源码转换的

211
00:07:01,333 --> 00:07:02,400
那最终的方式呢

212
00:07:02,400 --> 00:07:05,100
有那个 PyTorch 的 FX

213
00:07:05,100 --> 00:07:06,300
源码转换有 PyTroch 的 JIT

214
00:07:06,700 --> 00:07:07,533
在前端呢

215
00:07:07,533 --> 00:07:08,933
获得计算图呢

216
00:07:08,933 --> 00:07:10,000
最主要的工作呢

217
00:07:10,000 --> 00:07:12,466
就是方便底层进行编译优化

218
00:07:12,666 --> 00:07:13,933
而这个图的概念呢

219
00:07:13,933 --> 00:07:15,266
可以用它来

220
00:07:15,333 --> 00:07:19,100
保存或者表示整个神经网络的全过程

221
00:07:19,100 --> 00:07:20,400
也可以序列化过来

222
00:07:20,400 --> 00:07:22,566
不需要再次编译前段代码

223
00:07:22,566 --> 00:07:25,933
就是可以进行推理或者训练的加速

224
00:07:26,900 --> 00:07:28,966
那现在来谈谈静态图啊

225
00:07:28,966 --> 00:07:30,300
产生这个静态图

226
00:07:30,300 --> 00:07:32,966
对实际 AI 的编译器的作用

227
00:07:33,000 --> 00:07:35,933
首先呢第一个就是图的优化

228
00:07:35,933 --> 00:07:38,466
其实可以做很多图层的优化

229
00:07:38,466 --> 00:07:40,533
拿到这个图之后

230
00:07:40,533 --> 00:07:44,300
ZOMI 老师为啥我可以做到图的优化呢

231
00:07:44,333 --> 00:07:45,766
我不就得到一个图吗

232
00:07:45,766 --> 00:07:46,766
我能干啥呢

233
00:07:46,766 --> 00:07:48,800
我这个图去执行就好了呀

234
00:07:48,900 --> 00:07:50,766
你优化个干嘛你

235
00:07:51,766 --> 00:07:54,800
哎这位同学问的非常好啊

236
00:07:54,800 --> 00:07:58,100
虽然这个问题问的有点嗯一言难尽啊

237
00:07:58,100 --> 00:07:59,066
那可以看到啊

238
00:07:59,066 --> 00:08:00,133
其实现在呢

239
00:08:00,133 --> 00:08:02,300
拿到了整个神经网络模型的

240
00:08:02,300 --> 00:08:03,400
全局的信息

241
00:08:03,400 --> 00:08:04,333
拿到这个信息呢

242
00:08:04,333 --> 00:08:06,466
就知道未来要执行什么

243
00:08:06,466 --> 00:08:08,066
之前我执行过什么

244
00:08:08,166 --> 00:08:09,400
既然我知道全局信息

245
00:08:09,400 --> 00:08:12,600
我肯定可以做一些对系统级的优化嘛

246
00:08:12,966 --> 00:08:13,966
所以呢这里面呢

247
00:08:13,966 --> 00:08:16,766
就像之前提到的 LLVM 那样

248
00:08:16,766 --> 00:08:18,266
由非常多的 pass

249
00:08:18,266 --> 00:08:19,800
然后中间通过一个 IR

250
00:08:19,800 --> 00:08:21,133
进行一个优化的

251
00:08:21,133 --> 00:08:22,366
那自动微分呢

252
00:08:22,366 --> 00:08:23,866
这个呢在 MindSpore 里面呢

253
00:08:23,866 --> 00:08:26,600
也是通过一个编译来去实现的

254
00:08:27,533 --> 00:08:29,733
因此呢对于 AI 编译器来说呢

255
00:08:29,733 --> 00:08:32,200
可以将神经网络中间表达呢

256
00:08:32,200 --> 00:08:33,333
或者 IR 呢

257
00:08:33,333 --> 00:08:35,566
变成不同的硬件的代码

258
00:08:35,566 --> 00:08:37,333
就直接怼到硬件上面呢

259
00:08:37,333 --> 00:08:39,566
然后可以直接快速的部署起来

260
00:08:39,566 --> 00:08:41,200
提供高效的服务

261
00:08:41,766 --> 00:08:42,166
当然了

262
00:08:42,166 --> 00:08:45,666
上面提到的都是比较抽象的概念

263
00:08:45,666 --> 00:08:47,700
实际上对到每一层啊

264
00:08:47,733 --> 00:08:49,666
都是通过不同的优化

265
00:08:49,666 --> 00:08:51,600
不同的 pass 去执行的

266
00:08:51,733 --> 00:08:52,700
例如对计算图

267
00:08:52,700 --> 00:08:55,200
有计算图的特殊的优化

268
00:08:55,200 --> 00:08:56,600
在运行时的时候呢

269
00:08:56,600 --> 00:08:58,400
有运行时的优化

270
00:08:58,666 --> 00:08:59,866
在算子执行的时候

271
00:08:59,866 --> 00:09:02,100
有算子执行特殊的优化

272
00:09:02,100 --> 00:09:04,066
所以后面呢把它解耦出来

273
00:09:04,066 --> 00:09:04,866
其实

274
00:09:04,933 --> 00:09:06,166
对于不同层

275
00:09:06,166 --> 00:09:08,300
都可以做不同的 pass 的优化

276
00:09:08,300 --> 00:09:10,933
这对整个 AI 系统全程来说

277
00:09:10,966 --> 00:09:12,533
是非常重要的

278
00:09:12,533 --> 00:09:14,200
这也是为什么现在我

279
00:09:14,366 --> 00:09:17,266
我比较喜欢 PyTorch2.0 推出的 Dynamo

280
00:09:17,266 --> 00:09:18,266
这个特性

281
00:09:20,166 --> 00:09:21,133
在结束之前呢

282
00:09:21,133 --> 00:09:24,333
看一下静态图加 AI 编译器的

283
00:09:24,400 --> 00:09:25,500
一些问题啊

284
00:09:25,500 --> 00:09:26,500
就是它的 Cons

285
00:09:26,533 --> 00:09:27,766
对我一个算法来说呢

286
00:09:27,766 --> 00:09:29,800
其实我觉得 PyTorch 的

287
00:09:29,866 --> 00:09:31,800
动态图确实做的非常好

288
00:09:31,800 --> 00:09:33,466
我为什么需要编译器呢

289
00:09:34,133 --> 00:09:35,866
我使用其他 AI 框架的时候

290
00:09:35,866 --> 00:09:38,333
大部分都会带有一些 AI 编译器的性能

291
00:09:38,333 --> 00:09:40,533
那这个时候呢我要去学他的前端

292
00:09:40,533 --> 00:09:42,300
不能够很好灵活的表达

293
00:09:42,333 --> 00:09:42,800
这个呢

294
00:09:42,800 --> 00:09:45,366
是对一些初学者或者开发者来说呢

295
00:09:45,466 --> 00:09:46,666
是不太友好的

296
00:09:46,666 --> 00:09:47,900
那第二点呢就是

297
00:09:48,600 --> 00:09:50,566
经过优化后的计算图啊

298
00:09:50,566 --> 00:09:51,066
其实已经

299
00:09:51,066 --> 00:09:53,400
不是原来所表达的代码了

300
00:09:53,400 --> 00:09:56,566
就导致代码有一些错误呢很难去表达

301
00:09:56,566 --> 00:09:58,400
例如我做了一些算子的消除

302
00:09:58,466 --> 00:10:01,300
我原来算子消除的那段代码写错了

303
00:10:01,300 --> 00:10:03,266
这个时候呢很难去定位

304
00:10:04,400 --> 00:10:06,533
第三点呢还是调试的问题

305
00:10:06,533 --> 00:10:09,000
假设改了代码需要重新编译

306
00:10:09,000 --> 00:10:10,300
而重新编译呢

307
00:10:10,300 --> 00:10:12,966
又导致执行效率的变低

308
00:10:14,966 --> 00:10:18,266
最后就是引发大家一个的思考

309
00:10:18,300 --> 00:10:19,800
像 TorchDynamo 呢

310
00:10:19,800 --> 00:10:21,400
PyTorch2.0 的特性

311
00:10:21,400 --> 00:10:23,766
真的能解决 99%的场景吗

312
00:10:23,866 --> 00:10:26,266
他能解决多少场景的问题

313
00:10:26,266 --> 00:10:28,000
这个是一个问号

314
00:10:28,066 --> 00:10:30,566
希望他能够解决的越多越好

315
00:10:30,733 --> 00:10:32,500
然后第二点就是 MindSpore 呢

316
00:10:32,500 --> 00:10:34,066
它的优化主要是针对

317
00:10:34,066 --> 00:10:36,133
静态图加 AI 编译器的

318
00:10:36,300 --> 00:10:38,866
未来在动态图转静态图

319
00:10:38,866 --> 00:10:40,600
然后使用 AI 编译器

320
00:10:41,000 --> 00:10:43,500
大家有没有更好的方案呢

321
00:10:43,666 --> 00:10:44,666
其实我这里面呢

322
00:10:44,666 --> 00:10:47,700
很希望大家不要太多的去沉迷于

323
00:10:47,866 --> 00:10:49,466
用 PyTorch 这个框架

324
00:10:49,466 --> 00:10:51,866
而是更多的去回头来看看

325
00:10:51,866 --> 00:10:53,900
对于自己国产的框架

326
00:10:53,900 --> 00:10:55,166
有什么优化的点

327
00:10:55,166 --> 00:10:56,466
有什么好的思路

328
00:10:56,466 --> 00:10:59,166
去贡献到国产的 AI 框架里面

329
00:10:59,566 --> 00:11:00,866
好了谢谢各位

330
00:11:00,933 --> 00:11:01,700
拜了个拜

331
00:11:01,700 --> 00:11:03,500
卷的不行了卷的不行了

332
00:11:03,500 --> 00:11:05,166
记得一键三连加关注哦

333
00:11:05,266 --> 00:11:06,933
所有的内容都会开源在

334
00:11:06,933 --> 00:11:08,466
下面这条链接里面

335
00:11:08,866 --> 00:11:09,800
拜了个拜

