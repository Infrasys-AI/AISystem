1
00:00:00,038 --> 00:00:04,806
【字幕生成: 奔崩字幕校对: 奔崩】
（进——片——头）

2
00:00:06,311 --> 00:00:08,320
Hello，大家好，我是 ZOMI

3
00:00:08,320 --> 00:00:11,920
今天我们还是在 AI 编译器的后端优化

4
00:00:11,920 --> 00:00:14,760
今天我们主要去分享的内容是

5
00:00:14,760 --> 00:00:16,360
算子的调度优化

6
00:00:17,680 --> 00:00:19,520
现在我们来回顾一下

7
00:00:19,520 --> 00:00:21,080
在整个 AI 编译器里面

8
00:00:21,080 --> 00:00:24,760
现在算子的调度优化其实还在这个位置

9
00:00:24,760 --> 00:00:27,520
而今天或者接下来我要给大家汇报的内容

10
00:00:27,800 --> 00:00:29,920
更多的是集中在不同的 Path

11
00:00:29,920 --> 00:00:32,720
不同的一些优化的方式方法

12
00:00:32,720 --> 00:00:35,120
那这一节里面我们更多的是聚焦于

13
00:00:35,120 --> 00:00:36,640
算子的优化

14
00:00:36,640 --> 00:00:38,000
OPS 的优化

15
00:00:38,000 --> 00:00:40,160
所以我们可能会更加硬核一点

16
00:00:40,160 --> 00:00:41,440
更加贴近底层一点

17
00:00:41,571 --> 00:00:42,440
不会吧

18
00:00:44,040 --> 00:00:45,400
现在我们回顾一下

19
00:00:45,400 --> 00:00:47,880
AI 编译器的后端最主要的组成方式

20
00:00:47,880 --> 00:00:49,920
或者几个优化的一个大的模块

21
00:00:50,520 --> 00:00:52,320
首先我们会把 Graph  IR

22
00:00:52,320 --> 00:00:54,480
就是图的 IR 图的模式

23
00:00:54,480 --> 00:00:56,440
变成 Tensor 的 IR

24
00:00:56,600 --> 00:00:57,840
生成低级的 IR

25
00:00:57,840 --> 00:01:00,280
然后给后端的优化去做

26
00:01:00,280 --> 00:01:01,360
那这个后端的优化

27
00:01:01,360 --> 00:01:03,760
就是我们接下来要给大家汇报的内容

28
00:01:03,760 --> 00:01:05,440
接着变成一个 Lower IR

29
00:01:05,440 --> 00:01:07,560
就是比较低级的机器语言码的 IR

30
00:01:07,560 --> 00:01:08,800
然后给后端

31
00:01:08,800 --> 00:01:13,200
后端对应的生成我们不同硬件的一些执行指令

32
00:01:14,880 --> 00:01:16,200
在上一节的内容里面

33
00:01:16,360 --> 00:01:17,640
其实我们去讲了

34
00:01:17,640 --> 00:01:19,640
或者给大家分享了一个调度树

35
00:01:19,640 --> 00:01:22,000
那调度树就是把一些算子

36
00:01:22,360 --> 00:01:24,880
把算子的计算和调度分开

37
00:01:24,880 --> 00:01:28,560
那右边的这个就是对应的算子的一个执行的方式

38
00:01:28,560 --> 00:01:31,600
左边这个就是低级的 IR

39
00:01:31,600 --> 00:01:33,280
OPS IR 或者 Tensor IR

40
00:01:33,280 --> 00:01:36,320
当然了每个 IR 的方式可能不尽相同

41
00:01:36,320 --> 00:01:38,200
所以我们统一叫做调度树

42
00:01:38,200 --> 00:01:41,080
Schedule Trees 来代表 Lower IR

43
00:01:41,080 --> 00:01:42,160
有了这个 Lower IR

44
00:01:42,320 --> 00:01:43,720
我们就可以对这个 IR

45
00:01:43,720 --> 00:01:46,440
或者这个树进行一个编译的优化

46
00:01:46,720 --> 00:01:47,640
编译优化完之后

47
00:01:47,760 --> 00:01:49,480
我们就生成每一个算子

48
00:01:49,480 --> 00:01:52,320
所对应的调度的策略和调度的代码

49
00:01:52,320 --> 00:01:54,360
有了上两节课的基础之后

50
00:01:54,480 --> 00:01:56,120
我们今天主要聚焦的内容

51
00:01:56,120 --> 00:01:58,000
就是算子的调度优化

52
00:01:58,640 --> 00:02:00,360
可以看到其实算子

53
00:02:00,360 --> 00:02:03,000
假设左边这个我们输入一个马冬梅

54
00:02:03,000 --> 00:02:04,440
那预测的是马冬梅

55
00:02:05,280 --> 00:02:07,960
神经网络里面卷积这个算子的实现

56
00:02:08,120 --> 00:02:09,240
就像右边所示

57
00:02:09,240 --> 00:02:10,120
非常复杂

58
00:02:10,120 --> 00:02:12,120
特别是有非常多的 for

59
00:02:12,120 --> 00:02:13,480
非常多的循环

60
00:02:13,480 --> 00:02:16,240
所以我们最重要的特点就是多重循环嵌套

61
00:02:16,240 --> 00:02:18,720
第二个就是没有复杂的控制流

62
00:02:18,720 --> 00:02:20,680
一般都是一些简单的控制流

63
00:02:20,680 --> 00:02:22,360
或者根本就没有控制流

64
00:02:22,680 --> 00:02:25,840
第三个就是神经网络里面传输的时候

65
00:02:26,000 --> 00:02:28,440
是以张量作为一个主要的数据结构

66
00:02:28,440 --> 00:02:30,960
所以它的数据方式或者数据的排布

67
00:02:30,960 --> 00:02:32,120
会非常复杂

68
00:02:33,520 --> 00:02:35,360
而在 Halide 或者 TVM 里面

69
00:02:35,480 --> 00:02:37,920
有非常多不同的优化的方式

70
00:02:37,920 --> 00:02:40,160
提供给我们去做一个实现

71
00:02:40,160 --> 00:02:42,000
或者做一个初步的拼接的

72
00:02:42,440 --> 00:02:44,600
在正式的去展开这里面的

73
00:02:44,600 --> 00:02:46,200
各种的优化的方式

74
00:02:46,200 --> 00:02:48,760
或者编译器给我们提供的基本的方法之前

75
00:02:49,440 --> 00:02:51,680
我们来看一个基于源码

76
00:02:51,680 --> 00:02:54,040
进行一个修改的一些简单的内容

77
00:02:55,120 --> 00:02:57,920
首先第一个内容就是循环的交换

78
00:02:58,200 --> 00:02:59,480
在多重循环里面

79
00:02:59,480 --> 00:03:01,440
或者在图像迭代里面

80
00:03:01,600 --> 00:03:03,920
我们可以看到假设先遍历一个 10000

81
00:03:03,920 --> 00:03:05,000
然后再遍历 200

82
00:03:05,000 --> 00:03:05,560
这个时候

83
00:03:06,040 --> 00:03:08,760
我们内层的循环遍历的次数比较少

84
00:03:08,760 --> 00:03:11,720
但是我们外层循环遍历的次数非常多

85
00:03:12,040 --> 00:03:15,320
这种方式可能会导致我们内存的消耗比较大

86
00:03:15,360 --> 00:03:17,480
我们可能需要把 1 万这里面的数据

87
00:03:17,600 --> 00:03:18,720
扔到内存里面

88
00:03:18,720 --> 00:03:21,040
所以我们可以把它进行一个对换

89
00:03:21,440 --> 00:03:23,160
这种就叫做循环交换

90
00:03:23,160 --> 00:03:24,320
我们先遍历 200

91
00:03:24,320 --> 00:03:25,440
再遍历我们 1 万

92
00:03:25,960 --> 00:03:27,200
每次编译器

93
00:03:27,320 --> 00:03:28,520
就把这 1 万的数据

94
00:03:28,520 --> 00:03:30,000
丢给硬件再去执行

95
00:03:30,000 --> 00:03:31,120
然后从编译栈

96
00:03:31,120 --> 00:03:32,240
或者我们堆栈里面

97
00:03:32,440 --> 00:03:34,720
再迭代下一个 i 的数据出来

98
00:03:35,040 --> 00:03:36,560
这种方式可以很好的利用

99
00:03:36,560 --> 00:03:38,320
我们内存或者显存的空间

100
00:03:39,880 --> 00:03:42,520
第二个就是循环变量的实例化

101
00:03:42,520 --> 00:03:44,320
可以看到其实我们在 for 里面

102
00:03:44,520 --> 00:03:45,880
我们实例化了一个 i

103
00:03:45,880 --> 00:03:47,160
再实例化了一个 j

104
00:03:47,160 --> 00:03:50,680
但很多时候我们可以把 i 和 j 实例化出来

105
00:03:50,960 --> 00:03:52,200
避免每一次迭代

106
00:03:52,360 --> 00:03:54,040
都对它进行一个实例化

107
00:03:54,040 --> 00:03:57,760
接着我们还可能会有一个表达式的外放

108
00:03:59,200 --> 00:04:01,760
表达式的外放可能还是比较简单的

109
00:04:01,760 --> 00:04:04,040
假设我现在有 x 除以(y-1)

110
00:04:04,320 --> 00:04:07,080
这个数据其实跟迭代 i 和 j

111
00:04:07,080 --> 00:04:08,480
没有半毛钱关系

112
00:04:08,480 --> 00:04:10,840
所以我们会把这一个表达式

113
00:04:11,080 --> 00:04:13,280
直接外提到循环外面

114
00:04:13,280 --> 00:04:15,691
tmp = x / (y - 1)

115
00:04:15,880 --> 00:04:18,000
这个时候我在迭代循环里面

116
00:04:18,320 --> 00:04:19,400
直接从内存空间

117
00:04:19,400 --> 00:04:20,680
或者在 cache 里面

118
00:04:20,840 --> 00:04:22,200
读到 tmp 里面

119
00:04:22,560 --> 00:04:24,360
以空间换时间的方法

120
00:04:24,360 --> 00:04:26,080
不用每次都进行一个计算

121
00:04:27,760 --> 00:04:30,040
另外我们还有一个循环终止

122
00:04:30,320 --> 00:04:32,320
循环终止主要是指消除

123
00:04:32,320 --> 00:04:34,720
循环终止时候的一个调用方式

124
00:04:35,000 --> 00:04:37,640
这个其实跟刚才的循环变量实例化

125
00:04:37,640 --> 00:04:38,320
比较相像

126
00:04:38,320 --> 00:04:39,320
我这里面 int i

127
00:04:39,320 --> 00:04:41,240
那后面 i 它其实有一个

128
00:04:41,880 --> 00:04:43,000
循环终止的方式

129
00:04:43,000 --> 00:04:44,120
循环终止一开始

130
00:04:44,120 --> 00:04:46,080
可能直接点 size 去获取的

131
00:04:46,320 --> 00:04:48,000
这里面我们直接把点 size

132
00:04:48,240 --> 00:04:50,120
实例化到循环外面

133
00:04:50,120 --> 00:04:51,080
通过这种方式

134
00:04:51,240 --> 00:04:53,880
去消除我们循环终止时候的一个调用

135
00:04:55,480 --> 00:04:56,280
刚才所讲的

136
00:04:56,280 --> 00:04:58,080
只是我们在写算子的时候

137
00:04:58,080 --> 00:05:00,320
可能需要注意的一些初级的功能

138
00:05:00,920 --> 00:05:02,960
有了对刚才一些概念的了解

139
00:05:02,960 --> 00:05:05,720
其实我更建议大家去了解一下 CUDA

140
00:05:06,080 --> 00:05:07,960
看看 CUDA 是怎么写代码的

141
00:05:07,960 --> 00:05:09,680
可能我们在写代码的时候

142
00:05:09,840 --> 00:05:10,880
不一定会用 CUDA

143
00:05:10,880 --> 00:05:13,200
因为 CUDA 主要是针对 GPU 去使用的

144
00:05:13,560 --> 00:05:15,120
像华为昇腾就推出了

145
00:05:15,120 --> 00:05:18,240
自己的 DSL Domain Specific Language TBE

146
00:05:18,680 --> 00:05:20,200
陈天奇推出的 TVM

147
00:05:20,200 --> 00:05:23,800
像这种的 Domain Specific Language 的方式

148
00:05:24,440 --> 00:05:26,040
通过这些领域专用的语言

149
00:05:26,200 --> 00:05:28,080
我们可以写一些自己的算子

150
00:05:28,080 --> 00:05:30,640
而自己写算子就是我们 AI 框架

151
00:05:31,000 --> 00:05:31,800
变成了一个图的 IR

152
00:05:32,080 --> 00:05:32,920
或者变成一个

153
00:05:32,920 --> 00:05:34,400
每次当算子调度的时候

154
00:05:34,720 --> 00:05:36,880
都可以去调用一个算子库

155
00:05:36,880 --> 00:05:38,760
然后跑在硬件上面的

156
00:05:39,800 --> 00:05:41,320
由于整个 AI 编译器

157
00:05:41,320 --> 00:05:42,960
或者在 AI 框架里面

158
00:05:43,080 --> 00:05:44,760
大部分都是分层解耦的

159
00:05:44,920 --> 00:05:46,160
所以很有可能

160
00:05:46,160 --> 00:05:47,840
我们是走了 Graph IR 之后

161
00:05:48,160 --> 00:05:49,400
再去调 Runtime

162
00:05:49,400 --> 00:05:50,960
或者调算子库

163
00:05:51,200 --> 00:05:52,280
不一定在 Runtime 里面

164
00:05:52,440 --> 00:05:53,840
可能直接调算子库

165
00:05:54,120 --> 00:05:55,560
然后再执行在 Runtime 里面

166
00:05:56,240 --> 00:05:58,560
最后在硬件上面去跑的

167
00:05:58,840 --> 00:06:00,600
所以说每一层都是分层解耦的

168
00:06:00,840 --> 00:06:02,760
大家不要觉得 AI 编译器里面

169
00:06:02,760 --> 00:06:04,880
每一层我都要实现对应的功能

170
00:06:04,880 --> 00:06:07,800
其实每一层我们都有可替换的方案

171
00:06:08,280 --> 00:06:11,520
或者可替换的对应的开源的课程

172
00:06:12,400 --> 00:06:14,760
现在我们看一下一个正式的内容

173
00:06:14,760 --> 00:06:16,720
也是接下来我要给大家汇报的

174
00:06:17,000 --> 00:06:19,520
就是 AI 编译器的算子优化

175
00:06:20,960 --> 00:06:22,280
其实算子优化这里面

176
00:06:22,680 --> 00:06:24,720
我对这里面的算子优化的

177
00:06:24,720 --> 00:06:26,040
一个调度的方法

178
00:06:26,040 --> 00:06:27,640
分为三大个类型

179
00:06:27,640 --> 00:06:29,560
第一个就是循环优化

180
00:06:29,560 --> 00:06:31,800
我们叫做 loop optimization

181
00:06:32,120 --> 00:06:33,920
第二个就是指令优化

182
00:06:33,920 --> 00:06:35,400
instruction optimization

183
00:06:36,200 --> 00:06:38,240
第三个就是存储的优化

184
00:06:38,240 --> 00:06:39,680
memory optimization

185
00:06:40,040 --> 00:06:42,160
现在我们逐个的去看一下

186
00:06:42,440 --> 00:06:45,240
为啥循环优化会有这么多内容呢

187
00:06:48,000 --> 00:06:50,600
最重要的原因是因为我们计算的特征

188
00:06:50,600 --> 00:06:52,040
特别是对于神经网络

189
00:06:52,040 --> 00:06:54,200
AI 编译器里面的计算的特征

190
00:06:54,440 --> 00:06:56,840
我们是以多重循环嵌套

191
00:06:56,840 --> 00:06:58,400
作为一个主要的特点的

192
00:06:58,680 --> 00:07:00,800
第 2 个是以多维张量计算

193
00:07:01,080 --> 00:07:02,520
作为一个主要的数据结构

194
00:07:02,520 --> 00:07:03,760
所以算子的优化

195
00:07:03,760 --> 00:07:06,000
或者 ops optimizer

196
00:07:06,560 --> 00:07:07,480
后端的优化

197
00:07:07,560 --> 00:07:09,160
大部分集中在对

198
00:07:09,160 --> 00:07:12,840
循环遍历迭代 loop 进行一个优化

199
00:07:14,000 --> 00:07:15,560
而优化的方法特别多

200
00:07:15,560 --> 00:07:18,120
我们会对循环进行展开 Unrolling

201
00:07:18,120 --> 00:07:20,360
我们还会对循环进行分块

202
00:07:20,360 --> 00:07:24,840
接着还有循环的重排 reorder 融合 fusion

203
00:07:24,840 --> 00:07:26,240
还有拆分 split

204
00:07:27,080 --> 00:07:28,680
而指令优化的更多是

205
00:07:28,680 --> 00:07:30,760
对应到具体硬件的芯片

206
00:07:30,760 --> 00:07:31,760
例如向量化

207
00:07:31,760 --> 00:07:33,080
还有张量化

208
00:07:33,542 --> 00:07:35,040
根据硬件的 SIMP

209
00:07:35,040 --> 00:07:36,560
或者 SIMB 的方式

210
00:07:36,560 --> 00:07:37,760
进行一个优化的

211
00:07:38,120 --> 00:07:40,080
最后就是存储优化

212
00:07:40,080 --> 00:07:41,520
有可能部分的存储优化

213
00:07:41,520 --> 00:07:42,680
叫做并行的优化

214
00:07:43,200 --> 00:07:44,720
因为 cpu 跟 npu 的并行

215
00:07:44,880 --> 00:07:46,800
我们可以变成存储分配

216
00:07:47,320 --> 00:07:49,480
或者存储延迟隐藏的这种功能

217
00:07:50,040 --> 00:07:51,760
但是这里面大部分的内容

218
00:07:51,920 --> 00:07:53,440
都是跟存储相关的

219
00:07:53,800 --> 00:07:55,200
所以我叫做存储优化

220
00:07:55,200 --> 00:07:57,320
而存储优化主要分为两个功能

221
00:07:57,320 --> 00:07:59,240
第一个就是访存的延迟

222
00:07:59,880 --> 00:08:01,560
第二个就是存储的分配

223
00:08:03,080 --> 00:08:03,400
好了

224
00:08:03,400 --> 00:08:05,000
今天的内容到这里为止

225
00:08:05,200 --> 00:08:06,880
我们将会在下一节里面

226
00:08:06,880 --> 00:08:08,120
去详细讲开

227
00:08:08,680 --> 00:08:11,600
具体每个调度优化的方式和方法

228
00:08:12,680 --> 00:08:13,240
谢谢各位

229
00:08:13,680 --> 00:08:14,400
拜了个拜

230
00:08:15,120 --> 00:08:15,840
卷的不行了

231
00:08:15,840 --> 00:08:16,680
卷的不行了

232
00:08:16,680 --> 00:08:18,360
记得一键三连加关注哦

233
00:08:18,680 --> 00:08:19,880
所有的内容都会开源

234
00:08:19,880 --> 00:08:21,520
在下面这条链接里面

235
00:08:22,200 --> 00:08:22,840
拜了个拜