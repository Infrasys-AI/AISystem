1
00:00:01,466 --> 00:00:03,733
字幕生成：mkwei  字幕校准：mkwei

2
00:00:11,500 --> 00:00:11,966
今天呢

3
00:00:42,600 --> 00:00:43,500
现在非常火的

4
00:00:45,200 --> 00:00:47,100
看一下它的整体的架构的发展

5
00:00:51,800 --> 00:00:54,166
接着我们来到了国外的 AI 芯片

6
00:00:54,166 --> 00:00:57,233
和国内的 AI 芯片的一个解读

7
00:01:11,600 --> 00:01:13,000
谷歌 TPU 这个系列呢

8
00:01:30,200 --> 00:01:32,866
对比英伟达的 GPU 的第一款训练卡

9
00:01:33,200 --> 00:01:35,266
确实性能超越了非常的多

10
00:01:37,500 --> 00:01:39,200
整体的性能呢翻了一番

11
00:01:48,000 --> 00:01:49,966
最后啊或者我们在下个视频呢

12
00:01:54,000 --> 00:01:56,666
当然呢是光互联的方式

13
00:01:58,166 --> 00:02:01,433
简单回顾完我们之前讲的一些内容

14
00:02:03,300 --> 00:02:04,966
可能大家都忘了

15
00:02:04,966 --> 00:02:07,133
那现在呢我们来到了正式第一个内容

16
00:03:17,566 --> 00:03:19,633
就要求 TPU 也需要到 5 纳米

17
00:03:21,000 --> 00:03:22,766
7 纳米可能就够了

18
00:03:34,400 --> 00:03:36,200
然后呢 TPUV3 呢等

19
00:03:59,900 --> 00:04:01,666
V3 呢产品形态

20
00:04:01,666 --> 00:04:03,233
右边呢右边呢

21
00:04:09,466 --> 00:04:10,166
而左边呢

22
00:04:30,166 --> 00:04:31,766
或者叫我们的内存

23
00:04:37,366 --> 00:04:39,033
其实我们在上一个视频

24
00:04:47,700 --> 00:04:50,100
变成了两个进行堆叠

25
00:04:54,566 --> 00:04:55,733
就是超级计算

26
00:05:21,400 --> 00:05:23,566
上面这款呢就是我们的 CPU

27
00:05:24,766 --> 00:05:29,066
就可能带着好几个 GPU 或者 TPU 的卡

28
00:05:48,166 --> 00:05:49,333
最后呢在第三步

29
00:06:08,666 --> 00:06:11,966
它们之间呢需要进行一个平衡求和

30
00:06:16,366 --> 00:06:18,866
可以重新翻一翻我刚才讲的内容

31
00:06:25,066 --> 00:06:28,066
我们看看整体的 Pod 超级计算的形态

32
00:06:31,466 --> 00:06:34,233
我们后面呢将会在第四个小节里面呢

33
00:06:40,100 --> 00:06:41,366
什么叫做 Pod

34
00:06:41,366 --> 00:06:42,333
这个很有意思

35
00:07:05,966 --> 00:07:07,133
那这里面的 a 呢

36
00:07:24,900 --> 00:07:28,666
两个 blue link 的 25GB 每秒的电脑的接口

37
00:07:46,766 --> 00:07:47,733
是 IBM 嘛

38
00:07:56,300 --> 00:07:57,800
是吧大家联想一下

39
00:08:20,066 --> 00:08:21,933
也就是英特尔它自己的一个内容

40
00:08:33,566 --> 00:08:36,133
也就是 b 跟 c

41
00:08:36,400 --> 00:08:41,566
里面呢有 256 块刚才讲到的 TPU2 的芯片

42
00:08:54,000 --> 00:08:56,200
TPU V3 的整体的基本的形态啊

43
00:09:02,966 --> 00:09:04,966
感觉蓝色更炫酷一点

44
00:09:07,300 --> 00:09:10,600
里面呢同样有 4 块 TPU

45
00:09:30,466 --> 00:09:31,666
不过呢有个很大的区别

46
00:09:31,666 --> 00:09:35,366
就是 V3 整体的 pod 的形态呢是 1024

47
00:10:03,600 --> 00:10:06,500
ZOMI 觉得就是每块卡的算力不一样

48
00:10:10,500 --> 00:10:11,566
这里面呢

49
00:10:16,100 --> 00:10:18,000
而右边的 TPUV3 呢

50
00:10:20,066 --> 00:10:22,033
现在我们看到一个超级计算中心呢

51
00:10:24,100 --> 00:10:27,200
但是呢当时还是在 18 年呢

52
00:10:27,200 --> 00:10:30,466
18 年谷歌已经提出了这么一个 petaflops

53
00:10:41,700 --> 00:10:44,266
还是一台机器一台机器的去卖的

54
00:10:48,000 --> 00:10:49,766
通过 RPC 远程连接呢

55
00:10:51,166 --> 00:10:53,033
也就是我们的 CPU 的连接

56
00:11:32,366 --> 00:11:34,333
有一个 2D 的 toru s

57
00:11:38,266 --> 00:11:39,533
那对比起以前呢

58
00:11:44,500 --> 00:11:46,766
啊省去了我们的集群的网卡

59
00:11:49,700 --> 00:11:52,700
也就是 TPU 跟 CPU 之间的通讯呢

60
00:11:52,900 --> 00:11:54,766
延迟降的非常的多

61
00:11:58,666 --> 00:12:01,133
这呢也侧面的反映了谷歌的 TPU

62
00:12:05,900 --> 00:12:08,566
这里面呢我们就看看整个 TPU 的 pod 啊

63
00:12:08,566 --> 00:12:09,933
整个环的链路啊

64
00:12:13,466 --> 00:12:14,866
同步跟异步的训练呢

65
00:12:14,866 --> 00:12:17,433
当然呢是同步的训练会比异步的更慢

66
00:12:24,466 --> 00:12:25,666
可以打败整体的

67
00:12:33,400 --> 00:12:34,800
跨节点进行通讯时

68
00:12:39,400 --> 00:12:40,400
我们整个参数

69
00:12:41,100 --> 00:12:43,766
跟各个节点的带宽不足的问题呢

70
00:12:43,766 --> 00:12:44,966
我们可以看到啊

71
00:12:45,266 --> 00:12:46,966
假设呢这八块卡呢

72
00:12:47,800 --> 00:12:50,800
在一块 GPU 或者在一个 DGS 里面呢

73
00:12:50,800 --> 00:12:53,200
这八块卡又在一个 DJs 里面

74
00:13:13,200 --> 00:13:14,500
和谷歌的论文

75
00:13:16,200 --> 00:13:18,300
谷歌的 Pod 的一个详情

76
00:13:46,900 --> 00:13:49,400
和机架式的交换机的顶部啊

77
00:13:54,866 --> 00:13:57,133
实际上呢谷歌 TPU V3 这里面呢

78
00:14:02,100 --> 00:14:04,000
是通过谷歌的计算中心

79
00:14:11,866 --> 00:14:13,066
其实它没有官方呢

80
00:14:28,200 --> 00:14:29,866
还有 OPA 的铜缆呢

81
00:14:53,266 --> 00:14:53,966
还是很有意思

82
00:14:53,966 --> 00:14:56,866
就讲我们的核心呢是怎么串联起来的

83
00:14:56,866 --> 00:14:59,533
那通过刚才的整个 pod 的形态呢

84
00:00:08,900 --> 00:00:11,500
生活才能亮晶晶的 ZOMI

85
00:00:17,700 --> 00:00:20,300
才是真正的谷歌 TPU V3 的

86
00:00:20,300 --> 00:00:22,366
实际的一个芯片

87
00:00:22,366 --> 00:00:23,733
板卡的图

88
00:00:24,200 --> 00:00:24,566
现在呢

89
00:00:24,566 --> 00:00:27,333
我们回顾一下之前的整个 AI 芯片系列

90
00:00:28,366 --> 00:00:30,433
我们其实分开了 6 个章节

91
00:00:31,900 --> 00:00:35,566
从 AI 的一个计算的体系开始引起呢

92
00:00:35,566 --> 00:00:38,666
看我们的 AI 芯片应该怎么去设计

93
00:00:38,666 --> 00:00:40,066
有哪些技巧

94
00:00:40,600 --> 00:00:42,600
接着呢我们去到了英伟达的 GPU

95
00:00:48,400 --> 00:00:51,800
和 NV link 到底有什么秘密

96
00:00:57,200 --> 00:00:59,966
最后去引起我们 AI 芯片的思考

97
00:00:59,966 --> 00:01:01,833
包括 SIMD SIMT 的编程体系

98
00:01:04,366 --> 00:01:07,366
现在呢我们还是在第四个内容

99
00:01:07,366 --> 00:01:11,033
谷歌 TPU 系列这一个内容啊

100
00:01:13,000 --> 00:01:15,500
其实我们已经前面给大家分享过了

101
00:01:15,500 --> 00:01:17,200
整体的 TPU 的历史的发展

102
00:01:20,266 --> 00:01:22,366
大家叫脉冲阵列也好

103
00:01:22,366 --> 00:01:23,433
那 TPU2 呢

104
00:01:24,700 --> 00:01:26,266
它是基于我们的推理卡

105
00:01:26,266 --> 00:01:29,233
v1 而衍生的第一款训练卡

106
00:01:35,266 --> 00:01:37,533
而谷歌的 TPU V3 呢

107
00:01:39,200 --> 00:01:41,966
特别是利用了 pod 的超算的形态

108
00:01:41,966 --> 00:01:43,766
那什么叫 pod 的形态呢

109
00:01:43,766 --> 00:01:48,033
我将会在后面给大家去简单的分享一下

110
00:01:49,966 --> 00:01:51,233
就会给大家去分享

111
00:02:01,400 --> 00:02:03,300
也就是鸽了有一段时间呢

112
00:02:10,000 --> 00:02:13,366
其实呢谷歌 TPUV3 呢对比起 TPUV2 呢

113
00:02:13,366 --> 00:02:15,233
只是一个简单的增强版

114
00:02:16,766 --> 00:02:18,766
去把它的架构图啊

115
00:02:18,766 --> 00:02:20,366
实物图案拿出来看看

116
00:02:22,100 --> 00:02:22,800
那实际上呢

117
00:02:22,800 --> 00:02:24,500
它增加的东西并不多

118
00:02:24,500 --> 00:02:25,966
主要是我觉得很重要的

119
00:02:25,966 --> 00:02:30,033
就是峰值的算力提升了 2.7 倍

120
00:02:32,866 --> 00:02:35,233
一个方面呢就是 MXU 就脉动阵列

121
00:02:36,700 --> 00:02:39,266
第二个呢就是时钟频率加快了

122
00:02:39,266 --> 00:02:40,666
但是带来的问题呢

123
00:02:40,666 --> 00:02:44,133
就是我们的功耗啊更加的上去了

124
00:02:46,600 --> 00:02:49,966
里面的从 V1 的推理到 V2 的第一块训练

125
00:02:49,966 --> 00:02:52,966
到 V3 的提供了 pod 的形态

126
00:02:52,966 --> 00:02:56,233
整体呢 ZOMI 最关心的就是两个指标

127
00:02:58,200 --> 00:03:00,266
也就是我们的制造工艺

128
00:03:00,266 --> 00:03:03,033
TPU V1 呢因为它是一个推理卡

129
00:03:05,966 --> 00:03:09,633
然后呢到 V2 呢用了 16 纳米 V3 只是增强

130
00:03:11,800 --> 00:03:14,500
所以它呢仍然延用 16 纳米

131
00:03:14,500 --> 00:03:16,300
大家不要觉得现在的手机啊

132
00:03:16,300 --> 00:03:17,566
都到了 5 纳米

133
00:03:19,600 --> 00:03:21,000
其实完全没有必要啊

134
00:03:24,300 --> 00:03:25,400
会我主要关心的

135
00:03:25,400 --> 00:03:28,800
就是里面的提供的算力 TOPS

136
00:03:28,966 --> 00:03:32,266
TOPS 啊那个 TPUV2 呢

137
00:03:32,266 --> 00:03:34,433
就提供了 180TOPS

138
00:03:38,966 --> 00:03:40,066
但是有一点很重要的

139
00:03:40,066 --> 00:03:43,233
就是下面这个 TOPS 的每瓦特啊

140
00:03:44,266 --> 00:03:46,633
V2 只需要 0.16 哦哦

141
00:03:49,700 --> 00:03:50,700
3 倍多

142
00:03:50,700 --> 00:03:53,966
再看到它的散热是一个严重的问题

143
00:03:53,966 --> 00:03:55,833
于是呢我们可以看到左右两边

144
00:03:56,366 --> 00:03:59,933
就谷歌 GPU 的一个具体的产品形态

145
00:04:03,200 --> 00:04:05,000
因为散热功耗大了

146
00:04:05,000 --> 00:04:06,700
所以它需要用到液冷

147
00:04:06,700 --> 00:04:07,366
那液冷呢

148
00:04:07,366 --> 00:04:09,466
就是下面这个铜管道

149
00:04:10,900 --> 00:04:13,800
只是一个简单的散热片

150
00:04:14,900 --> 00:04:16,500
从架构图可以看到啊

151
00:04:16,500 --> 00:04:17,700
MXU 也就是脉动阵列

152
00:04:17,700 --> 00:04:21,566
V3 比 V2 大了两倍

153
00:04:21,566 --> 00:04:22,933
多了一个嘛

154
00:04:25,600 --> 00:04:26,666
那我觉得很正常

155
00:04:26,666 --> 00:04:28,633
因为 HBM 它是采购的嘛

156
00:04:28,666 --> 00:04:30,166
HBM 是做我们的显存

157
00:04:32,666 --> 00:04:33,133
接下来呢

158
00:04:36,266 --> 00:04:37,366
整体的架构呢

159
00:04:39,000 --> 00:04:40,166
或者之前的视频呢

160
00:04:40,166 --> 00:04:42,166
给大家简单的介绍了

161
00:04:42,166 --> 00:04:44,633
V3 呢主要是增加了一个频率的

162
00:04:45,500 --> 00:04:47,700
还有多了一个 MXU

163
00:04:52,066 --> 00:04:53,233
来到了第二个内容

164
00:04:55,700 --> 00:04:58,066
或者我们的集群互联的时候呢

165
00:04:58,066 --> 00:05:00,933
现在搞大模型大家都在知道集群了

166
00:05:02,666 --> 00:05:05,233
你给大家说训练 AI 用集群呢

167
00:05:06,600 --> 00:05:08,666
或者觉得我一张卡都可以玩的

168
00:05:08,666 --> 00:05:09,766
为什么要用集群呢

169
00:05:09,766 --> 00:05:12,533
所以我们做一些简单的概念的澄清

170
00:05:12,800 --> 00:05:13,766
涉及到集群呢

171
00:05:13,766 --> 00:05:15,266
我们在训练过程当中呢

172
00:05:15,266 --> 00:05:17,633
就需要一个分布式的架构

173
00:05:20,000 --> 00:05:21,400
就 PS 架构啊

174
00:05:23,566 --> 00:05:24,766
一款 CPU 里面呢

175
00:05:29,366 --> 00:05:31,766
那在整体我们的训练的过程当中呢

176
00:05:31,766 --> 00:05:33,233
其实首先呢

177
00:05:36,300 --> 00:05:37,800
或者我们的梯度

178
00:05:37,800 --> 00:05:38,900
那算完这个之后呢

179
00:05:38,900 --> 00:05:39,700
我们的梯度啊

180
00:05:39,700 --> 00:05:41,100
可能每张卡都会算一个

181
00:05:41,100 --> 00:05:43,400
于是呢我们的梯度需要进行聚合

182
00:05:43,400 --> 00:05:44,866
把每一块卡

183
00:05:44,866 --> 00:05:48,166
每块 NPU 每块 GPU 的卡呢进行一个聚合

184
00:05:49,300 --> 00:05:52,066
绿色的再分发过来给每一张卡

185
00:05:52,066 --> 00:05:53,266
这么一个过程

186
00:05:53,266 --> 00:05:54,166
那这个过程呢

187
00:05:54,166 --> 00:05:56,566
我们可以用同步的方式

188
00:05:56,566 --> 00:05:58,666
也可以用异步的方式

189
00:05:58,666 --> 00:06:00,033
进型同步

190
00:06:02,400 --> 00:06:04,966
你都需要对我们的数据进行同步的

191
00:06:04,966 --> 00:06:08,666
因为每一张卡训练的参数是不一样的

192
00:06:14,900 --> 00:06:16,366
如果大家没搞明白的

193
00:06:20,266 --> 00:06:23,133
现在呢我们真正来到了第三个内容了

194
00:06:28,066 --> 00:06:30,133
所以我们简称叫超算的形态了

195
00:06:34,200 --> 00:06:34,700
打开

196
00:06:34,700 --> 00:06:38,100
讲讲这个图里面的具体的细节了

197
00:06:38,200 --> 00:06:40,100
首先呢我们看一下啊

198
00:06:42,300 --> 00:06:44,566
现在呢 Pod 就是 super computer

199
00:06:44,566 --> 00:06:48,166
ML super computer machine learning 超级计算

200
00:06:48,166 --> 00:06:49,833
简称一个 Pod 的形态

201
00:06:53,200 --> 00:06:55,600
变成一个 AI 的集群

202
00:06:55,600 --> 00:06:57,100
那在讲集群之前呢

203
00:06:57,100 --> 00:06:58,400
最小的一个单位呢

204
00:06:58,400 --> 00:07:00,400
肯定是我们一块基板

205
00:07:00,400 --> 00:07:02,000
那 TPUB2 的基板呢

206
00:07:02,000 --> 00:07:03,566
就像下面这个图

207
00:07:03,566 --> 00:07:05,966
我们简单的看看每一个内容

208
00:07:07,100 --> 00:07:11,500
有四个左上左下右上右下四个 a

209
00:07:11,500 --> 00:07:13,966
这个四个 TPUV2 的芯片里面

210
00:07:13,966 --> 00:07:14,833
芯片在里面

211
00:07:17,400 --> 00:07:18,566
上面只是散热板的

212
00:07:18,566 --> 00:07:19,366
没有风扇的

213
00:07:19,366 --> 00:07:21,433
大家不要觉得这里面藏了个风扇了

214
00:07:22,600 --> 00:07:23,366
那第二个呢

215
00:07:23,366 --> 00:07:24,933
我们看看有个 b

216
00:07:28,666 --> 00:07:31,966
当然呢我们还有一个 c 英特音调的

217
00:07:31,966 --> 00:07:33,633
OPA 的电脑的接口

218
00:07:35,200 --> 00:07:36,766
我们后面会澄清一下

219
00:07:36,766 --> 00:07:39,133
接着呢我们有一个电源的电路板

220
00:07:42,000 --> 00:07:44,900
的形态刚才讲到有两个概念呢

221
00:07:44,900 --> 00:07:46,766
一个就是 blue link

222
00:07:50,066 --> 00:07:53,333
所以他推出了一个网络协议呢

223
00:07:53,366 --> 00:07:54,033
名字呢

224
00:07:57,800 --> 00:07:58,900
很简单吧

225
00:07:58,900 --> 00:07:59,400
然后呢

226
00:07:59,400 --> 00:08:02,700
每个 Socket 提供 25GM 每秒的一个带宽

227
00:08:02,700 --> 00:08:03,600
它主要呢

228
00:08:03,600 --> 00:08:06,300
是提供 NPU 或者 TPU

229
00:08:06,300 --> 00:08:09,500
跟 TPU 之间的一个网络的互联

230
00:08:09,500 --> 00:08:10,100
那另外呢

231
00:08:10,100 --> 00:08:11,366
就是 OPA 啊

232
00:08:11,366 --> 00:08:14,633
英特尔提供的一个互联的架构

233
00:08:15,600 --> 00:08:17,866
类似的网络架构来对应的

234
00:08:17,866 --> 00:08:18,833
c 里面呢

235
00:08:21,900 --> 00:08:25,300
里面呢我们看一看这些 TPUV2 呢

236
00:08:25,300 --> 00:08:26,866
组成一个 supercomputer

237
00:08:26,866 --> 00:08:28,733
也就是一个 pod 形态呢

238
00:08:31,766 --> 00:08:33,566
然后形成呢右边的这个图

239
00:08:41,566 --> 00:08:45,566
那左边的 a 和 d 呢主要是 CPU 的集群

240
00:08:45,566 --> 00:08:48,866
那我们再换后面去讲的 CPU 呢

241
00:08:48,866 --> 00:08:52,433
主要是管理 TPU 怎么去运作的

242
00:08:52,800 --> 00:08:54,000
现在我们来到了

243
00:08:56,200 --> 00:08:59,200
整体的版底呢刷成了蓝色

244
00:08:59,200 --> 00:09:02,966
区别于 TPU V2 的绿色

245
00:09:04,966 --> 00:09:07,066
如果是黑色可能会更帅

246
00:09:10,600 --> 00:09:15,000
上面呢有 4 个液冷的铜的散热管

247
00:09:15,000 --> 00:09:17,400
那 b 呢同样是 Bluelink

248
00:09:17,400 --> 00:09:20,700
c 呢同样对应的是 OPA 的电缆

249
00:09:20,700 --> 00:09:21,600
d 跟刚才一样呢

250
00:09:21,600 --> 00:09:24,500
都是一个电路板的一个电源接口

251
00:09:24,500 --> 00:09:26,100
这是两种网络的配置形态

252
00:09:26,100 --> 00:09:27,266
没有太大区别

253
00:09:27,266 --> 00:09:30,466
所以我们说 V3 呢是 V2 的增强版

254
00:09:35,366 --> 00:09:38,433
也就是 1K 的芯片组成

255
00:09:40,400 --> 00:09:42,300
大了非常的多

256
00:09:42,300 --> 00:09:44,500
然后里面呢密密麻麻的铜板

257
00:09:44,500 --> 00:09:49,100
还有密密麻麻的光纤电缆

258
00:09:49,666 --> 00:09:51,633
接着呢我们对比一下哦

259
00:09:56,100 --> 00:10:00,000
右边的 V3 的形态呢是 1024 块卡

260
00:10:00,000 --> 00:10:02,566
那大家呢长得差不多

261
00:10:02,566 --> 00:10:03,633
最大的区别呢

262
00:10:06,900 --> 00:10:10,500
组成的 pod 的形态算力也不一样

263
00:10:11,566 --> 00:10:16,133
可能看到 TPUV2 的 pod 呢是 11.5 petaflops

264
00:10:18,000 --> 00:10:20,066
整体提供的是 100 petaflops

265
00:10:30,466 --> 00:10:32,966
或者一个 supercomputer 的形态

266
00:10:32,966 --> 00:10:35,566
确实整体非常的超前

267
00:10:35,566 --> 00:10:40,233
而英伟达当时候还没有卖非常大量

268
00:10:44,266 --> 00:10:46,466
那整体的架构图也是比较明显的

269
00:10:46,466 --> 00:10:48,033
我们的 AI 框架呢

270
00:10:49,766 --> 00:10:51,166
到我们的 TPU host

271
00:10:53,000 --> 00:10:54,766
CPU 呢去控制 TPU

272
00:10:54,766 --> 00:10:58,166
去真正的互联的运作和执行

273
00:10:58,166 --> 00:11:00,233
当时还没有大模型谷歌

274
00:11:02,900 --> 00:11:06,266
还是非常的值得大家去学习的

275
00:11:06,266 --> 00:11:06,933
那这里面呢

276
00:11:08,966 --> 00:11:10,066
最重要的改进啊

277
00:11:10,066 --> 00:11:11,533
在整个 pod 形态里面呢

278
00:11:12,900 --> 00:11:14,100
就是 ICI

279
00:11:14,266 --> 00:11:17,066
谷歌除了提供 TPU 这块芯片呢

280
00:11:17,066 --> 00:11:19,066
我觉得里面很有意思一点呢

281
00:11:19,066 --> 00:11:21,266
就是利用了交换机

282
00:11:21,266 --> 00:11:22,366
提供了一个虚拟电路

283
00:11:22,366 --> 00:11:25,466
和无死锁的电路由的功能啊

284
00:11:25,766 --> 00:11:26,133
上了

285
00:11:28,966 --> 00:11:32,366
构建出整个 TPU V2 的集群里面呢

286
00:11:34,300 --> 00:11:38,266
提供一个非常夸张的一个平分的带宽

287
00:11:39,500 --> 00:11:41,266
传统的集群的主网

288
00:11:41,266 --> 00:11:44,533
或者同年代的一个 GPU 的集群的主网

289
00:11:46,766 --> 00:11:48,033
交换机的成本

290
00:11:54,766 --> 00:11:55,766
那这个内容呢

291
00:11:55,766 --> 00:11:58,666
我们将会在后面再深入的去展开

292
00:12:01,100 --> 00:12:03,166
或者谷歌的 super pod 呢

293
00:12:03,500 --> 00:12:05,900
非常的先进那

294
00:12:09,900 --> 00:12:11,966
是一个 2D torus 的方式

295
00:12:11,966 --> 00:12:13,466
刚才我们简单的讲到了

296
00:12:17,400 --> 00:12:19,200
因为它中间的 BUB 少了嘛

297
00:12:19,200 --> 00:12:20,666
但是呢在谷歌的 TPU

298
00:12:20,666 --> 00:12:23,066
board 和整个互联的形态里面呢

299
00:12:23,066 --> 00:12:24,466
同部的训练的方式呢

300
00:12:25,666 --> 00:12:27,533
一部的 SGD 的训练的方式

301
00:12:29,866 --> 00:12:33,433
允许节点之间呢进行互相的通讯呢

302
00:12:34,800 --> 00:12:36,100
all reduce 的方式呢

303
00:12:36,100 --> 00:12:38,366
就可以得到一致的权重的解决了

304
00:12:38,366 --> 00:12:39,433
异步训练的时候呢

305
00:12:40,400 --> 00:12:41,100
服务器

306
00:12:46,966 --> 00:12:47,833
这八块卡呢

307
00:12:53,200 --> 00:12:54,900
他们之间的互相的通讯呢

308
00:12:54,900 --> 00:12:57,500
其实带来的成本会非常大

309
00:12:57,500 --> 00:12:58,666
那谷歌 TPU 呢

310
00:12:58,666 --> 00:13:00,933
就提出了一个 2D torus 的结果呢

311
00:13:06,700 --> 00:13:10,666
如果大家对这个 2D 或者 2D torus 的结构呢

312
00:13:10,666 --> 00:13:13,233
有兴趣也可以查阅更详细的资料

313
00:13:14,500 --> 00:13:16,200
现在我们来到了第四个内容

314
00:13:18,300 --> 00:13:20,900
主要看看它整个 Pod 呢有哪些内容啊

315
00:13:20,900 --> 00:13:22,766
这里面呢有 a b c d 啊

316
00:13:22,766 --> 00:13:24,033
标了不同的颜色

317
00:13:26,400 --> 00:13:29,666
那 b 和 c 呢就是 TPU 的机架

318
00:13:29,866 --> 00:13:30,733
整体看一下我们

319
00:13:33,300 --> 00:13:35,666
一个蓝色的跟红色的分别呢

320
00:13:35,666 --> 00:13:36,466
对应的是我们

321
00:13:36,466 --> 00:13:37,933
的电源的管理系统

322
00:13:40,100 --> 00:13:41,900
接着我们看一下虚框

323
00:13:41,900 --> 00:13:43,666
绿色的绿色的这个模块呢

324
00:13:49,400 --> 00:13:50,366
所以上面呢

325
00:13:50,366 --> 00:13:54,233
走的更多的是我们的网络的模块

326
00:13:57,100 --> 00:14:00,500
其实我们看不到太多的存储的模块

327
00:14:00,600 --> 00:14:02,100
这里面呢怀疑它的存储模块呢

328
00:14:04,000 --> 00:14:05,066
或者数据中心呢

329
00:14:05,066 --> 00:14:08,066
去把网络模型一些数据呢传过来

330
00:14:08,066 --> 00:14:09,733
进行一个训练的

331
00:14:13,066 --> 00:14:14,666
没有公布太多的图片

332
00:14:14,666 --> 00:14:16,633
而我终于呢在网上呢

333
00:14:19,400 --> 00:14:20,866
大家可能会有一个疑问呢

334
00:14:20,866 --> 00:14:22,966
为什么我们的线要密密麻麻

335
00:14:22,966 --> 00:14:25,466
为什么我们的 CPU 呢要挂在两边呢

336
00:14:25,466 --> 00:14:28,233
其实呢主要的原因是因为 bluelink

337
00:14:29,866 --> 00:14:32,933
我们的电缆呢光纤呢长度不能太长

338
00:14:34,800 --> 00:14:38,566
而 CPU 呢分布在两边的原因

339
00:14:38,866 --> 00:14:39,033
接着呢

340
00:14:42,466 --> 00:14:43,633
非常的有意思啊

341
00:14:44,200 --> 00:14:49,800
从小的 32 个 core 到 128 个 core 到 512 个 core

342
00:14:49,800 --> 00:14:52,900
到最后的 1020 个 core 的组成呢

343
00:14:59,500 --> 00:15:02,366
谷歌就说他在谷歌 TPU v2 v3 的说

344
00:15:02,366 --> 00:15:03,266
pod 里面呢

345
00:15:03,266 --> 00:15:06,766
为谷歌非常多的服务或者他的应用呢

346
00:15:06,766 --> 00:15:08,733
提供了大量的算力

347
00:00:06,600 --> 00:00:08,900
我是心里藏着小星星

348
00:00:13,966 --> 00:00:16,133
谷歌 TPU V3 这个系列里面

349
00:00:27,300 --> 00:00:28,366
里面所讲的内容

350
00:00:30,400 --> 00:00:31,900
讲的非常多了

351
00:00:47,100 --> 00:00:48,400
和最核心的 Tensor Core

352
00:01:01,800 --> 00:01:03,866
AI 芯片的架构的思考

353
00:01:17,200 --> 00:01:20,266
还有 TPU1 提出的脉动阵列块

354
00:01:23,400 --> 00:01:24,700
第一款训练卡

355
00:01:29,200 --> 00:01:30,200
那第一款训练卡呢

356
00:01:51,200 --> 00:01:54,000
谷歌 TPUV4 的一个超级互联

357
00:02:07,100 --> 00:02:10,000
谷歌 TPUV3 的一个简单的介绍

358
00:02:15,200 --> 00:02:16,766
我们将会在后面呢

359
00:02:20,366 --> 00:02:22,133
为什么叫增强版

360
00:02:30,000 --> 00:02:32,866
那这个提升呢主要是来自于两个方面

361
00:02:35,200 --> 00:02:36,700
这里的数量翻倍了

362
00:02:44,100 --> 00:02:46,600
那现在我们看看整个谷歌 TPU 系列

363
00:02:56,200 --> 00:02:58,200
第一个呢就是 pocess node

364
00:03:03,000 --> 00:03:04,366
推理卡要求没那么高

365
00:03:04,366 --> 00:03:05,966
28 纳米就行了

366
00:03:09,600 --> 00:03:11,800
它没有本质性的改变

367
00:03:36,200 --> 00:03:38,966
整体的峰值算力呢是翻了一番的

368
00:03:43,200 --> 00:03:44,266
可以看到啊

369
00:03:46,600 --> 00:03:49,700
V3 呢翻了 3 倍哦

370
00:03:55,800 --> 00:03:56,366
左边呢

371
00:04:14,000 --> 00:04:14,900
刚才讲到了

372
00:04:22,900 --> 00:04:25,600
然后另外的话就是 HBM 也就大了嘛

373
00:04:33,100 --> 00:04:36,266
我们看一下 TPUV2 的第一款训练卡的

374
00:04:44,600 --> 00:04:45,500
还有带宽呢

375
00:04:53,200 --> 00:04:54,566
才正式进入到我们的 POD

376
00:05:00,900 --> 00:05:02,666
但是回到 18 年的时候啊

377
00:05:05,200 --> 00:05:06,600
其实很多人是不相信的

378
00:05:17,600 --> 00:05:20,000
然后呢当时叫做参数服务器

379
00:05:33,200 --> 00:05:36,300
我们就需要正向的训一个计算的损失

380
00:06:23,100 --> 00:06:25,066
今天 ZOMI 的语速呢有点快

381
00:06:30,100 --> 00:06:31,466
那这张图呢就非常炫酷

382
00:06:49,800 --> 00:06:53,200
我把非常多的卡集中在一起

383
00:07:14,800 --> 00:07:17,400
哦还有一个散热板

384
00:07:21,400 --> 00:07:22,600
是不可能的

385
00:07:33,600 --> 00:07:35,200
那 b 和 c 你听不懂没关系

386
00:07:39,100 --> 00:07:42,000
最后还支持另外两种网络的配置

387
00:07:47,700 --> 00:07:50,066
IBM 是一个蓝色巨人嘛

388
00:07:54,000 --> 00:07:56,300
叫做 blue link

389
00:08:14,600 --> 00:08:15,600
和 InfiniBand

390
00:08:18,800 --> 00:08:20,066
连接上我们的 CPU

391
00:08:28,700 --> 00:08:31,766
最多能够做一个 256 个 chip 进行组成

392
00:09:38,400 --> 00:09:40,400
所以它它的整个机型规模呢

393
00:09:51,600 --> 00:09:56,000
左边的 V2 的 Pod 的形态呢是 256 块卡

394
00:10:40,200 --> 00:10:41,700
或者一个集群中心

395
00:11:00,200 --> 00:11:02,900
提出了这么经典这么有意思的集群

396
00:11:06,900 --> 00:11:08,966
我们看一下谷歌 GPU 啊

397
00:11:11,500 --> 00:11:12,900
增加了核间互联

398
00:11:26,100 --> 00:11:28,966
刚才讲到了一个核间互联的结构呢

399
00:11:48,000 --> 00:11:49,700
还有使得我们整个集群

400
00:12:27,500 --> 00:12:29,866
因为呢谷歌的 Pod 的形态呢

401
00:13:00,900 --> 00:13:04,166
非常的惊艳超前

402
00:13:24,000 --> 00:13:26,400
a 和 d 呢就是 CPU 的机架

403
00:13:30,700 --> 00:13:33,300
这里面呢有上面的和下面的

404
00:13:37,900 --> 00:13:40,100
和具体的电源的接口

405
00:13:43,666 --> 00:13:46,933
就是机架式的一个网络的交换机

406
00:14:09,700 --> 00:14:11,866
那我们回顾一下谷歌 TPUV2 呢

407
00:14:16,600 --> 00:14:19,200
最多只能找到这么一组图片呢

408
00:14:32,900 --> 00:14:34,800
所以呢 NPU 分布在中间

409
00:14:39,000 --> 00:14:42,466
我们看看整个谷歌 TPUV3 的 Pod 形态啊

410
00:14:43,600 --> 00:14:44,200
是吧

411
00:00:05,966 --> 00:00:06,633
哈喽大家好

412
00:00:11,966 --> 00:00:13,966
我们回到之前鸽了一段时间的

413
00:00:16,100 --> 00:00:17,700
那右边的这个图呢

414
00:00:43,500 --> 00:00:45,200
大家都在抢到或者 GPU

415
00:03:22,766 --> 00:03:24,333
那第二个主要的内容呢

416
00:04:10,166 --> 00:04:10,933
没有铜管道

417
00:06:00,600 --> 00:06:02,400
不管你怎么做变形啊

418
00:06:11,966 --> 00:06:14,633
求均值这么一个过程

419
00:10:22,000 --> 00:10:23,866
都提供 e 级的算力了

