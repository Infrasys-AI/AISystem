1
00:00:05,666 --> 00:00:06,433
哈喽大家好

2
00:00:22,400 --> 00:00:24,766
直接延续到我们上一节的内容

3
00:00:26,200 --> 00:00:29,400
看看谷歌 TPUV4 的一个整体的 pod 的形态

4
00:00:47,100 --> 00:00:48,400
提到一个很重要的一点

5
00:00:52,000 --> 00:00:54,600
组成了一个超级计算节点 Pod

6
00:00:54,700 --> 00:00:55,466
打开这篇文章

7
00:00:58,900 --> 00:01:00,466
组成了整个 AI 技术

8
00:01:08,100 --> 00:01:09,800
可以释放到刚才呃

9
00:01:33,466 --> 00:01:35,366
那出现问题主要是并行的问题

10
00:01:39,100 --> 00:01:40,400
整体的成功案例呢

11
00:01:55,966 --> 00:01:58,133
然后在谷歌 GPT4 里面呢

12
00:02:00,400 --> 00:02:01,900
其实现在来说呢

13
00:02:01,900 --> 00:02:04,400
千亿应该是效果最好的

14
00:02:08,700 --> 00:02:12,300
我们看看谷歌 TPUV 4 的一个拓扑结构啊

15
00:02:16,100 --> 00:02:18,700
所以我们从右边的这个都可以看到啊

16
00:02:45,600 --> 00:02:46,100
然后呢

17
00:03:20,366 --> 00:03:22,233
形成一个整体的闭环

18
00:03:29,600 --> 00:03:31,666
啊上面的这段文字

19
00:03:32,966 --> 00:03:35,066
其实就是谷歌 TPU V4 的

20
00:04:26,500 --> 00:04:28,100
而且提供高的带宽

21
00:04:29,266 --> 00:04:30,266
而光互联呢

22
00:04:32,366 --> 00:04:35,566
就成为了一种首选的方案呢

23
00:04:38,666 --> 00:04:42,133
刚才讲到了 4*4*4 组成的一组 slice

24
00:05:29,366 --> 00:05:31,833
一共有 16 个 TPU

25
00:05:37,800 --> 00:05:39,766
连接到 OCS 上面了

26
00:05:54,566 --> 00:05:55,233
去讲讲

27
00:06:11,400 --> 00:06:13,000
我想问一下您

28
00:06:22,500 --> 00:06:25,766
对弹幕里面的吴彦祖你说对了

29
00:06:32,366 --> 00:06:33,166
反过来了

30
00:06:41,000 --> 00:06:42,566
第四代的 NV link 呢

31
00:07:05,300 --> 00:07:06,466
而上面的 trous 呢

32
00:07:11,266 --> 00:07:13,433
对比起谷歌的 OCS 的方案呢

33
00:07:24,566 --> 00:07:27,733
需要部署 4096 个 GPU 的集群呢

34
00:07:42,800 --> 00:07:45,300
我们经常在部署网络模型的时候呢

35
00:07:53,366 --> 00:07:54,533
一层是不行的

36
00:08:05,866 --> 00:08:07,033
还是很高的

37
00:08:44,966 --> 00:08:48,266
那整体看一下它整个 TPUV4 的一个测评啊

38
00:08:48,266 --> 00:08:51,266
在使用光互联或者光交换机的时候呢

39
00:09:11,666 --> 00:09:14,633
其实刚才讲到了很多 OCS

40
00:09:23,600 --> 00:09:26,500
又是发表了另外一篇独立的论文的

41
00:09:29,566 --> 00:09:31,466
这个光路由开关芯片呢

42
00:09:49,900 --> 00:09:52,500
反射竞争力的一个整体的技术啊

43
00:09:52,500 --> 00:09:54,100
为什么叫反射镜阵列

44
00:10:07,666 --> 00:10:08,333
那下面呢

45
00:10:18,100 --> 00:10:20,666
是下面的左下角的这个图

46
00:10:20,666 --> 00:10:23,733
我们的反射镜阵列的一个封装的照片

47
00:10:42,200 --> 00:10:43,400
我们的每个小点点

48
00:10:54,100 --> 00:10:56,066
在两个方向上面去旋转

49
00:11:14,666 --> 00:11:17,566
我们刚才讲到的 2D 的 MEMS 呢

50
00:11:17,566 --> 00:11:19,033
是在这个位置啊

51
00:11:22,800 --> 00:11:25,766
我们可以看到有另外一个重叠的光

52
00:11:28,200 --> 00:11:30,200
我们带内的光的通讯信号呢

53
00:11:40,166 --> 00:11:41,633
为什么叫做 OCS 呢

54
00:11:45,900 --> 00:11:48,266
但是呢它需要把光转换到电

55
00:11:58,666 --> 00:12:00,833
从而节省了非常多的电呢

56
00:12:04,300 --> 00:12:06,200
时延才是最核心的

57
00:12:15,400 --> 00:12:17,366
第一个呢是光纤的准直器

58
00:12:17,366 --> 00:12:20,066
第二个呢是我们的 camera 相机的模块

59
00:12:20,066 --> 00:12:22,666
第三个呢是我们的封装的 MEMS

60
00:12:25,666 --> 00:12:28,433
当然还有很多各种各样的外围电路了

61
00:12:31,666 --> 00:12:32,666
电源的风扇呢

62
00:12:32,666 --> 00:12:35,666
还有高压驱风器的一个整个后备箱

63
00:12:35,666 --> 00:12:37,533
如果做硬件的吴彦祖呢

64
00:12:40,966 --> 00:12:43,133
接着呢我们来到了这一个内容呢

65
00:13:00,866 --> 00:13:02,433
提供一个低网络的代价

66
00:13:06,400 --> 00:13:07,300
有了 OCS 呢

67
00:13:29,200 --> 00:13:30,500
我们做了系统优化的

68
00:13:53,400 --> 00:13:55,600
其实啊已经很成熟了

69
00:14:00,166 --> 00:14:02,333
里面有非常非常多的坑

70
00:14:10,166 --> 00:14:12,033
整个 3D Torus 的一个环面

71
00:14:21,166 --> 00:14:22,333
就变得非常复杂

72
00:14:24,400 --> 00:14:25,700
基本上就是全定制化

73
00:14:33,100 --> 00:14:34,600
就是负载均衡的问题

74
00:14:37,300 --> 00:14:38,000
画面这种呢

75
00:14:47,666 --> 00:14:48,933
数量还是比较多

76
00:14:53,266 --> 00:14:54,733
使得我们的网络呢

77
00:14:59,800 --> 00:14:59,900
后呢

78
00:15:09,100 --> 00:15:09,900
虽然是 21 年

79
00:15:13,500 --> 00:15:14,266
那谷歌呢

80
00:15:14,266 --> 00:15:15,733
是坚持 32GB

81
00:15:18,466 --> 00:15:21,233
是比晶片的一个迭代速度会更快

82
00:15:24,200 --> 00:15:25,766
它确实比较慢

83
00:15:36,800 --> 00:15:39,500
单芯片的 FLOPS 变得没有那么香了

84
00:15:48,300 --> 00:15:50,200
第二点我们可以看到谷歌 TPUV4 呢

85
00:15:50,200 --> 00:15:53,500
是算法跟芯片协同的去设计的

86
00:15:55,600 --> 00:15:57,200
里面呢就提供了一个 SE

87
00:15:57,200 --> 00:16:00,866
也就是我们 sparse core 稀疏的矩阵的支持

88
00:16:08,400 --> 00:16:10,066
但是 Benchmark 之外啊

89
00:16:10,066 --> 00:16:12,433
其实我们看不到太多

90
00:16:14,200 --> 00:16:16,966
其实也很难直观的去了解到

91
00:16:18,566 --> 00:16:19,833
做了什么优化

92
00:16:22,100 --> 00:16:23,866
也没有买不到外面

93
00:16:28,900 --> 00:16:29,300
这个呢

94
00:16:29,300 --> 00:16:31,500
是希望谷歌可以更多地开源开放出来

95
00:16:31,500 --> 00:16:33,466
让大家去了解和研究

96
00:00:10,366 --> 00:00:13,366
我们接回上一节课里面讲到的

97
00:00:13,366 --> 00:00:14,633
谷歌 TPU4

98
00:00:17,800 --> 00:00:18,300
那今天呢

99
00:00:18,300 --> 00:00:20,300
我们直接跳过之前的内容

100
00:00:20,300 --> 00:00:22,400
或者不讲之前的一些概况了

101
00:00:35,866 --> 00:00:37,666
虽然它剖出来的图并不多

102
00:00:37,666 --> 00:00:40,066
但是这张图我们可以看到非常震撼的

103
00:00:40,066 --> 00:00:41,866
机器集群也是非常的多

104
00:00:41,866 --> 00:00:44,633
那我们现在整体来看看谷歌 TPUV4

105
00:00:48,400 --> 00:00:52,000
就是光互联可重配置的这种方式

106
00:00:56,066 --> 00:00:58,933
它说是由 4096 个 TPU V4 的单芯片

107
00:01:00,466 --> 00:01:01,366
那注意了

108
00:01:09,800 --> 00:01:13,766
之前讲到了 1.12 的 EFLOPS 的 BF16 的算力

109
00:01:14,800 --> 00:01:17,966
超过现在全球最快的超算了

110
00:01:17,966 --> 00:01:19,933
这种呢确实没有办法跟超算比

111
00:01:21,300 --> 00:01:22,966
那很关键的一个因素呢

112
00:01:22,966 --> 00:01:26,933
就是通过光电的路由交换机叫做 OCS

113
00:01:29,300 --> 00:01:30,766
避免出现问题的时候呢

114
00:01:32,400 --> 00:01:33,466
提高性能

115
00:01:36,500 --> 00:01:39,100
并行的一个集群的配置

116
00:01:45,700 --> 00:01:47,866
效果说实话真一般般的

117
00:01:47,900 --> 00:01:50,366
你干嘛哈哈

118
00:01:51,466 --> 00:01:53,533
Palm 跟 palm2 啊

119
00:02:05,400 --> 00:02:07,966
还有我们的 GPT4 模型

120
00:02:07,966 --> 00:02:08,733
先不谈为二了

121
00:02:12,300 --> 00:02:14,900
整个拓扑结构呢是 3D torus

122
00:02:14,900 --> 00:02:16,100
也就是 3D 环面

123
00:02:22,100 --> 00:02:23,200
那组成的方式呢

124
00:02:23,200 --> 00:02:25,466
这里面举了一个简单的例子

125
00:02:25,466 --> 00:02:26,433
由 4 乘以 4

126
00:02:30,400 --> 00:02:34,200
也就是每个节点呢就是一个芯片

127
00:02:35,366 --> 00:02:37,333
一个 TPUV4 的芯片里面呢

128
00:02:39,100 --> 00:02:42,300
每个 Tensor Core 里面呢有 4 个 MXU 脉动阵列

129
00:02:42,300 --> 00:02:44,500
整体形成的一个立方体结构

130
00:02:44,500 --> 00:02:45,600
我们叫做 cube

131
00:02:46,100 --> 00:02:49,700
再把这一 4 乘以 4 乘以 4 的一个 cube 呢

132
00:02:50,300 --> 00:02:53,066
谷歌新研发出来的光电互联交换机

133
00:02:53,066 --> 00:02:54,433
连接在一起

134
00:02:57,300 --> 00:02:59,500
也就是我们的 3D torus 结构

135
00:02:59,500 --> 00:03:00,300
每个节点呢

136
00:03:00,300 --> 00:03:04,066
连接到网络的六个相邻的一个节点呢

137
00:03:04,066 --> 00:03:05,033
为什么说六个呢

138
00:03:07,000 --> 00:03:08,866
上下左右还有前后啊

139
00:03:08,866 --> 00:03:10,133
那你看第一个呢

140
00:03:11,300 --> 00:03:13,166
它的前面是一个环嘛

141
00:03:13,166 --> 00:03:16,033
它会连接到最后一个这种方式

142
00:03:18,600 --> 00:03:20,366
在 XYZ 三个维度呢里面

143
00:03:22,200 --> 00:03:23,966
高度的环面互联方式呢

144
00:03:23,966 --> 00:03:27,566
是我们叫做 3D torus 的一个拓扑结构了

145
00:03:27,900 --> 00:03:29,600
现在呢我们仔细的看一看

146
00:03:36,866 --> 00:03:40,433
非常多的一个 TPU 连接在一起

147
00:03:40,666 --> 00:03:41,733
距离比较近的 TPU 呢

148
00:03:43,466 --> 00:03:45,766
并不是完全都用光互联的

149
00:03:45,766 --> 00:03:47,366
比较近的会用 ICI

150
00:03:47,366 --> 00:03:49,133
也就是我们的电互联

151
00:03:49,366 --> 00:03:51,166
通过电缆的方式呢进行连接

152
00:03:51,166 --> 00:03:52,533
而距离比较远啊

153
00:03:55,166 --> 00:03:57,533
就是使用光互联的方式

154
00:04:01,000 --> 00:04:01,166
谷歌

155
00:04:01,166 --> 00:04:04,333
为什么提出用光交换器呢叫 OCS 呢

156
00:04:06,466 --> 00:04:08,566
我们知道在整个集群里面呢

157
00:04:08,566 --> 00:04:13,166
可能呃算力的利用率呢就 40%到 50%

158
00:04:13,300 --> 00:04:15,900
可能经过极致性能优化呢到 70%

159
00:04:15,900 --> 00:04:17,800
那剩下的时间都在干嘛呢

160
00:04:17,800 --> 00:04:19,300
都在做通讯

161
00:04:19,300 --> 00:04:21,166
是为了避免计算

162
00:04:21,166 --> 00:04:23,633
等待整个集群的通讯

163
00:04:24,100 --> 00:04:26,500
必须要确保芯片之间必须互联

164
00:04:28,100 --> 00:04:29,266
低的延迟

165
00:04:30,266 --> 00:04:32,366
对于物理距离比较远的芯片呢

166
00:04:35,566 --> 00:04:38,666
光交换机呢是由 64 颗 TPU

167
00:04:42,100 --> 00:04:44,300
之间进行一个互联

168
00:04:44,300 --> 00:04:45,900
实现了 Pod 形态里面

169
00:04:45,900 --> 00:04:48,766
整个 slice 呢全光电互联

170
00:04:48,766 --> 00:04:51,566
也就是 64 个 TPU

171
00:04:51,600 --> 00:04:55,600
从而不断的组成变成我们的 4096

172
00:04:55,766 --> 00:04:58,533
弹幕里面的吴彦祖呢就会想问哎

173
00:05:01,166 --> 00:05:03,566
那就把 pod 跟 pod 之间

174
00:05:03,566 --> 00:05:06,766
再通过二层的光互联的交换机

175
00:05:06,766 --> 00:05:08,733
进行一个互联就好了

176
00:05:09,266 --> 00:05:11,633
现在我们简化刚才的一个图

177
00:05:15,566 --> 00:05:17,933
组成为了使得我们刚才讲到了

178
00:05:20,300 --> 00:05:22,300
V4 的一个 Cube 核

179
00:05:22,300 --> 00:05:24,300
要实现 6 面的链接呢

180
00:05:24,300 --> 00:05:27,166
每一个面呢需要 16 条链路

181
00:05:27,166 --> 00:05:29,366
因为一个面呢它是 4 乘以 4

182
00:05:32,066 --> 00:05:34,333
每个 TPU 呢需要进行一个互联

183
00:05:34,800 --> 00:05:37,800
每一个 cube 呢一共有 96 条光链路

184
00:05:39,766 --> 00:05:43,233
为了提供我们整个 3D 环面的一个链接

185
00:05:44,300 --> 00:05:47,700
我们必须要连接到相同的 OCS

186
00:05:47,700 --> 00:05:49,600
如果你连接到不同的 OCS

187
00:05:49,600 --> 00:05:51,600
上面的问题就严重了

188
00:05:51,600 --> 00:05:53,600
我们将会在大模型里面的 AI 集群

189
00:05:53,600 --> 00:05:54,566
里面的网络

190
00:05:55,200 --> 00:05:58,366
为什么都要连接到同一个 OCS 上面

191
00:05:58,366 --> 00:06:01,133
或者叫做同一个交换机上面

192
00:06:01,400 --> 00:06:01,800
实际上呢

193
00:06:01,800 --> 00:06:05,500
每个 cube 呢需要连接到 48 个 OCS 上面了

194
00:06:05,500 --> 00:06:09,800
而 48 个 OCS 呢来自于 64 个 cube 的 48 对光缆

195
00:06:10,366 --> 00:06:11,433
ZOMI 老师你好啊

196
00:06:13,000 --> 00:06:17,500
一个 AI 集群我要买 4096 个 TPUV4

197
00:06:17,500 --> 00:06:20,000
但我不是要买很多个 OCS

198
00:06:20,000 --> 00:06:21,800
光互联交换机吗

199
00:06:25,766 --> 00:06:28,666
比呢比的就是钞能力了

200
00:06:28,666 --> 00:06:31,933
谁有钱谁就能组更大的集群嘛

201
00:06:33,166 --> 00:06:34,166
因为现在 AI 集群

202
00:06:34,166 --> 00:06:37,133
我们看下对标英伟达的一个计算集群

203
00:06:42,566 --> 00:06:44,966
其实最多可以链接 32 个

204
00:06:44,966 --> 00:06:48,233
共 256 颗 H100 啊

205
00:06:48,266 --> 00:06:50,433
并且能够实现呢每个 GPU 哦

206
00:06:52,200 --> 00:06:55,466
实现 900GB/s 的一个互联的带宽

207
00:06:55,466 --> 00:06:56,733
我们可以看到啊

208
00:06:57,000 --> 00:06:58,200
下面的这个图呢

209
00:06:58,200 --> 00:07:00,900
NV 的每个机架一共有四台 DGX

210
00:07:00,900 --> 00:07:02,200
一共 32 颗

211
00:07:02,200 --> 00:07:05,300
H100 机架的另外呢都需要光纤进行连接

212
00:07:06,466 --> 00:07:08,366
就是上面的这个小模块呢

213
00:07:08,366 --> 00:07:11,133
是我们对应的交换机

214
00:07:13,466 --> 00:07:15,866
英伟达的每个机架的算力密度呢

215
00:07:15,866 --> 00:07:17,866
可能相对更小一点点

216
00:07:17,866 --> 00:07:20,066
而且需要更多的收发激光器

217
00:07:20,066 --> 00:07:21,833
和光纤的线路

218
00:07:23,566 --> 00:07:24,566
如果英伟达呢

219
00:07:27,700 --> 00:07:30,100
就必须要切换成为更多的 Superpod

220
00:07:30,100 --> 00:07:33,000
因为刚才的一个 Superpod 一共是 256 码

221
00:07:33,266 --> 00:07:34,633
使用 nvswitch 的第四代

222
00:07:36,466 --> 00:07:40,133
就必须要切分到更多的一个 Superpod

223
00:07:42,600 --> 00:07:42,800
所以

224
00:07:45,300 --> 00:07:47,666
就会听到各种的 CIos

225
00:07:47,666 --> 00:07:47,933
啊

226
00:07:49,666 --> 00:07:50,933
各种网络的 top

227
00:07:50,966 --> 00:07:53,366
中间呢完成多层的一个交换呢

228
00:07:54,500 --> 00:07:55,366
整个集群内呢

229
00:07:55,366 --> 00:07:59,533
一共需要采购 568 个 Infiniband 的一个交换机

230
00:07:59,700 --> 00:08:00,600
集群的建设呢

231
00:08:00,600 --> 00:08:05,866
已经占到了计算的成本的 20%到 30%

232
00:08:07,000 --> 00:08:10,200
所以说组集群呢不仅是买 GPU 的硬件

233
00:08:10,200 --> 00:08:14,200
我们还要买很多光交换机或者交换机

234
00:08:14,200 --> 00:08:16,066
各种各样的交换机

235
00:08:16,366 --> 00:08:18,766
因为谷歌 TPUV4 呢接上不同的 cube

236
00:08:18,766 --> 00:08:19,766
所以工作负载呢

237
00:08:19,766 --> 00:08:22,166
由不同规模的算力进行承担了

238
00:08:22,166 --> 00:08:24,233
我们称为切片的 slice

239
00:08:26,500 --> 00:08:28,500
我们可以组 128 256

240
00:08:28,700 --> 00:08:30,700
据说呢谷歌 TPUV4 这种结构呢

241
00:08:30,700 --> 00:08:33,600
其实更有利于做我们的科研呢

242
00:08:33,600 --> 00:08:35,800
可以更好的做一个弹性容错啊

243
00:08:35,800 --> 00:08:38,666
对我们的工程领域确实有很大的进步

244
00:08:38,666 --> 00:08:39,566
下面的一段话呢

245
00:08:39,566 --> 00:08:42,766
就谷歌 TPUV4 自己自推的一些功能特性

246
00:08:42,766 --> 00:08:44,966
点了我们就可以先跳过

247
00:08:51,566 --> 00:08:54,433
芯片的可靠率是在 99%以下

248
00:08:56,800 --> 00:08:58,500
比不使用 OCS

249
00:08:58,500 --> 00:09:00,466
不使用我们的光交换机呢

250
00:09:00,466 --> 00:09:01,233
高了 6 倍

251
00:09:06,600 --> 00:09:09,600
接下来我们来到了第三个内容

252
00:09:09,600 --> 00:09:11,666
光电路由的交换机

253
00:09:14,600 --> 00:09:16,466
我们简称光交换机

254
00:09:16,466 --> 00:09:19,066
现在我们打开一下谷歌的光交换机

255
00:09:19,066 --> 00:09:20,533
有哪些不一样的内容

256
00:09:26,500 --> 00:09:28,966
大家可以看一下我们后面的引用

257
00:09:29,200 --> 00:09:29,566
虎哥一说

258
00:09:31,466 --> 00:09:32,733
主要叫做 Palomar

259
00:09:35,266 --> 00:09:36,566
里面起了一个名字

260
00:09:36,566 --> 00:09:38,233
里面呢使用的是 MEMS

261
00:09:40,366 --> 00:09:42,733
呃简单的一个概念啊

262
00:09:42,800 --> 00:09:44,866
可能上博士课程的时候还会有

263
00:09:44,866 --> 00:09:47,366
我也是在那个时候去接触到的

264
00:09:47,366 --> 00:09:49,933
里面使用了就是微机电系统啊

265
00:09:54,100 --> 00:09:56,266
我们为什么这么复杂用到微机原理呢

266
00:09:56,266 --> 00:09:58,933
是因为微机的一个光电路由开关呢

267
00:10:02,566 --> 00:10:03,033
最重要的是

268
00:10:05,400 --> 00:10:07,666
能够提供毫秒级别的一个内容

269
00:10:08,300 --> 00:10:11,700
就是有非常多的一个 2D 的 MEMS 阵列

270
00:10:11,700 --> 00:10:13,066
下面呢我们简单的过一过

271
00:10:13,066 --> 00:10:16,233
这个 2D 的微电机的一个阵列

272
00:10:16,600 --> 00:10:18,100
刚才讲到了一个反射镜阵列就

273
00:10:25,366 --> 00:10:27,766
是一个非常大的一个芯粒

274
00:10:27,766 --> 00:10:28,733
每个芯粒里面呢

275
00:10:32,700 --> 00:10:35,266
我们可以看到有非常多的小点点

276
00:10:35,266 --> 00:10:37,666
就是我们讲到了一个 MEMS 的反射镜

277
00:10:37,666 --> 00:10:38,566
那右边呢

278
00:10:38,566 --> 00:10:42,233
就是我们整个 MEMS 的反射镜的热成像图

279
00:10:43,400 --> 00:10:45,100
把它一个热成像图放大

280
00:10:45,100 --> 00:10:46,766
每个反射镜呢有四个

281
00:10:46,766 --> 00:10:47,933
我们可以看到啊

282
00:10:51,166 --> 00:10:52,333
配方我们把配方

283
00:10:56,066 --> 00:10:56,566
所以呢

284
00:10:56,566 --> 00:11:00,466
使得我们的光可以进行一个光切换

285
00:11:00,500 --> 00:11:01,800
下面呢我们简单的了解完

286
00:11:01,800 --> 00:11:03,766
它的一个硬件的形态

287
00:11:03,766 --> 00:11:06,933
我们看一下它的一个主要的工作原理

288
00:11:09,700 --> 00:11:10,900
现在我们顺着光的方向

289
00:11:10,900 --> 00:11:13,200
我们从假设啊从这一个方向进去

290
00:11:13,200 --> 00:11:14,666
从这个方向出来

291
00:11:19,000 --> 00:11:21,400
对我们的光呢进行一个演示

292
00:11:21,466 --> 00:11:22,833
在光传输的过程当中

293
00:11:27,700 --> 00:11:28,200
这个时候呢

294
00:11:30,200 --> 00:11:33,400
跟带内的信号呢是互相重叠在一起的

295
00:11:34,300 --> 00:11:36,200
提供 850 纳米的一个波段

296
00:11:36,200 --> 00:11:37,466
提供一个红外线

297
00:11:37,466 --> 00:11:39,633
用于调节整个反射镜的

298
00:11:41,600 --> 00:11:43,100
是因为我们传统的交换机呢

299
00:11:43,100 --> 00:11:45,166
实际上它传进来的是一个光线

300
00:11:45,166 --> 00:11:45,933
是一个光了

301
00:11:48,266 --> 00:11:51,033
再从电转换到光进行出去

302
00:11:52,500 --> 00:11:54,300
非常大的性能的损耗

303
00:11:54,300 --> 00:11:55,100
那这个时候呢

304
00:11:55,100 --> 00:11:58,666
整个 OCS 啊是提供光到光的一个转换

305
00:12:00,800 --> 00:12:04,300
除了电之外呢还节省了非常多的时延

306
00:12:07,966 --> 00:12:10,333
了解工作原理之后呢

307
00:12:11,400 --> 00:12:14,000
它的整个 VCS 的一个具体的实物图

308
00:12:14,200 --> 00:12:15,400
里面呢有几个模块

309
00:12:22,666 --> 00:12:25,666
最后一块滴呢就是我们的注入模块呀

310
00:12:28,700 --> 00:12:30,000
背板呢还是很有意思的

311
00:12:30,000 --> 00:12:31,666
里面呢有个 CPU 的控制的

312
00:12:37,500 --> 00:12:39,200
也可以深入去看一下

313
00:12:43,100 --> 00:12:47,600
就是思考和简单的有缺点的对比啊

314
00:12:47,666 --> 00:12:49,133
首先呢我们可以看到呢

315
00:12:52,700 --> 00:12:56,200
因为它提供了一个最新的 3D Torus 的环面

316
00:12:56,200 --> 00:12:58,000
的一个网络的拓扑

317
00:12:58,300 --> 00:12:59,966
有了这个拓扑呢不是最重要的

318
00:12:59,966 --> 00:13:00,866
因为这个拓扑呢

319
00:13:02,400 --> 00:13:04,066
就使用了 OCS

320
00:13:04,066 --> 00:13:06,433
从而改变了我们整个拓扑的形态

321
00:13:07,300 --> 00:13:10,666
我们就可以进行一个路由的可重配置

322
00:13:10,966 --> 00:13:12,166
有了路由的可重配置呢

323
00:13:12,166 --> 00:13:14,933
就可以帮助我们的 Silic 的集群呢

324
00:13:18,566 --> 00:13:21,433
进行我们的网络的重新的组合

325
00:13:24,600 --> 00:13:26,966
所以说它是一脉相承的

326
00:13:26,966 --> 00:13:29,233
从一个点到一个面

327
00:13:30,500 --> 00:13:31,900
时候确实呃

328
00:13:31,900 --> 00:13:33,566
如果能考虑的这么全面

329
00:13:33,566 --> 00:13:34,366
确实很牛逼

330
00:13:34,366 --> 00:13:35,533
也不得不佩服

331
00:13:38,400 --> 00:13:40,666
不过最可惜的就是谷歌在 Tensorflow

332
00:13:40,666 --> 00:13:42,466
AI 软件到 AI 硬件呢

333
00:13:42,466 --> 00:13:44,433
确实没有把生态很好的做起来

334
00:13:45,300 --> 00:13:47,566
谷歌安卓确实生态做得非常好

335
00:13:47,566 --> 00:13:48,566
那整个缺点呢

336
00:13:48,566 --> 00:13:51,633
就是系统的成熟度是比较低的

337
00:13:55,600 --> 00:13:58,900
但系列 3D torus 3D 环面的这种拓扑呢

338
00:13:58,900 --> 00:14:00,166
确实还不太成熟

339
00:14:02,500 --> 00:14:05,566
需要进行大量工程化的一些优化

340
00:14:05,866 --> 00:14:06,766
但是呢整个拓扑呢

341
00:14:06,766 --> 00:14:08,633
相对来说还是比较僵硬的

342
00:14:12,000 --> 00:14:14,400
如果想改变里面的其中一个环节

343
00:14:14,400 --> 00:14:16,366
会把 slice 呢改变

344
00:14:16,366 --> 00:14:18,766
或者把整个 slice 的数量呢改变

345
00:14:18,766 --> 00:14:21,166
那扩充我们的 3D Torus 的结构呢

346
00:14:22,300 --> 00:14:24,166
因为它整个是一脉相承的

347
00:14:25,700 --> 00:14:27,300
虽然它定制完之后

348
00:14:27,300 --> 00:14:29,400
可以很灵活的去配置怎么拓普

349
00:14:29,400 --> 00:14:32,400
但是配置之前还是很复杂的

350
00:14:32,400 --> 00:14:33,100
那第三个呢

351
00:14:34,600 --> 00:14:37,300
不是说 3D Torus 3D 画面能解决很多问题

352
00:14:38,000 --> 00:14:39,900
大部分都在超算里面去用的

353
00:14:39,900 --> 00:14:42,000
为什么我们现在很多 AI 集群里面呢

354
00:14:42,000 --> 00:14:43,000
会用 CIos

355
00:14:43,000 --> 00:14:44,600
用网络拓扑呢

356
00:14:44,900 --> 00:14:46,466
其实因为整个 CIos 的网络

357
00:14:48,900 --> 00:14:50,866
能够提供比较好的一个路径的

358
00:14:50,866 --> 00:14:53,266
勇于实现更多的路径的传输

359
00:14:54,700 --> 00:14:56,300
尽可能的负载均衡

360
00:14:56,300 --> 00:14:59,800
这也是 CIos 网络拓扑的一个好处之

361
00:14:59,900 --> 00:15:03,100
我们进行一个简单的思考和总结

362
00:15:03,100 --> 00:15:04,200
我们之前讲到了

363
00:15:04,200 --> 00:15:07,900
谷歌 TPUV4 的一个 HBM 其实就有 32GB

364
00:15:07,900 --> 00:15:09,100
其实并不影响啊

365
00:15:15,700 --> 00:15:17,966
是因为我们的模型的演进啊

366
00:15:17,966 --> 00:15:18,466
说实话

367
00:15:21,200 --> 00:15:23,200
我们的模型的参数量不断的增加

368
00:15:23,200 --> 00:15:24,200
但是芯片呢

369
00:15:25,766 --> 00:15:27,166
它从设计到逆向啊

370
00:15:27,166 --> 00:15:28,733
真正的投产封测

371
00:15:28,966 --> 00:15:29,866
它还是比较慢的

372
00:15:29,866 --> 00:15:30,933
而大模型的涌现呢

373
00:15:33,266 --> 00:15:35,966
而并不是提高单芯片的能力啊

374
00:15:35,966 --> 00:15:36,833
那这个时候呢

375
00:15:39,500 --> 00:15:41,266
单芯片的 FLOPS 比再高

376
00:15:41,266 --> 00:15:43,966
其实并不是说非常的重要

377
00:15:43,966 --> 00:15:45,933
整体的高效的互联

378
00:15:53,500 --> 00:15:55,600
根据我们的收款推和大模型的业务呢

379
00:16:00,866 --> 00:16:02,233
那最后一点呢

380
00:16:04,800 --> 00:16:06,266
谷歌 TPUV4 这篇文章呢

381
00:16:06,266 --> 00:16:08,433
非常好发布了非常多的 Benchmark

382
00:16:12,400 --> 00:16:14,200
整体的 XLA 编译优化呢

383
00:16:16,966 --> 00:16:18,566
它到底处于一个什么位置

384
00:16:19,800 --> 00:16:22,100
TPUV4 呢因为它没有真正的公开

385
00:16:23,866 --> 00:16:25,933
那它真的像测评

386
00:00:06,400 --> 00:00:07,100
我是矮又穷

387
00:00:14,600 --> 00:00:17,800
里面主要组成的超级计算集群

388
00:00:29,400 --> 00:00:32,666
也就是它的超级计算的集群的形态

389
00:00:32,666 --> 00:00:33,566
那看到这个图呢

390
00:00:33,566 --> 00:00:35,866
就是谷歌剖出来的一张图

391
00:00:55,466 --> 00:00:56,066
我们可以看到

392
00:01:01,366 --> 00:01:08,133
4409 个 TPUV4 的单芯片不是指 4096 块卡里面

393
00:01:19,900 --> 00:01:21,300
它不是一个量级的

394
00:01:26,900 --> 00:01:29,300
动态的配置 TPU 芯片里面的链接

395
00:01:30,766 --> 00:01:32,433
可以执行的调整

396
00:01:40,400 --> 00:01:44,366
就是呃谷歌发表两篇或者两个大模型

397
00:01:44,366 --> 00:01:45,733
像这两个大模型啊

398
00:01:53,500 --> 00:01:55,966
呃超过了 5,400 亿参数的

399
00:01:58,100 --> 00:02:00,400
训练了 64 天

400
00:02:18,700 --> 00:02:22,100
一共有三种颜色不同的环面组成

401
00:02:26,400 --> 00:02:30,400
乘以 464 个 TPUV4 的芯片互联在一起

402
00:02:37,300 --> 00:02:39,100
又有两个 Tensor Core

403
00:02:49,700 --> 00:02:50,300
由 OCS

404
00:02:54,400 --> 00:02:57,300
接着呢我们看看整个拓扑的结构啊

405
00:03:05,000 --> 00:03:07,000
因为它是一个 3D 环面了

406
00:03:10,100 --> 00:03:11,300
它也有前面哦

407
00:03:16,000 --> 00:03:18,500
所以它会有六个相邻的节点

408
00:03:31,666 --> 00:03:32,966
下面的这个图呢

409
00:03:41,700 --> 00:03:43,466
实际上刚才讲到的

410
00:03:52,500 --> 00:03:55,166
远一点呢我们的机柜呢的 TPU 呢

411
00:03:57,500 --> 00:04:00,566
通过我们的光纤光缆进行互联的

412
00:04:04,300 --> 00:04:06,466
主要是为了避免计算等通讯

413
00:04:23,600 --> 00:04:24,100
所以我们呢

414
00:04:58,500 --> 00:05:01,166
如果我大于 4096 怎么办呢

415
00:05:11,600 --> 00:05:15,566
看看谷歌 TPU V4 的 Pod 的拓扑结构的基本

416
00:05:17,900 --> 00:05:20,300
4 乘以 4 乘以 4 的一个 TPU

417
00:05:34,300 --> 00:05:34,800
所以呢

418
00:05:43,200 --> 00:05:44,300
呢相对的侧面

419
00:06:37,100 --> 00:06:41,000
以 DGX Superpod 呢我们的 H100 为例啊

420
00:06:50,400 --> 00:06:52,200
这个单位呢可能有点小问题

421
00:07:21,800 --> 00:07:23,566
成本呢相对来说高

422
00:07:34,600 --> 00:07:36,466
或者 NVLINK 的第四代呢

423
00:07:40,100 --> 00:07:42,600
并且独立的去规划我们的互联网络

424
00:07:47,900 --> 00:07:49,666
factory 啊还有 benefit 啊

425
00:08:24,200 --> 00:08:26,500
刚才一个 cube 呢是 60 个芯片

426
00:08:54,400 --> 00:08:56,800
整体的系统的平均的性能呢

427
00:09:01,200 --> 00:09:05,266
可以看到光交换机的开关非常的重要

428
00:09:20,500 --> 00:09:23,600
可以看到谷歌光路由交换机实际上呢

429
00:09:32,700 --> 00:09:35,266
Palomar 呢就是谷歌的一篇新的论文

430
00:09:38,200 --> 00:09:40,366
MEMS 微晶原理的一个

431
00:09:58,900 --> 00:10:02,266
可以实现比较低的一个性能的损耗啊

432
00:10:03,000 --> 00:10:05,400
提供一个低切换的一个延迟

433
00:10:23,700 --> 00:10:25,366
在每一个陶瓷封装内部呢

434
00:10:28,700 --> 00:10:32,700
一共有 176 个可单独控制的微反射镜啊

435
00:10:47,900 --> 00:10:51,166
1234 四个配方

436
00:10:52,300 --> 00:10:54,100
我们把 MEMS 的反射镜呢

437
00:11:06,900 --> 00:11:09,300
就是下面的下面的这个图了

438
00:11:25,766 --> 00:11:27,733
那这个光我们叫做光波

439
00:11:33,400 --> 00:11:34,300
这里面的开口呢

440
00:11:51,000 --> 00:11:52,500
转换的过程当中呢就有

441
00:12:10,300 --> 00:12:11,400
我们现在回过来看一下

442
00:12:49,100 --> 00:12:52,700
谷歌 TPUV4 的一个优点就是提供给低时延嘛

443
00:13:14,900 --> 00:13:18,566
可以在 64 128 256 里面的一个情况

444
00:13:21,400 --> 00:13:24,600
从而提供了更好的集群的布局

445
00:13:35,500 --> 00:13:38,000
谷歌的一个工程性的能力

446
00:13:51,600 --> 00:13:53,400
因为像 CIos 这种拓扑呢

447
00:14:08,600 --> 00:14:10,166
因为它已经规定好了

448
00:14:46,466 --> 00:14:47,666
拓扑的替换路径呢

449
00:15:09,900 --> 00:15:13,500
那些大家都可以用到 64GB 的一个 HBM

450
00:15:30,900 --> 00:15:33,266
主要是依赖于 AI 的一个计算集群

451
00:15:45,900 --> 00:15:48,000
反倒变得非常的重要

452
00:16:02,200 --> 00:16:04,500
就是 ZOMI 提出的一个疑问呢

453
00:16:25,900 --> 00:16:28,900
或者像它内篇论文描述的这么好吗

454
00:00:01,500 --> 00:00:04,366
字幕生成：mkwei  字幕校准：mkwei

455
00:00:07,100 --> 00:00:10,000
肥又穷只能在这瞎逼逼的 ZOMI

456
00:00:10,000 --> 00:00:10,366
今天呢

457
00:00:44,600 --> 00:00:47,100
这篇文章的标题里面呢

458
00:01:14,066 --> 00:01:14,833
整个超级计算机呢

459
00:01:35,366 --> 00:01:36,533
可以灵活的进行

460
00:02:04,400 --> 00:02:05,400
例如 Llama

461
00:02:34,200 --> 00:02:35,366
一个 TPUV4 的芯片

462
00:03:35,066 --> 00:03:36,866
整体的一个 Pod 的形态

463
00:13:44,400 --> 00:13:45,300
不像安卓

