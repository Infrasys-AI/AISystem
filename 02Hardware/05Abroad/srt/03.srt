1
00:00:07,700 --> 00:00:09,666
到点我就想下班

2
00:00:14,566 --> 00:00:16,733
明天又要去见客户了

3
00:00:17,366 --> 00:00:18,466
偶买噶

4
00:00:28,700 --> 00:00:29,800
我们现在回顾一下

5
00:00:34,966 --> 00:00:36,766
AI 芯片今天呢

6
00:00:36,766 --> 00:00:37,466
我们来到了

7
00:00:37,500 --> 00:00:40,200
DOJO 的训练矩阵和训练系统

8
00:00:42,166 --> 00:00:44,266
DOJO 这块芯片的一些思考

9
00:00:48,366 --> 00:00:49,533
现在我们来看一下

10
00:00:56,366 --> 00:00:58,866
单个可以扩展的计算平面

11
00:00:59,100 --> 00:00:59,800
那现在呢

12
00:01:00,700 --> 00:01:02,400
单个可扩展的计算平面呢

13
00:01:05,200 --> 00:01:06,300
所决定的

14
00:01:07,800 --> 00:01:09,566
我们叫做 DOJO Core

15
00:01:16,966 --> 00:01:18,766
那 6 块 DOJO 瓦片呢

16
00:01:18,766 --> 00:01:21,566
就组成了一个 DOJO 的主机

17
00:01:49,566 --> 00:01:50,566
那回顾完之后呢

18
00:01:53,766 --> 00:01:55,366
今天的正式内容呢就是

19
00:01:59,566 --> 00:02:01,766
现在我们看一下整个 DOJO Die 有呢

20
00:02:01,800 --> 00:02:04,100
里面主要是由 354 个 DOJO Core

21
00:02:05,566 --> 00:02:07,133
这么一小块来组成的

22
00:02:09,700 --> 00:02:12,866
也就是上面蓝色的这些小模块

23
00:02:17,766 --> 00:02:20,333
把好多的 DOJO Core 呢连接在一起

24
00:02:29,400 --> 00:02:31,700
就是 NOC 的路由

25
00:02:33,166 --> 00:02:34,466
它可以随机的分发

26
00:02:34,500 --> 00:02:37,100
然后每个时钟周期呢可以在四个方向

27
00:02:40,100 --> 00:02:40,800
每个方向呢

28
00:02:56,166 --> 00:02:59,933
根据 NOC 路由去搬运到具体的 SRAM 里面

29
00:03:15,200 --> 00:03:16,500
在整个训练 Tile 里面呢

30
00:03:22,200 --> 00:03:23,300
结合在一起里面呢

31
00:03:23,300 --> 00:03:27,200
在 BF16 和 CFP8 里面呢提供 376TFlops

32
00:03:36,966 --> 00:03:40,166
还有华为的阿特拉斯 380TFLOPS 呢

33
00:03:41,600 --> 00:03:44,166
他们之间有一个非常高的代差

34
00:03:49,766 --> 00:03:53,733
有 440MB 那特斯拉将整个设计的重心呢

35
00:03:58,300 --> 00:04:01,300
就是通过大量更快更近的片上存储

36
00:04:04,566 --> 00:04:07,933
来减少对内存的访问需求

37
00:04:07,966 --> 00:04:12,133
从而提高整个系统的性能的吞吐

38
00:04:17,966 --> 00:04:18,766
芯片里面呢

39
00:04:24,366 --> 00:04:28,566
就布满了 576 个双向的串形通道的接口

40
00:04:28,600 --> 00:04:32,566
而单边的带宽呢是 4TB 每秒

41
00:04:32,566 --> 00:04:34,466
传输的速率也是非常快

42
00:04:39,766 --> 00:04:41,333
具体的外围接口有哪些

43
00:04:47,100 --> 00:04:48,666
DOJO 的一个对外的接口

44
00:04:49,700 --> 00:04:52,000
有几个内容值得大家去关注的

45
00:04:52,000 --> 00:04:54,300
首先第一个呢就是内存

46
00:04:54,300 --> 00:04:54,800
这里面呢

47
00:05:15,100 --> 00:05:19,000
至少比 NV link 单项的传输速率要高

48
00:05:19,000 --> 00:05:19,500
另外的话

49
00:05:20,300 --> 00:05:22,200
它的传输的方式呢

50
00:05:27,200 --> 00:05:30,300
就是典型的 PCIe 的插槽的接口

51
00:05:33,766 --> 00:05:35,366
是特斯拉自己的协议

52
00:05:35,366 --> 00:05:38,166
特斯拉的 Transport Protocol

53
00:05:47,500 --> 00:05:48,666
那最后一个内容呢

54
00:05:59,766 --> 00:06:01,733
就负责把 DOJO 的 D1 Die 呢

55
00:06:06,700 --> 00:06:09,300
使得我们整个链路连起来

56
00:06:09,300 --> 00:06:12,400
把整个 DOJO D1 连起来变成一个 ExaPOD

57
00:06:20,766 --> 00:06:22,566
DOJO 的 training tile

58
00:06:22,966 --> 00:06:24,266
不过呢很有意思的一点呢

59
00:06:28,400 --> 00:06:30,766
转换成为 z 平面的拓扑

60
00:06:39,166 --> 00:06:41,566
然后把数据呢再继续往下一级

61
00:06:49,366 --> 00:06:51,766
下面我们还是回到整个 DOJO 的训练 Tile

62
00:07:02,600 --> 00:07:05,800
里面就有一款我们的 D1 Die

63
00:07:13,766 --> 00:07:15,933
四个主机的服务器

64
00:07:21,300 --> 00:07:22,600
还有一组 switch

65
00:07:28,000 --> 00:07:31,500
组成我们整个 DOJO 的训练矩阵

66
00:07:33,766 --> 00:07:36,566
那就变成我们右边的这个渲染图

67
00:07:40,500 --> 00:07:43,100
下面我们来到了第二个内容

68
00:07:43,100 --> 00:07:45,200
DOJO 的通讯的方式

69
00:07:45,300 --> 00:07:49,000
那其实今天的视频主要是刚才讲到了

70
00:07:54,700 --> 00:07:56,200
之后呢我们看一下

71
00:08:06,100 --> 00:08:07,200
我们下面呢

72
00:08:07,300 --> 00:08:08,400
然后快速的聚焦

73
00:08:17,900 --> 00:08:19,700
横轴坐标呢是我们的链路的长度

74
00:08:27,966 --> 00:08:29,566
这就是我们的 DOJO 芯片呢

75
00:08:29,566 --> 00:08:31,366
为什么会通过 DIP

76
00:08:38,766 --> 00:08:41,933
就是我们刚才讲到的一个 Dojo D1

77
00:08:44,400 --> 00:08:45,500
所以呢

78
00:08:50,300 --> 00:08:51,900
传输到 b 这个地方

79
00:08:51,966 --> 00:08:53,966
进行一个协同运作

80
00:08:53,966 --> 00:08:56,266
或者做一个 All Reduce 的操作的时候呢

81
00:09:06,100 --> 00:09:08,400
不仅仅将 DRAM 的实现呢为本地的存储

82
00:09:12,500 --> 00:09:14,066
绕过我们整个 2D 网络

83
00:09:24,566 --> 00:09:25,266
每一个节点呢

84
00:09:36,500 --> 00:09:38,200
左边的这个呢就是数据的源

85
00:09:48,100 --> 00:09:49,900
是通过片上的一个网络路由

86
00:09:53,766 --> 00:09:55,466
DOJO Core 架构的核心的时候

87
00:10:05,500 --> 00:10:06,866
因此呢我们可以看到在

88
00:10:09,900 --> 00:10:11,300
一个正方形 5 乘以 5

89
00:10:18,400 --> 00:10:19,700
每一次转发的时候

90
00:10:21,200 --> 00:10:22,166
通过这种方式呢

91
00:10:24,166 --> 00:10:25,533
每次跨件传输的时候呢

92
00:10:27,500 --> 00:10:29,800
进行一个 balance of recovery

93
00:10:29,800 --> 00:10:30,166
接下来

94
00:10:30,166 --> 00:10:33,366
我们尝试的去打开其中一个小格子

95
00:10:38,566 --> 00:10:39,766
是里面最核心的

96
00:10:41,200 --> 00:10:42,800
那这里面呢有两个内容

97
00:10:56,966 --> 00:11:00,166
和 remote 的线程的执行两种方式

98
00:11:00,166 --> 00:11:00,733
另外的话

99
00:11:08,200 --> 00:11:10,400
我们的线程就会进入休眠

100
00:11:20,800 --> 00:11:22,500
整个计算单元或者线程呢

101
00:11:22,500 --> 00:11:24,400
才会真正的工作起来

102
00:11:34,366 --> 00:11:36,533
这种效率是非常非常的低效的

103
00:11:43,766 --> 00:11:46,733
变成一个带节点的通信树

104
00:11:54,700 --> 00:11:55,700
通过树的方式呢

105
00:12:08,100 --> 00:12:11,500
把我们的 DIP 呢插在每一块 D1 之外呢

106
00:12:20,000 --> 00:12:23,200
去提升我们整体的数据的传输方式

107
00:12:23,200 --> 00:12:25,966
那这也是很有意思的一个创新点

108
00:12:27,300 --> 00:12:28,100
哎呦好不容易

109
00:12:34,966 --> 00:12:35,666
那这里面呢

110
00:12:52,966 --> 00:12:55,333
非常依赖于 AI 的编译器

111
00:13:09,166 --> 00:13:11,533
如果 DOJO 去对接业界的 tvm 嘛

112
00:13:24,500 --> 00:13:26,666
我觉得这是一个很大的灵魂拷问

113
00:13:31,300 --> 00:13:33,800
这 DOJO 是走的非常非常困难

114
00:13:44,366 --> 00:13:45,533
包括 stable difussion

115
00:14:01,700 --> 00:14:03,000
留给时间去验证

116
00:14:10,800 --> 00:14:12,566
就是在云服务的场景里面

117
00:14:12,566 --> 00:14:13,966
我们多任务场景

118
00:14:28,100 --> 00:14:29,200
现在至少来看呢

119
00:14:29,200 --> 00:14:31,800
DOJO 是不太支持这种任务的分配

120
00:14:31,800 --> 00:14:32,900
和云服务的

121
00:14:33,366 --> 00:14:35,933
不知道 DOJO 会在这方面有如何的考虑

122
00:14:45,566 --> 00:14:47,366
包括精度异常这些模块

123
00:14:47,366 --> 00:14:49,166
那在训练的场景里面呢

124
00:14:53,366 --> 00:14:54,733
给我们提供好的模型

125
00:14:55,766 --> 00:14:57,166
但是呢我们要自己去开发模型

126
00:14:57,200 --> 00:14:58,700
要自己去调试的时候

127
00:14:58,800 --> 00:15:00,800
他既可能会成为一个灾难

128
00:15:00,800 --> 00:15:01,400
不知道 DOJO

129
00:15:01,400 --> 00:15:03,300
他是如何去解决这些问题的

130
00:15:03,366 --> 00:15:04,733
所以软件上面的 DOJO

131
00:15:11,100 --> 00:15:12,700
最应该下功夫的点

132
00:15:25,500 --> 00:15:28,200
你可能需要运行非常非常多的任务

133
00:15:34,300 --> 00:15:36,500
这会影响到我们的其他的业务

134
00:15:42,366 --> 00:15:43,566
但是呢另外一个方面呢

135
00:15:47,166 --> 00:15:47,966
那 ExaPOD 呢

136
00:15:47,966 --> 00:15:49,333
作为一个整个服务器集群

137
00:15:51,500 --> 00:15:52,800
如果不能优化的话

138
00:15:59,766 --> 00:16:01,566
他是怎么考虑这些问题的

139
00:16:05,700 --> 00:16:07,400
会非常非常的高哦

140
00:16:08,566 --> 00:16:09,566
那今天的内容呢

141
00:16:09,566 --> 00:16:10,566
就到这里为止了

142
00:16:13,900 --> 00:16:15,200
整个 DOJO 的

143
00:16:16,500 --> 00:16:18,300
DOJO 存算一体的细节内容

144
00:16:18,366 --> 00:16:20,133
再到 DOJO 的训练的矩阵

145
00:00:06,600 --> 00:00:07,700
我是 ZOMI

146
00:00:23,966 --> 00:00:25,266
我们现在来到了

147
00:00:31,800 --> 00:00:34,966
我们已经来到了 AI 的专用处理器

148
00:00:53,900 --> 00:00:56,300
它是一个存算一体的架构

149
00:01:02,400 --> 00:01:05,200
主要是它由组成的方式不一样

150
00:01:09,766 --> 00:01:12,733
接着呢由 300 多个 DOJO Core 组成

151
00:01:14,166 --> 00:01:16,533
同时呢我们叫做 DOJO DIE

152
00:01:29,300 --> 00:01:31,600
还有我们的内存 SRAM

153
00:01:43,166 --> 00:01:44,866
是集中在 MatMul

154
00:01:46,766 --> 00:01:49,566
还有 SRAM 两个模块里面

155
00:02:07,100 --> 00:02:09,700
另外的话它里面有 440MB 的 SRAM

156
00:02:20,300 --> 00:02:24,100
变成一个非常大的一个 2D 的网络

157
00:02:24,100 --> 00:02:25,900
那里面每一个小格子呢

158
00:02:26,200 --> 00:02:27,700
就是一个 DOJO Core

159
00:02:27,766 --> 00:02:29,366
另外呢我们看一下第二个内容

160
00:02:37,100 --> 00:02:40,066
就是上下左右

161
00:02:47,300 --> 00:02:49,666
进行一次 64B 的读和写

162
00:02:52,300 --> 00:02:55,400
非常方便的去搬运我们的数据

163
00:03:02,566 --> 00:03:05,366
是由 5 乘以 5 的 D1 Die

164
00:03:06,366 --> 00:03:10,266
由很多个 DOJO Core 所组成的一片 Die

165
00:03:19,366 --> 00:03:21,966
这个带宽的传输速率是非常的高的

166
00:03:53,700 --> 00:03:55,800
其实是放在网格里面均匀分布的

167
00:04:12,900 --> 00:04:16,266
就是非常明显的存算一体的架构

168
00:04:17,100 --> 00:04:17,900
回到 D1 这款

169
00:04:18,766 --> 00:04:20,866
我们可以看到上下左右呢

170
00:04:20,900 --> 00:04:23,600
都有一排浅浅的一些接口

171
00:04:38,400 --> 00:04:39,766
我们现在看一下

172
00:04:44,000 --> 00:04:46,900
DIP 简称就是 DOJO Interface Processor

173
00:04:48,700 --> 00:04:49,700
处理器那这里面呢

174
00:05:05,766 --> 00:05:07,966
那可能左边一个呢就是 16

175
00:05:09,766 --> 00:05:13,166
提供了 800GB 每秒的带宽

176
00:05:22,166 --> 00:05:24,166
下面有一个非常熟悉的接口

177
00:05:26,700 --> 00:05:27,200
这一个呢

178
00:05:38,200 --> 00:05:39,966
TTP 的协议

179
00:05:41,500 --> 00:05:44,100
把整个完整的 DRAM 的内存呢

180
00:05:52,566 --> 00:05:56,733
电路呢有一个非常有意思的接口

181
00:06:03,400 --> 00:06:06,600
另外一款主机或另外一款芯片上面

182
00:06:13,366 --> 00:06:15,666
我们看一下刚才讲到的这块芯片呢

183
00:06:18,166 --> 00:06:20,766
插到我们刚才所讲到的

184
00:06:35,900 --> 00:06:39,200
传输到每一块 DOJO 的 D1 DIE 里面

185
00:06:43,900 --> 00:06:45,900
那具体的 z 平面的拓扑呢

186
00:06:45,966 --> 00:06:49,366
我们会在下面进行一个详细的展开

187
00:06:58,566 --> 00:07:01,566
就有六个训练的 training Tile 所组成

188
00:07:08,500 --> 00:07:10,400
所以说细分得非常细

189
00:07:10,766 --> 00:07:13,766
这里面外围呢有四个 CPU

190
00:07:15,966 --> 00:07:18,133
另外的话还有 20 个

191
00:07:22,566 --> 00:07:24,966
连接到以太网的交换机里面

192
00:07:24,966 --> 00:07:27,333
再连接到其他的主机上面

193
00:07:51,900 --> 00:07:53,500
训练的芯片

194
00:08:31,366 --> 00:08:34,133
去构建我们整个 z 平面的链路

195
00:08:34,966 --> 00:08:37,133
现在我们看一下右边的这一个图

196
00:08:37,166 --> 00:08:38,766
其中的一个小框框

197
00:08:41,900 --> 00:08:44,400
那 5 乘以 5 呢就组成一个 Dojo 的训练的 tile

198
00:08:45,500 --> 00:08:47,700
它整体来说还是非常复杂的一个系统

199
00:08:47,900 --> 00:08:48,666
我们的数据呢

200
00:08:48,700 --> 00:08:50,300
假设从 a 这个地方呢

201
00:08:56,300 --> 00:08:59,200
整个数据通路呢会非常非常的长

202
00:09:01,400 --> 00:09:02,100
于是呢

203
00:09:02,100 --> 00:09:05,600
DOJO 呢就提出了一个 z 平面的链路

204
00:09:14,000 --> 00:09:16,566
漫长的通讯的存储方式

205
00:09:16,566 --> 00:09:17,766
而且任何一个节点

206
00:09:17,766 --> 00:09:20,366
都可以跨系统的去访问我们的数据

207
00:09:20,366 --> 00:09:20,966
那这里面呢

208
00:09:21,000 --> 00:09:22,800
就得益于我们的 DIP

209
00:09:22,800 --> 00:09:24,366
这整一个架构的设计

210
00:09:31,300 --> 00:09:32,500
下面呢我们就打开看一下

211
00:09:32,500 --> 00:09:35,066
DOJO 系统的网络通讯的方式

212
00:09:35,100 --> 00:09:36,500
那这里面很有意思的就是

213
00:09:38,166 --> 00:09:39,933
右边的就是目标的数据

214
00:09:39,966 --> 00:09:43,133
我们希望把数据呢从左边传输到右边

215
00:09:43,166 --> 00:09:45,333
现在我们细节的去打开中间这一个呢

216
00:09:51,600 --> 00:09:53,766
也就是在上一节具体的去打开

217
00:10:00,166 --> 00:10:01,966
NOC 的路由呢可以把我们的数据呢

218
00:10:22,166 --> 00:10:23,866
把整个矩阵记录下来

219
00:10:25,500 --> 00:10:27,466
都会对网络的链接呢

220
00:10:35,200 --> 00:10:36,500
具体的数据的传输呢

221
00:10:50,766 --> 00:10:51,933
最终任务生成之后呢

222
00:10:54,166 --> 00:10:56,966
实际上是分为 local 的线程的执行

223
00:11:11,966 --> 00:11:14,166
也将会进入休眠的状态

224
00:11:18,366 --> 00:11:20,566
这种线程呢被触发之后呢

225
00:11:24,500 --> 00:11:25,266
那这里面呢

226
00:11:28,100 --> 00:11:29,000
实际上呢

227
00:11:29,366 --> 00:11:32,966
如果我们从 A.00 传到最后一个点四五

228
00:11:33,000 --> 00:11:34,366
一个一个节点的传输呢

229
00:11:36,500 --> 00:11:38,800
所以 DOJO 他在整体的编辑器里面呢

230
00:11:38,800 --> 00:11:40,900
就设计了一个系统的同步

231
00:11:46,700 --> 00:11:49,100
那就变成右边的 barrier domain

232
00:11:49,100 --> 00:11:51,700
两个通信树对整体的计算区域

233
00:11:51,766 --> 00:11:52,766
也就是 DOJO Core 呢

234
00:11:55,700 --> 00:11:59,100
进行索引和触达到每一个 DOJO Core 里面

235
00:11:59,100 --> 00:12:01,700
这样的话会加快我们的索引和运算

236
00:12:02,200 --> 00:12:03,800
所以呢在整个 DOJO 的系统的

237
00:12:03,800 --> 00:12:05,366
网络传输的方式呢

238
00:12:05,366 --> 00:12:08,066
啊除了硬件的 z 平面的设计

239
00:12:15,366 --> 00:12:16,366
例如 look up table 啦

240
00:12:16,400 --> 00:12:19,100
还有刚才讲到的编译通信树

241
00:12:19,100 --> 00:12:20,000
这种方式呢

242
00:12:31,100 --> 00:12:33,700
DOJO 已经连载了三个视频了

243
00:12:33,766 --> 00:12:34,966
这最后一个内容了

244
00:12:35,600 --> 00:12:38,200
ZOMI 想引发大家的一些思考

245
00:12:38,200 --> 00:12:39,166
关于 DOJO 的

246
00:12:39,366 --> 00:12:40,333
首先呢我们讲了很多

247
00:12:40,366 --> 00:12:40,966
其实大部分

248
00:12:40,966 --> 00:12:43,366
都是围绕着 DOJO 的硬件来去讲的

249
00:12:43,400 --> 00:12:44,200
DOJO 的硬件呢

250
00:12:44,200 --> 00:12:46,500
又跟传统的我们的 GPGPU

251
00:12:46,500 --> 00:12:49,700
或者我们的 tpu、npu 的架构是不一样的

252
00:12:49,700 --> 00:12:52,100
它提出了一个存算一体的架构

253
00:12:57,100 --> 00:12:58,400
或者我们的软件编译器

254
00:12:58,400 --> 00:12:59,966
但是呢关于业界的 AI 编译器

255
00:12:59,966 --> 00:13:02,133
其实现在是没有一个统一的方案

256
00:13:16,700 --> 00:13:18,400
于是呢这里面呢就衍生一个问题

257
00:13:19,366 --> 00:13:23,066
如何去兼容 AI 软件的应用性

258
00:13:23,100 --> 00:13:24,500
和 AI 软件的生态

259
00:13:41,700 --> 00:13:44,300
里面就跑了几个简单的应用而已

260
00:13:45,500 --> 00:13:46,400
他跑通了

261
00:13:46,400 --> 00:13:49,166
居然拿来在发布会上去讲这个事情

262
00:13:50,766 --> 00:13:53,266
你只是跑通一个网络模型的大哥

263
00:13:59,966 --> 00:14:01,666
更多的希望留给业界

264
00:14:04,966 --> 00:14:05,766
DOJO Core 里面呢

265
00:14:05,766 --> 00:14:08,966
其实并不太关心虚拟内存的支持

266
00:14:09,000 --> 00:14:10,800
那这个时候我们会引起很多问题

267
00:14:22,200 --> 00:14:24,966
我们编译器去做一个分配的

268
00:14:37,300 --> 00:14:38,900
就是在 DOJO Core 里面呢

269
00:14:38,900 --> 00:14:41,466
其实我们可以发现之前的分享里面呢

270
00:14:41,500 --> 00:14:42,600
都知道 DOJO Core 里面

271
00:14:51,966 --> 00:14:53,366
如果我们只是用 DOJO

272
00:14:54,700 --> 00:14:55,500
这个没问题

273
00:15:04,700 --> 00:15:06,200
其实是没有太提的

274
00:15:08,400 --> 00:15:11,100
但我觉得软件上面才是他最重要

275
00:15:13,166 --> 00:15:14,166
最后还有两个问题呢

276
00:15:14,200 --> 00:15:16,400
是跟云是强相关的

277
00:15:16,400 --> 00:15:19,200
因为 DOJO 呢他未来是打造一个 ExaPOD

278
00:15:19,200 --> 00:15:22,300
也就是一个嗯超级的计算机集群

279
00:15:22,300 --> 00:15:23,666
那这个时候你有一个集群

280
00:15:23,700 --> 00:15:25,500
你不可能运行一个单个任务

281
00:15:28,166 --> 00:15:30,733
但是呢如果有一个任务死机了

282
00:15:30,966 --> 00:15:32,766
我们需要重启计算机

283
00:15:32,766 --> 00:15:34,333
或者重启整个系统的时候

284
00:15:37,966 --> 00:15:39,133
怎么去做诊断

285
00:15:49,300 --> 00:15:51,266
它怎么考虑优化的问题

286
00:15:54,200 --> 00:15:55,900
你要跑起来是很困难的

287
00:15:55,900 --> 00:15:57,300
你要需要大量的人

288
00:15:57,400 --> 00:15:58,800
会给整个系统作运维

289
00:15:58,800 --> 00:15:59,766
我也不知道 DOJO

290
00:16:01,566 --> 00:16:02,166
说实话这

291
00:16:10,600 --> 00:16:13,900
我们其实分开了 3 节给大家去汇报

292
00:16:20,100 --> 00:16:21,700
和他的传输方式

293
00:16:25,900 --> 00:16:26,800
感谢各位

294
00:00:09,766 --> 00:00:11,966
可惜昨天晚上又加班

295
00:00:25,300 --> 00:00:28,300
DOJO 系列里面的训练系统

296
00:00:46,100 --> 00:00:48,000
进行一个简单的回顾

297
00:00:51,766 --> 00:00:53,866
首先呢我们一直在强调 DOJO 呢

298
00:00:59,766 --> 00:01:00,733
为什么会叫它

299
00:01:21,800 --> 00:01:24,600
接下来打开 DOJO Core 里面去看一下

300
00:01:35,166 --> 00:01:36,966
对比 GPU 呢和 CPU

301
00:01:40,400 --> 00:01:43,166
更多的内容或者更多的电路呢

302
00:01:55,366 --> 00:01:57,133
DOJO 的训练矩阵

303
00:02:15,300 --> 00:02:17,800
第一个呢就是片上的网络路由

304
00:02:43,366 --> 00:02:44,966
在每一个时钟周期内呢

305
00:02:44,966 --> 00:02:47,333
我们可以对 DOJO Core 里面的 SRAM 呢

306
00:02:55,700 --> 00:02:56,200
数据呢

307
00:03:05,366 --> 00:03:06,366
就是我们刚才讲到

308
00:03:10,300 --> 00:03:12,300
最后呢就封装在一块晶圆上面

309
00:03:16,500 --> 00:03:19,400
每个边缘有 4.5TB 每秒的传输带宽

310
00:03:27,166 --> 00:03:29,666
那这个嗯计算算力呢

311
00:03:29,700 --> 00:03:32,800
其实 ZOMI 觉得并不算非常非常的高

312
00:03:44,166 --> 00:03:46,166
或者成倍的倍数

313
00:03:46,400 --> 00:03:46,966
不过呢

314
00:03:46,966 --> 00:03:49,766
值得一提的就是在一个 D1 Die 里面呢

315
00:04:12,100 --> 00:04:12,900
所以这个呢

316
00:04:34,566 --> 00:04:35,566
它这周围呢

317
00:05:01,500 --> 00:05:04,100
这里面呢有两个 HBM 所组成

318
00:05:07,966 --> 00:05:09,766
右边的这一个呢也是 16

319
00:05:19,500 --> 00:05:20,300
我们可以看到呢

320
00:05:24,166 --> 00:05:26,733
就是图上面的这个接口

321
00:05:48,700 --> 00:05:50,300
就是我们的网络

322
00:05:50,400 --> 00:05:52,566
大家注意一下这个外围的设计

323
00:05:56,700 --> 00:05:58,900
就是这里面的一个网口

324
00:06:12,800 --> 00:06:13,366
那现在呢

325
00:06:24,300 --> 00:06:26,200
就是 DIP 其实呢

326
00:06:30,900 --> 00:06:32,300
那这个 z 平面的拓扑呢

327
00:06:35,166 --> 00:06:35,933
非常方便的

328
00:06:54,700 --> 00:06:56,666
下面我们可以看到一个 DOJO D1 呢

329
00:07:01,566 --> 00:07:02,566
那每个 training Tile 呢

330
00:07:27,500 --> 00:07:28,000
从而呢

331
00:07:36,766 --> 00:07:38,933
所示的这种结构

332
00:07:53,566 --> 00:07:54,733
训练的矩阵

333
00:07:57,166 --> 00:07:58,333
有了这些矩阵

334
00:08:10,300 --> 00:08:12,800
那右边的这两个图呢是很有意思的

335
00:08:14,766 --> 00:08:17,466
另外一个呢就是我们的训练的 tile

336
00:08:19,766 --> 00:08:21,333
那我们传输的链路越长

337
00:08:23,966 --> 00:08:25,466
就会越明显

338
00:08:25,566 --> 00:08:27,766
整体的资源利用率呢也会越低

339
00:08:59,166 --> 00:09:01,366
这就会造成我们通讯的瓶颈

340
00:09:10,900 --> 00:09:12,500
也就是我们的 z 维度

341
00:09:25,300 --> 00:09:27,866
都可以将具体使用到的数据

342
00:09:49,900 --> 00:09:51,300
我们之前讲到的

343
00:09:55,500 --> 00:09:57,200
讲到的 NOC 的路由

344
00:10:01,966 --> 00:10:05,066
通过上下左右四个方向进行分发

345
00:10:06,900 --> 00:10:08,400
整个 DOJO D1 里面了

346
00:10:11,300 --> 00:10:12,466
每次快到的时候呢

347
00:10:13,900 --> 00:10:14,800
所以我们可以看到呢

348
00:10:16,966 --> 00:10:18,466
这里面有个 routing table lookup

349
00:10:19,700 --> 00:10:21,100
都有一个 routing table 的 lookup

350
00:10:33,366 --> 00:10:34,966
也就是我们 DOJO Core 里面

351
00:10:36,500 --> 00:10:38,500
刚才讲到的 NOC 的路由呢

352
00:10:39,766 --> 00:10:41,266
对数据呢进行分发

353
00:10:44,766 --> 00:10:46,666
一个就是任务的监控

354
00:10:47,500 --> 00:10:48,000
主要是指

355
00:10:51,900 --> 00:10:53,300
就会到具体的执行

356
00:10:53,300 --> 00:10:54,100
那具体的执行

357
00:11:00,700 --> 00:11:02,900
我们的执行不是一直在执行的

358
00:11:02,966 --> 00:11:03,366
很多时候

359
00:11:03,366 --> 00:11:06,066
我们会在做任务的等待和监控

360
00:11:06,366 --> 00:11:08,266
在没有任务或者没有数据的时候呢

361
00:11:14,166 --> 00:11:18,366
直到我们的远程为 remote data 和 local 的 data

362
00:11:41,100 --> 00:11:43,800
把我们的整个具体的 DOJO Core 呢

363
00:11:52,766 --> 00:11:54,733
进行了一个平面的划分

364
00:12:11,500 --> 00:12:13,600
我们还有在编译器软件栈里面呢

365
00:12:28,100 --> 00:12:28,800
终于来到了

366
00:12:52,100 --> 00:12:52,900
那这个时候呢

367
00:12:55,300 --> 00:12:57,066
或者我们的嗯

368
00:13:03,100 --> 00:13:04,000
的标准的

369
00:13:04,766 --> 00:13:05,666
DOJO 的编译器呢

370
00:13:11,566 --> 00:13:13,166
或者 SLA 这种编译器呢

371
00:13:14,900 --> 00:13:16,700
或者编译有非常大量的工作

372
00:13:18,400 --> 00:13:19,366
我们 DOJO

373
00:13:26,766 --> 00:13:28,866
我们从特斯拉的去年

374
00:13:28,900 --> 00:13:30,066
和今年的 AI 分享会

375
00:13:33,900 --> 00:13:36,500
所以我也是不太看好 DOJO 的一个原因

376
00:13:36,900 --> 00:13:39,000
他花了两年的时间

377
00:13:40,600 --> 00:13:41,700
而建立起来呢

378
00:13:49,166 --> 00:13:50,766
我觉得这是很可耻的

379
00:13:58,000 --> 00:13:59,966
当然了吐槽的事情我们就不多说了

380
00:14:03,100 --> 00:14:04,000
现在第二个问题

381
00:14:14,166 --> 00:14:15,566
如何更好的分配

382
00:14:15,566 --> 00:14:17,266
具体的 DOJO Core 的任务

383
00:14:17,700 --> 00:14:19,466
其实这个就回到刚才第一个问题

384
00:14:24,966 --> 00:14:26,333
所以编辑器如果写的不好

385
00:14:32,966 --> 00:14:33,333
未来

386
00:14:36,766 --> 00:14:37,266
第三点呢

387
00:14:49,166 --> 00:14:50,066
如何有效的

388
00:14:50,100 --> 00:14:52,000
去对我们的代码进行调试呢

389
00:15:36,500 --> 00:15:37,900
那我们怎么去做隔离

390
00:15:43,600 --> 00:15:44,566
DOJO 对硬件呢

391
00:15:44,566 --> 00:15:47,133
其实是做了非常多的定制化阉割的

392
00:16:02,166 --> 00:16:03,533
些都可以有方案

393
00:16:03,566 --> 00:16:05,733
但是可能投入的人力成本

394
00:16:15,200 --> 00:16:16,500
包括 DOJO 整体架构

395
00:16:21,766 --> 00:16:23,933
最后引发一些疑问和思考

396
00:01:36,966 --> 00:01:40,366
它的控制部件少了非常非常的多

397
00:02:40,766 --> 00:02:43,333
都传输一个数据包的输入和输出

398
00:03:32,766 --> 00:03:33,766
其实跟英伟达

399
00:04:54,766 --> 00:04:55,533
我们可以看到

400
00:06:56,600 --> 00:06:58,566
属于一个训练的矩阵里面呢

401
00:07:58,300 --> 00:08:01,400
我们的数据应该怎么去通讯

402
00:08:21,300 --> 00:08:24,000
整个带宽的约束或者带宽的 boundary 呢

403
00:10:46,600 --> 00:10:47,500
那任务的生成呢

404
00:11:10,700 --> 00:11:11,900
从而我们的计算单元呢

405
00:12:13,566 --> 00:12:15,366
做了非常大量的工作

406
00:12:28,766 --> 00:12:31,133
DOJO 系列的最后一个内容了

407
00:14:26,300 --> 00:14:28,100
或者编译器确实呃

408
00:16:23,900 --> 00:16:25,866
希望大家能够坚持到最后

409
00:00:05,566 --> 00:00:06,666
哈喽大家好

410
00:00:21,400 --> 00:00:23,966
好了吐槽的话呢就不多说

411
00:00:40,166 --> 00:00:42,166
引发了最后关于存算一体

412
00:00:44,300 --> 00:00:46,100
DOJO 的整体的结构

413
00:00:49,500 --> 00:00:51,800
整个 DOJO 的架构设计的哲学

414
00:01:24,600 --> 00:01:29,100
DOJO Core 其实呢是由前端执行引擎

415
00:01:31,566 --> 00:01:35,133
最后有一个 NOC 的路由四部分来组成

416
00:01:44,800 --> 00:01:46,766
我们的核心的计算单元

417
00:01:50,566 --> 00:01:53,133
我们来到今天的正式的内容

418
00:02:04,100 --> 00:02:05,500
也就中间的左上角

419
00:02:13,100 --> 00:02:15,266
接着呢我们看一下左边有几个内容

420
00:02:31,700 --> 00:02:33,200
实际上呢 NOC 的路由呢

421
00:03:12,300 --> 00:03:14,866
一个 5 乘以 5 的矩阵

422
00:03:40,166 --> 00:03:41,566
其实是没有说

423
00:03:55,766 --> 00:03:58,266
SRAM 里面最重要的一个设计的思路呢

424
00:04:35,566 --> 00:04:38,366
可以对接非常多的芯片和外围的接口

425
00:04:41,400 --> 00:04:44,000
具体其实就有一种就是 DIP 啊

426
00:04:58,166 --> 00:05:01,533
居然有一个非常大的 HBM

427
00:05:04,100 --> 00:05:05,700
一共呢有 32GB

428
00:05:40,166 --> 00:05:41,533
通过这个 TTP 的协议呢

429
00:05:44,100 --> 00:05:47,466
带宽呢提供给我们 DOJO 的训练的芯片

430
00:06:01,766 --> 00:06:03,466
连接到以太网上面

431
00:06:26,166 --> 00:06:28,466
它把以太网的整个网络呢

432
00:06:32,366 --> 00:06:34,933
是非常重要方便我们数据的

433
00:06:51,766 --> 00:06:52,666
或者训练矩阵

434
00:07:48,966 --> 00:07:51,866
整个 DOJO 的训练的主机

435
00:08:08,366 --> 00:08:10,266
在整个通讯的方式里面

436
00:08:12,766 --> 00:08:14,733
首先呢一个就是我们的训练的 Die

437
00:09:08,366 --> 00:09:10,866
而且还提供了另外一种网络的维度

438
00:09:27,800 --> 00:09:31,000
send 和 save 到不同的 SRAM 或者 DRAM 里面

439
00:09:47,366 --> 00:09:48,066
那 DOJO Core 呢

440
00:09:57,166 --> 00:09:59,933
对我们的数据呢进行连接和同步

441
00:10:08,366 --> 00:10:09,866
这就是整个 DOJO D1 嘛

442
00:10:12,400 --> 00:10:13,900
都会进行一个查表

443
00:10:14,766 --> 00:10:16,933
这里面有个 routing table lookup

444
00:10:42,800 --> 00:10:44,766
一个呢就是任务的生成

445
00:10:47,966 --> 00:10:50,733
我们从远程去获取具体的数据包

446
00:11:06,100 --> 00:11:06,400
所以呢

447
00:13:03,966 --> 00:13:04,766
那这个时候呢

448
00:13:05,600 --> 00:13:09,100
就会跟业界的编译器差异非常的大

449
00:13:13,366 --> 00:13:14,933
那可能很难对接

450
00:13:30,000 --> 00:13:31,300
其实可以看到

451
00:13:39,000 --> 00:13:40,600
才把 ExaPOD 建立起来

452
00:14:03,966 --> 00:14:04,966
我们可以看到啊

453
00:14:19,400 --> 00:14:22,200
他大量的依赖于我们的编译栈

454
00:15:06,166 --> 00:15:08,466
或者在特斯拉的会上没有太提的

455
00:15:52,766 --> 00:15:54,266
基本上这个服务器呢

456
00:00:01,533 --> 00:00:04,233
字幕生成：mkwei  字幕校准：mkwei

457
00:00:11,966 --> 00:00:14,566
到凌晨 12 点半才回来

458
00:00:29,766 --> 00:00:31,866
在整个 AI 芯片基础里面呢

459
00:01:06,300 --> 00:01:07,866
里面最小的一个单元呢

460
00:01:12,700 --> 00:01:14,200
我们的 DOJO D1

461
00:01:57,166 --> 00:01:59,133
也就是 DOJO 的训练系统

462
00:02:49,700 --> 00:02:52,066
因此呢我们可以在内核里面呢

463
00:03:00,566 --> 00:03:02,533
实际上我们关心的 Training Tile 呢

464
00:03:33,800 --> 00:03:36,966
的 A100 320TFlops 呢

465
00:04:01,300 --> 00:04:04,500
片上存储之间就是 SRAM 和 SRAM 之间的流转

466
00:04:23,900 --> 00:04:24,400
这里面呢

467
00:04:55,500 --> 00:04:57,900
在一块外围的接入的设备

468
00:05:13,166 --> 00:05:15,133
这个传输速率也是非常的高的

469
00:05:30,300 --> 00:05:33,700
不过呢里面的实现的传输的协议呢

470
00:05:59,200 --> 00:05:59,766
这个网口呢

471
00:06:15,600 --> 00:06:18,166
实际上呢 5*5 形成一排

472
00:06:41,600 --> 00:06:43,800
传输到 DOJO Core 里面

473
00:06:52,700 --> 00:06:53,866
训练芯片里面

474
00:07:05,800 --> 00:07:08,500
有每个 D1 Die 呢就有 300 多个 DOJO Core

475
00:07:18,100 --> 00:07:20,900
我们的刚才讲到的 DIP

476
00:07:31,500 --> 00:07:33,700
或者 DOJO 的训练服务器

477
00:07:56,166 --> 00:07:57,166
有了这些主机

478
00:08:01,400 --> 00:08:02,766
怎么去传输

479
00:08:04,500 --> 00:08:06,100
刚才上面讲的内容有点多了

480
00:09:45,300 --> 00:09:47,400
就是具体的一个 DOJO Core

481
00:11:25,200 --> 00:11:28,000
我们刚才谈到了一个 5 乘以 5 的矩阵

482
00:13:02,100 --> 00:13:03,066
或者没有一个业界

483
00:14:42,566 --> 00:14:45,533
其实阉割掉非常非常多的模块

484
00:15:39,100 --> 00:15:42,000
这个时候就变得非常非常的重要了

