1
00:00:00,140 --> 00:00:04,700
字幕生成: 粟君杰字幕校对: 粟君杰

2
00:00:04,790 --> 00:00:05,900
Hello，大家好

3
00:00:05,900 --> 00:00:06,920
我是 ZOMI

4
00:00:06,920 --> 00:00:08,540
来到了大模型与

5
00:00:08,540 --> 00:00:09,760
分布式训练

6
00:00:09,760 --> 00:00:14,320
分布式分布式并行里面的最后一个环节了

7
00:00:14,320 --> 00:00:17,020
接近最后一个环节就是流水并行

8
00:00:17,020 --> 00:00:18,460
Pipeline 并行

9
00:00:18,460 --> 00:00:21,640
那之前呢，了解了分布式并行的数据并行

10
00:00:21,640 --> 00:00:22,360
模型并行

11
00:00:22,360 --> 00:00:23,620
或者叫做张量并行

12
00:00:23,620 --> 00:00:25,520
然后到流水线并行

13
00:00:25,520 --> 00:00:27,680
最后还会有一个环节

14
00:00:27,680 --> 00:00:31,420
就是把刚才前面的这些并行呢，组合起来

15
00:00:31,420 --> 00:00:32,680
变成一个混合并行

16
00:00:32,680 --> 00:00:37,560
今天的内容呢，主要是集中在模型并行

17
00:00:37,560 --> 00:00:37,980
里面的

18
00:00:37,980 --> 00:00:38,820
流水线并行

19
00:00:38,820 --> 00:00:40,920
又叫做 Pipeline Parallelism

20
00:00:40,920 --> 00:00:43,380
那这里面呢，会分开三个内容来讲

21
00:00:43,380 --> 00:00:45,420
第一个就是最原始的流水并行

22
00:00:45,420 --> 00:00:46,760
到底是个什么东西

23
00:00:46,760 --> 00:00:48,560
然后呢，会分享两篇论文

24
00:00:48,560 --> 00:00:50,810
第一篇就是谷歌的 Gpipe

25
00:00:50,810 --> 00:00:54,360
第二篇就是微软的 PipeDream

26
00:00:54,520 --> 00:00:57,300
下面来看看流水并行的一个概念

27
00:00:57,300 --> 00:00:58,800
其实上一个视频呢

28
00:00:58,800 --> 00:01:02,260
已经简单的去给大家去分享了一个流水并行

29
00:01:02,260 --> 00:01:04,660
流水并行呢，主要是层间的并行

30
00:01:04,660 --> 00:01:06,800
我把网络模型的不同的层

31
00:01:06,800 --> 00:01:09,290
放在不同的设备上面去执行

32
00:01:09,290 --> 00:01:13,050
这里面呢，引入一个概念叫做 stage 或者叫做阶段

33
00:01:13,050 --> 00:01:15,270
我可能 Device 1 可以把第一层

34
00:01:15,270 --> 00:01:16,380
第二层放进去

35
00:01:16,380 --> 00:01:18,240
这个呢，叫做 stage 1

36
00:01:18,240 --> 00:01:20,640
把第三层放在 Device 2 的时候

37
00:01:20,640 --> 00:01:22,320
可能会叫做 stage 2

38
00:01:22,320 --> 00:01:23,710
以此类推

39
00:01:23,710 --> 00:01:25,450
俺也一样

40
00:01:25,450 --> 00:01:29,260
接下来呢，换一个角度去看待这个问题

41
00:01:29,260 --> 00:01:32,780
因为流水并行呢，实际上是跟时间有关系的

42
00:01:32,780 --> 00:01:35,300
所以现在换了一种表达的方式

43
00:01:35,300 --> 00:01:37,020
由右边的这幅图所示

44
00:01:37,020 --> 00:01:38,640
左边的这个示例图里面呢

45
00:01:38,640 --> 00:01:40,800
把每一层当做一个 stage

46
00:01:40,800 --> 00:01:42,960
放在一台不同的设备里面

47
00:01:42,960 --> 00:01:45,900
首先我会做一个正向的计算

48
00:01:45,900 --> 00:01:48,690
然后通过我的 Loss 做一个反向的计算

49
00:01:48,690 --> 00:01:51,040
然后放在三个不同的卡

50
00:01:51,040 --> 00:01:52,750
放到右边的这个图呢

51
00:01:52,750 --> 00:01:53,920
F 代表我的正向 Forward

52
00:01:53,920 --> 00:01:56,640
B 呢，代表我的反向 Backword

53
00:01:56,640 --> 00:01:59,220
可以看到每一块机器都去执行

54
00:01:59,220 --> 00:02:01,130
自己层之间的一个计算

55
00:02:01,130 --> 00:02:04,490
最后再统一对四个卡进行更新

56
00:02:04,490 --> 00:02:08,180
那这种呢，就是最 Naive 的并行方式

57
00:02:08,180 --> 00:02:11,420
Naive 的 Papeline 并行呢，其实有一个很大的问题

58
00:02:11,420 --> 00:02:14,780
就是会有大量的等待和阻塞的时间

59
00:02:14,780 --> 00:02:16,900
可以看到中间的空载的时间

60
00:02:16,900 --> 00:02:19,000
就是我的机器啥都不执行

61
00:02:19,000 --> 00:02:20,620
就在那等待的时间

62
00:02:20,620 --> 00:02:24,770
我刚才黄线画的这些地方是非常的多的

63
00:02:24,770 --> 00:02:28,420
科学家们呢，又引入了另外一种并行模式

64
00:02:28,420 --> 00:02:31,000
叫做 Mini-batch 的 Pipeline 并行

65
00:02:31,000 --> 00:02:33,700
刚才 F0 呢，是整一个连在一起的

66
00:02:33,700 --> 00:02:35,830
他执行的是一个 batch

67
00:02:35,830 --> 00:02:39,440
现在把一个 batch 拆分成很多小的 batch

68
00:02:39,440 --> 00:02:42,230
通过小的 batch 去进行一个计算

69
00:02:42,230 --> 00:02:44,720
这个时候就可以充分的利用了

70
00:02:44,720 --> 00:02:46,960
计算和通信的时间

71
00:02:46,960 --> 00:02:50,860
把一个大的 batch 拆分成很多小的 Mini-batch 之后

72
00:02:50,860 --> 00:02:52,750
或者叫做 micro-batches 之后呢

73
00:02:52,750 --> 00:02:55,020
这个 AI 框架或者 AI 系统

74
00:02:55,020 --> 00:02:58,440
就可以充分的去利用芯片的计算时间

75
00:02:58,440 --> 00:03:00,780
还有运算的空载的时间

76
00:03:00,780 --> 00:03:06,020
使得 bubble，机器空载的时间呢越少

77
00:03:06,020 --> 00:03:07,220
另外一个好处就是

78
00:03:07,220 --> 00:03:11,180
机器跟机器之间的相互等待的时间也越少

79
00:03:11,180 --> 00:03:12,500
这里面可以看到

80
00:03:12,500 --> 00:03:15,560
F10 跟 F01 之间是并行去操作的

81
00:03:15,560 --> 00:03:18,020
Device 0 在执行计算的时候

82
00:03:18,020 --> 00:03:19,940
Device 1 也开始执行了

83
00:03:19,940 --> 00:03:23,370
就是我一个小的 batch 在 F00 里面执行完之后

84
00:03:23,370 --> 00:03:26,720
我去把下一个数据传给我的 F10 

85
00:03:26,720 --> 00:03:27,320
F10 

86
00:03:27,320 --> 00:03:29,000
计算完之后传给我的 F20 

87
00:03:29,000 --> 00:03:30,680
然后再传给我的 F30 

88
00:03:30,680 --> 00:03:33,260
而 Mini-batch 里面最经典的一篇文章呢

89
00:03:33,260 --> 00:03:34,340
就是 Gpipe

90
00:03:34,340 --> 00:03:35,960
谷歌 2019 年的时候

91
00:03:35,960 --> 00:03:38,880
发明的一个流水线并行的一篇文章

92
00:03:38,880 --> 00:03:42,180
这篇文章提出了三个比较重要的概念

93
00:03:42,180 --> 00:03:43,920
第一个是 Partition Stage

94
00:03:43,920 --> 00:03:46,760
就是把网络模型分开不同的阶段

95
00:03:46,760 --> 00:03:50,570
第二个呢，就是在 pipline 里面去引入了 Micro-Batch

96
00:03:50,570 --> 00:03:55,240
第三个就是重计算下面一起来看看这篇文章

97
00:03:55,240 --> 00:03:59,020
接下来让有请下一位学员登场

98
00:03:59,020 --> 00:04:00,760
GPipe 这篇文章呢

99
00:04:00,760 --> 00:04:04,100
叫做 Easy Scaling with Micro-Batch Pipeline Parallelism

100
00:04:04,100 --> 00:04:07,250
其中 Micro-Batch 是一个比较重要的概念

101
00:04:07,250 --> 00:04:10,910
第二个比较重要的概念就是 Pipeline Parallelism

102
00:04:10,910 --> 00:04:15,040
流水线并行里面很重要的一点就是

103
00:04:15,040 --> 00:04:17,500
网络模型的切分成不同的 stage

104
00:04:17,500 --> 00:04:19,399
不是按照一层一层的切的

105
00:04:19,399 --> 00:04:23,460
而是可能会两三层变成一个 stage 进行切分

106
00:04:23,460 --> 00:04:27,600
第二点就是把 Mini-batch 呢进一步的划分成为

107
00:04:27,600 --> 00:04:28,960
Micro-Batch

108
00:04:28,960 --> 00:04:32,600
充分的去利用流水线并行的一个效率

109
00:04:32,600 --> 00:04:34,460
这个刚才已经讲过了

110
00:04:34,460 --> 00:04:36,500
我 f00 执行完之后呢

111
00:04:36,500 --> 00:04:39,270
就可以传给下一层执行 F10 

112
00:04:39,270 --> 00:04:40,800
F10 算完之后呢

113
00:04:40,800 --> 00:04:43,050
就给在下一层 F20 

114
00:04:43,050 --> 00:04:45,500
然后等整一层算完之后

115
00:04:45,500 --> 00:04:48,020
等所有的 Mini-batch 执行完之后呢

116
00:04:48,020 --> 00:04:50,740
就开始按照 Micro-Batch 的方式

117
00:04:50,740 --> 00:04:54,130
在进行每一个数据的反向计算

118
00:04:54,130 --> 00:04:56,600
最后呢进行一个统一的更新

119
00:04:56,600 --> 00:04:59,090
这个就是 Micro-Batch 带来的好处

120
00:04:59,090 --> 00:05:02,020
而文章里面就详细的说明了

121
00:05:02,020 --> 00:05:05,320
Micro-Batch 可以使得网络模型的 Bubble

122
00:05:05,320 --> 00:05:09,419
计算的空载时间压缩的非常的小

123
00:05:09,419 --> 00:05:11,639
在网络模型优化的阶段呢

124
00:05:11,639 --> 00:05:14,489
GPipe 提出了一个从计算的概念

125
00:05:14,489 --> 00:05:16,679
也就是在反向计算的时候呢

126
00:05:16,679 --> 00:05:18,300
我计算 B03 的时候

127
00:05:18,300 --> 00:05:22,260
实际上我是依赖于 F03 的前一项的结果

128
00:05:22,260 --> 00:05:25,530
F03 前向的计算的结果的输出

129
00:05:25,530 --> 00:05:27,720
需要缓存到内存里面

130
00:05:27,720 --> 00:05:32,510
网络模型的激活计算的数据量是非常大的

131
00:05:32,510 --> 00:05:35,480
如果把 F00 F01 F02 F03 

132
00:05:35,480 --> 00:05:38,160
包括前面的所有都缓存起来

133
00:05:38,160 --> 00:05:40,740
然后再给后面去计计算的时候

134
00:05:40,740 --> 00:05:44,020
动态内存就会急剧的增加

135
00:05:44,020 --> 00:05:45,520
所以呢，文章里面呢

136
00:05:45,520 --> 00:05:48,070
刚才就提出了一个重计算的概念

137
00:05:48,070 --> 00:05:49,960
就是我在反向的时候呢

138
00:05:49,960 --> 00:05:51,960
不用正向的时候的结果

139
00:05:51,960 --> 00:05:54,740
而是重新算一遍正向的结果

140
00:05:54,740 --> 00:05:58,010
晶体管的计算的速率是非常高的

141
00:05:58,010 --> 00:05:59,900
远大于内存的消耗

142
00:05:59,900 --> 00:06:01,360
还有内存的搬运

143
00:06:01,360 --> 00:06:04,810
所以呢，这里面就提出了一个简单的优化的概念

144
00:06:04,810 --> 00:06:08,780
使得 GPine 里面可以存放更大的网络模型

145
00:06:08,780 --> 00:06:10,970
那从实验结果可以看到啊

146
00:06:10,970 --> 00:06:13,520
一个简单的原始的模型在 naive 的情况下

147
00:06:13,520 --> 00:06:17,800
最多只能存下 6.26 个 GB

148
00:06:17,800 --> 00:06:20,140
但是在八卡优化的情况下

149
00:06:20,140 --> 00:06:21,910
可以存下 26 个 GB

150
00:06:21,910 --> 00:06:23,920
而使用 TPU 这个硬件

151
00:06:23,920 --> 00:06:26,500
使用 naive 的 Pipeline 并行呢

152
00:06:26,500 --> 00:06:28,440
最多只能存 3.15G

153
00:06:28,440 --> 00:06:31,800
但是使用 GPipeline 在 128 卡里面呢

154
00:06:31,800 --> 00:06:35,240
可以塞得下 800 个 GB 的 Transformer 的网络模型

155
00:06:35,240 --> 00:06:37,340
所以这是非常夸张的一个概念

156
00:06:39,260 --> 00:06:41,570
了解完了 naive 的流水并行

157
00:06:41,570 --> 00:06:44,180
还有 GPipeline 的流水并行之后呢

158
00:06:44,180 --> 00:06:47,030
现在来看看流水并行其实有两种模式啊

159
00:06:47,030 --> 00:06:49,760
刚才讲的都是 F-then-B

160
00:06:49,760 --> 00:06:53,250
就是 Forward-then-Backword 这种模式

161
00:06:53,250 --> 00:06:55,080
先算完每台机器

162
00:06:55,080 --> 00:06:56,820
每个 Mini-Batch 的正向

163
00:06:56,820 --> 00:06:59,550
然后再算每个 Mini-Batch 的反向

164
00:06:59,550 --> 00:07:02,190
这里面呢，可能用一个 batch 来去代替

165
00:07:02,190 --> 00:07:05,400
但实际上在 GPipeline 里面是用了 Micro-Batch

166
00:07:05,400 --> 00:07:07,680
那同样的在第二个 stage 的时候呢

167
00:07:07,680 --> 00:07:09,520
我还是算完我的正向

168
00:07:09,520 --> 00:07:11,470
然后再上反向

169
00:07:11,470 --> 00:07:15,040
所以这里面呢叫做 F-then-B，Forward-then-Backword

170
00:07:15,040 --> 00:07:16,960
微软在 2021 年之后呢

171
00:07:16,960 --> 00:07:20,800
就提出了一个 one Forward and one Backword 的这种模式

172
00:07:20,800 --> 00:07:23,500
就是我算完一个正向之后

173
00:07:23,500 --> 00:07:24,920
全部算完一个正向

174
00:07:24,920 --> 00:07:28,310
我马上就开始一个反向的计算了

175
00:07:28,310 --> 00:07:29,840
在第二个 Micro-Batch 的时候

176
00:07:29,840 --> 00:07:32,780
我算完第二个前项的时候呢

177
00:07:32,780 --> 00:07:34,880
马上进行第二个后项

178
00:07:34,880 --> 00:07:37,340
以这种方式去进行计算

179
00:07:37,340 --> 00:07:41,710
可以看到极大的去减少了机器的空载的时间

180
00:07:41,710 --> 00:07:45,319
也就是中间的 Bubble 少了非常的多

181
00:07:45,319 --> 00:07:47,329
但是大家有没有发现呢

182
00:07:47,329 --> 00:07:52,289
在当 startup status 就是我初始的阶段或者能启动的阶段

183
00:07:52,289 --> 00:07:55,139
流水线的序列还是比较有序的

184
00:07:55,139 --> 00:07:57,200
但是到后面的阶段

185
00:07:57,200 --> 00:08:00,740
基本上就密密麻麻的越来越乱了

186
00:08:00,740 --> 00:08:02,900
那下面呢来看看 PipeDream

187
00:08:02,900 --> 00:08:05,400
这篇文章到底是怎么解决这个问题的

188
00:08:05,400 --> 00:08:09,540
同时也去看一下 GPipe 遇到哪些问题

189
00:08:09,540 --> 00:08:12,760
所以微软的人才会提出 GPipe

190
00:08:12,810 --> 00:08:15,580
现在已经打开了 PipeDream 这篇文章

191
00:08:15,580 --> 00:08:17,320
翻到有图的地方

192
00:08:17,320 --> 00:08:18,460
一般没有图的地方了

193
00:08:18,460 --> 00:08:20,720
我觉得唉，很难去看这篇文章的

194
00:08:20,720 --> 00:08:22,570
或者已经看不下去了啊

195
00:08:22,570 --> 00:08:23,950
诶嘿嘿嘿

196
00:08:23,950 --> 00:08:25,540
那翻到有图的地方

197
00:08:25,540 --> 00:08:29,050
这个 tree 呢，就是 GPipe 的一种具体的格式

198
00:08:29,050 --> 00:08:31,490
放大一点去看一看啊

199
00:08:31,490 --> 00:08:34,880
可以看到其实分了非常多的 Mini-Batch1 2 3 4

200
00:08:34,880 --> 00:08:36,860
反向的时候呢

201
00:08:36,860 --> 00:08:38,180
为什么会两个 1 呢

202
00:08:38,180 --> 00:08:41,840
是因为有一个 1 呢，是重新计算正向

203
00:08:41,840 --> 00:08:43,610
然后再进行反向计算的

204
00:08:43,610 --> 00:08:46,400
那这里面呢，只是比 GPipeline 里面的那个图

205
00:08:46,400 --> 00:08:47,420
画的更清楚

206
00:08:47,420 --> 00:08:49,910
实际上它还是 GPipeline 的一个格式

207
00:08:49,910 --> 00:08:52,880
可以看到 GPipeline 最重要的一个概念

208
00:08:52,880 --> 00:08:54,500
就是提出了 Micro-Batch

209
00:08:54,500 --> 00:08:57,180
就是我的网络模型的 Batch

210
00:08:57,180 --> 00:08:58,980
切分得越细越好

211
00:08:58,980 --> 00:09:01,540
中间的空载的时间就会越少

212
00:09:01,540 --> 00:09:04,210
但是这就会引起一个问题哦

213
00:09:04,210 --> 00:09:07,150
会引起了大量的前向的重计算

214
00:09:07,150 --> 00:09:11,220
另外的话还会引起了频繁的流水线的交互

215
00:09:11,220 --> 00:09:15,060
使得运算的时间进一步的拖长

216
00:09:15,060 --> 00:09:19,160
就是我的效率会降低，第二就是大量的重计算

217
00:09:19,160 --> 00:09:21,260
会导致网络模型的权重

218
00:09:21,260 --> 00:09:24,660
还有激活的中间变量急剧的上升

219
00:09:24,660 --> 00:09:26,580
本来做重计算的

220
00:09:26,580 --> 00:09:29,400
是为了解决内存下降的问题

221
00:09:29,400 --> 00:09:32,520
使得动态内存少很多

222
00:09:32,520 --> 00:09:35,800
通过计算去换取动态内存的空间

223
00:09:35,800 --> 00:09:37,780
但是我的 Micro-Batch 越多

224
00:09:37,780 --> 00:09:39,460
我要做大量的重计算

225
00:09:39,460 --> 00:09:42,420
这个时候呢，就会引起整个 ai 系统里面的

226
00:09:42,420 --> 00:09:45,870
权重和激活的中间变量变得更多

227
00:09:45,870 --> 00:09:47,580
这时候静态内存块或

228
00:09:47,580 --> 00:09:49,530
动态内存就提上去了

229
00:09:49,530 --> 00:09:51,460
为了解决这两个问题呢

230
00:09:51,460 --> 00:09:55,740
所以微软呢就提出了 PipeDream 的这个解决方案

231
00:09:55,740 --> 00:09:59,100
PipeDream 呢，对训练的阶段划分成为两个

232
00:09:59,100 --> 00:10:00,990
第一个呢，是 start up 的阶段

233
00:10:00,990 --> 00:10:03,440
第二个呢，就是 steady 的阶段

234
00:10:03,440 --> 00:10:05,390
就是稳态和初始态

235
00:10:05,390 --> 00:10:06,620
初始态的时候呢

236
00:10:06,620 --> 00:10:09,980
可能还是正常的分开很多个 Micro-Batch

237
00:10:09,980 --> 00:10:11,140
或者叫做 Mini-Batch

238
00:10:11,140 --> 00:10:14,950
PipeDream 里面的 Mini-Batch 是等同于 Mini-Batch 的 Micro-Batch 的

239
00:10:14,950 --> 00:10:17,200
我去划分成很多的 Micro-Batch

240
00:10:17,200 --> 00:10:19,640
然后再进行反向的计算

241
00:10:19,640 --> 00:10:21,140
但是反向的计算呢

242
00:10:21,140 --> 00:10:24,760
我是使用刚才介绍的 1F1B 这种方式

243
00:10:24,760 --> 00:10:26,500
ai 系统执行一个正向

244
00:10:26,500 --> 00:10:28,000
马上执行一个反向

245
00:10:28,000 --> 00:10:29,020
执行一个正向

246
00:10:29,020 --> 00:10:31,100
马上再执行一个反向

247
00:10:31,100 --> 00:10:32,660
通过这种方式

248
00:10:32,660 --> 00:10:35,900
使得在 steady state 就是稳态的时候呢

249
00:10:35,900 --> 00:10:38,420
使得 ai 系统啊基本上没有 buble

250
00:10:38,420 --> 00:10:40,580
可以看到后面密密麻麻的

251
00:10:40,580 --> 00:10:43,990
基本上做完跟前项要进行后项 ai 芯片

252
00:10:43,990 --> 00:10:48,070
升腾的 ai 芯片在 steady state 的时候是非常的繁忙的

253
00:10:48,070 --> 00:10:50,220
基本上都一直在进行计算

254
00:10:50,220 --> 00:10:52,950
另外通信也是非常的繁忙的

255
00:10:52,950 --> 00:10:56,480
不断的去进行一个通信的同步和数据的传输

256
00:10:56,480 --> 00:10:57,800
图还是这个图

257
00:10:57,800 --> 00:11:00,720
虽然 steady state 呢，让 Bubble 进一步减少了

258
00:11:00,720 --> 00:11:02,850
但是大家有没有发现一个问题

259
00:11:02,850 --> 00:11:05,790
后面的这一坨非常的乱

260
00:11:05,790 --> 00:11:08,660
我的权重到底什么时候更新

261
00:11:08,660 --> 00:11:11,200
我的梯度什么时候同步

262
00:11:11,200 --> 00:11:14,050
这引起了一个很严峻的问题

263
00:11:14,050 --> 00:11:18,340
所以在 PipeDream 这篇文章又提出了两个概念

264
00:11:18,340 --> 00:11:21,400
第一个解决方案呢，就是 Weight Stashing

265
00:11:21,400 --> 00:11:23,830
中文叫做权重隐藏

266
00:11:23,830 --> 00:11:27,020
第二个解决方案，就是 Vertical Sync

267
00:11:27,020 --> 00:11:29,450
垂直同步两个概念

268
00:11:29,450 --> 00:11:34,840
下面来逐个的去看一下，Weight Stashing 呢

269
00:11:34,840 --> 00:11:37,660
可以看到右边的多了一个红色的框框

270
00:11:37,660 --> 00:11:40,160
它意味着为每一个激活

271
00:11:40,160 --> 00:11:43,490
或者每一个计算的输出都保存一份

272
00:11:43,490 --> 00:11:44,900
前向计算的时候呢

273
00:11:44,900 --> 00:11:47,440
每个都是用最新的参数数据处理

274
00:11:47,440 --> 00:11:48,880
Mini-Batch 的

275
00:11:48,880 --> 00:11:51,520
然后把这份参数呢，保存下来

276
00:11:51,520 --> 00:11:54,740
用于同一个 Mini-Batch 的后项的计算

277
00:11:54,740 --> 00:11:58,360
对第五个 Mini-Batch 进行前向计算的时候

278
00:11:58,360 --> 00:12:02,800
用的是前一个最新的反向计算的一个激活

279
00:12:02,800 --> 00:12:05,680
去更新第五个的正向计算

280
00:12:05,680 --> 00:12:08,740
然后呢，第五个的反向计算的时候呢

281
00:12:08,740 --> 00:12:11,200
保留了前项计算一的这份权重

282
00:12:11,200 --> 00:12:13,030
然后呢，丢给 5 去计算

283
00:12:13,030 --> 00:12:15,820
但是呢，5 的时候已经经过了 2 3 4 了

284
00:12:15,820 --> 00:12:19,000
所以系统里面会同时去维护权重

285
00:12:19,000 --> 00:12:21,620
1 2 3 4 这几份

286
00:12:21,620 --> 00:12:24,500
worker 3 在第五个 Mini-Batch 前项计算的时候呢

287
00:12:24,500 --> 00:12:28,270
用的是 Mini-Batch 3 的反向的权重参数

288
00:12:28,270 --> 00:12:31,690
然后 Mini-Batch 3 的反向的权重参数

289
00:12:31,690 --> 00:12:34,150
Mini-Batch 5 反向的时候呢

290
00:12:34,150 --> 00:12:37,560
同样更新的时候用的是 Mini-Batch 3

291
00:12:37,560 --> 00:12:39,000
反向的权重参数

292
00:12:39,000 --> 00:12:42,600
还有 Mini-Batch 5 正向的权重

293
00:12:42,600 --> 00:12:45,420
所以 ai 系统呢会维护一个 Mini-Batch 3

294
00:12:45,420 --> 00:12:48,619
和 Mini-Batch 4 的权重版本

295
00:12:48,619 --> 00:12:51,619
保证我的正向和反向是相关联的

296
00:12:51,619 --> 00:12:53,869
而不算我的 2 的反向的时候呢

297
00:12:53,869 --> 00:12:55,440
用的是 5 的正向

298
00:12:55,440 --> 00:12:58,060
我算 4 的反向的时候用的是 7 的正向

299
00:12:58,060 --> 00:12:59,170
不是这么来的

300
00:12:59,170 --> 00:13:02,500
我算 5 的反向的时候用的是 5 的正向

301
00:13:02,500 --> 00:13:06,100
这样才能够使得权重参数能够对应上来

302
00:13:06,100 --> 00:13:08,600
不会随便的被刷新

303
00:13:08,600 --> 00:13:10,580
使得网络模型不收敛

304
00:13:10,580 --> 00:13:12,140
计算 Mini-Batch 5 的时候

305
00:13:12,140 --> 00:13:14,740
我用的是 Mini-Batch 1 去更新的

306
00:13:14,740 --> 00:13:16,300
所以在 worker 1 的时候

307
00:13:16,300 --> 00:13:18,550
我去计算 Mini-Batch 5 的正向

308
00:13:18,550 --> 00:13:21,160
同样 Mini-Batch 1 的反向

309
00:13:21,160 --> 00:13:24,400
在 worker 3 Mini-Batch 5 计算的时候

310
00:13:24,400 --> 00:13:28,460
我用的仍然是 worker 3 Mini-Batch 1 的反向

311
00:13:28,460 --> 00:13:29,630
以此类推

312
00:13:29,630 --> 00:13:31,370
在论文的实验里面的

313
00:13:31,370 --> 00:13:34,040
作者就告诉一个很重要的概念

314
00:13:34,040 --> 00:13:36,080
就是前面的 Weight Stashing

315
00:13:36,080 --> 00:13:38,540
权重隐藏这个功能

316
00:13:38,540 --> 00:13:41,660
其实已经很好的对网络模型的参数

317
00:13:41,660 --> 00:13:42,800
进行了同步了

318
00:13:42,800 --> 00:13:44,060
所以一般来说呢

319
00:13:44,060 --> 00:13:46,620
在超大规模网络模型训练的时候

320
00:13:46,620 --> 00:13:50,460
如果真的不是因为流水线并行引起的不收敛

321
00:13:50,460 --> 00:13:54,130
那他们默认是关闭垂直同步的

322
00:13:54,130 --> 00:13:56,080
只使用了权重隐藏

323
00:13:56,080 --> 00:14:00,350
Weight Stashing 这个功能在 PipeDream 这篇文章里面

324
00:14:00,350 --> 00:14:04,880
毫无悬念的就是它的效果性能还是非常的好的

325
00:14:04,880 --> 00:14:08,320
这里面呢就不跟大家一起去看实验结果了

326
00:14:08,320 --> 00:14:10,240
下面呢，来总结一下

327
00:14:10,240 --> 00:14:12,700
今天流水线并行的一个概念

328
00:14:12,700 --> 00:14:16,540
首先呢，模型并行主要分为张量并行和流水并行

329
00:14:16,540 --> 00:14:18,080
也叫做流水线并行啊

330
00:14:18,080 --> 00:14:20,120
张量并行呢，是层内并行

331
00:14:20,120 --> 00:14:23,360
流水线并行呢，用作层间并行

332
00:14:23,360 --> 00:14:26,120
那流水线并行作为模型并行的一部分呢

333
00:14:26,120 --> 00:14:28,020
一般不会单独去使用的

334
00:14:28,020 --> 00:14:29,400
而是通过混合

335
00:14:29,400 --> 00:14:32,640
张量并行和数据并行进行一起使用的

336
00:14:32,640 --> 00:14:36,000
刚才只是单单的去拎出了流水线并行

337
00:14:36,000 --> 00:14:38,000
来去讨论这个原理

338
00:14:38,000 --> 00:14:39,920
在下一个内容里面

339
00:14:39,920 --> 00:14:41,200
就会讲讲

340
00:14:41,200 --> 00:14:43,990
如何执行一个混合并行的网络模型

341
00:14:43,990 --> 00:14:46,120
那另外的话流水线并行呢

342
00:14:46,120 --> 00:14:49,660
从最 Naive 的方式到 F-then-B 的模式

343
00:14:49,660 --> 00:14:51,160
逐渐发展到 1F1B

344
00:14:51,160 --> 00:14:53,960
1F1B 就是一个正向一个反向的模式

345
00:14:53,960 --> 00:14:55,640
从另外一个方面来看呢

346
00:14:55,640 --> 00:14:58,180
从 Mini-Batch 发展到 Micro-Batch

347
00:14:58,180 --> 00:15:02,000
每批次处理数据的力度呢，会更加的细

348
00:15:02,000 --> 00:15:04,760
这个视频呢，讲的时间会非常的短

349
00:15:04,760 --> 00:15:07,550
只是给大家带来一个概念上的认知

350
00:15:07,550 --> 00:15:10,440
或者一起去探讨更新的一些技术

351
00:15:10,440 --> 00:15:14,640
周米更加希望大家真的去看一下 GPipe 和 PipeDream

352
00:15:14,640 --> 00:15:15,780
这两篇文章呢

353
00:15:15,780 --> 00:15:18,990
是有非常多的知识值得去学习的

354
00:15:18,990 --> 00:15:20,220
卷的不行了

355
00:15:20,220 --> 00:15:21,120
卷的不行了

356
00:15:21,120 --> 00:15:22,760
记得一键三连加关注哦

357
00:15:22,760 --> 00:15:24,260
所有的内容都会开源

358
00:15:24,260 --> 00:15:27,200
在下面这条链接里面，拜了个拜