1
00:00:00,140 --> 00:00:04,700
字幕生成: 粟君杰字幕校对: 粟君杰

1
00:00:05,120 --> 00:00:06,100
哈喽，大家好

2
00:00:06,100 --> 00:00:07,300
我是 ZOMI

3
00:00:07,300 --> 00:00:11,540
今天对分布式训练这个系列呢，来个总结

4
00:00:11,540 --> 00:00:12,320
可以看到

5
00:00:12,320 --> 00:00:15,200
其实之前呢，讲了非常多的内容

6
00:00:15,200 --> 00:00:17,900
那这些内容呢，还是比较散点的

7
00:00:17,900 --> 00:00:18,920
有架构呢

8
00:00:18,920 --> 00:00:19,640
有通信呢

9
00:00:19,640 --> 00:00:20,619
有算法了

10
00:00:20,619 --> 00:00:22,689
还有大模型并行的一些策略

11
00:00:22,689 --> 00:00:24,999
但是往下看一看

12
00:00:24,999 --> 00:00:26,080
what

13
00:00:26,279 --> 00:00:31,019
怎么感觉每一个封面都长得差不多那个样子

14
00:00:34,199 --> 00:00:36,330
这里面呢，不好意思啊

15
00:00:36,330 --> 00:00:39,620
那个我看到我的阅读量确实有点少啊

16
00:00:39,620 --> 00:00:43,460
只有，基本上每个视频只有 50 多个浏览量了

17
00:00:43,460 --> 00:00:46,370
可能有部分视频还只有十几个浏览量

18
00:00:46,370 --> 00:00:48,500
基本上没人看了

19
00:00:48,500 --> 00:00:49,220
不过没关系

20
00:00:49,220 --> 00:00:50,779
我还是在坚持

21
00:00:51,520 --> 00:00:53,580
就是呢，每个视频长得差不多，每个内容都比较独立

22
00:00:54,930 --> 00:00:56,880
他们之间呢，是什么关系呢，

23
00:00:56,880 --> 00:01:01,090
今天呢，就来串一串这些内容

24
00:01:02,090 --> 00:01:10,619
首先是来回顾一下深度学习迎来大模型井喷式发展，可以看到现在啊大模型的文章特别好发

25
00:01:10,619 --> 00:01:14,050
而且大模型的泛化能力确实特别好

26
00:01:14,050 --> 00:01:15,730
从 16 年到 17 年

27
00:01:15,730 --> 00:01:17,170
Transformer 出现之后呢

28
00:01:17,170 --> 00:01:21,580
大家就基于 Transformer，不断的去引进的 c v 大模型

29
00:01:21,580 --> 00:01:23,210
多模态大模型

30
00:01:23,210 --> 00:01:26,780
当然自身的语言大模型也在不断的去演

31
00:01:26,780 --> 00:01:31,460
这里面呢，与传统的神经网络模型呢，就形成了一个断代的局面

32
00:01:31,540 --> 00:01:35,200
随着模型的层数和参数量急剧的膨胀

33
00:01:35,200 --> 00:01:38,990
所以需要分布式去训练网络模型

34
00:01:38,990 --> 00:01:40,550
而大模型有哪些好处呢

35
00:01:40,550 --> 00:01:41,330
有三个

36
00:01:44,169 --> 00:01:45,369
引入了自监督学习，我的模型大

37
00:01:45,369 --> 00:01:46,839
我的数据量也要大

38
00:01:48,849 --> 00:01:50,720
不要人工标注那么多

39
00:01:50,720 --> 00:01:53,740
第二个呢，就是解决模型碎片化

40
00:01:53,740 --> 00:01:57,460
以前我在一个语言模型里面做十个翻译任务

41
00:01:57,460 --> 00:01:59,470
我需要十个模型

42
00:01:59,470 --> 00:02:04,250
现在呢，一个大模型就可以解决 100 多种语言翻译任务了

43
00:02:04,250 --> 00:02:09,680
第三个呢，就是模型的参数规模是非常非常的大的

44
00:02:09,680 --> 00:02:12,470
所以形成了一个从蓝色的这条线

45
00:02:12,470 --> 00:02:16,160
到红色的这条线形成了一个断带

46
00:02:17,380 --> 00:02:19,980
既然有大模型

47
00:02:19,980 --> 00:02:24,150
就引入了需要大量的集群和分布式训练的能力

48
00:02:24,150 --> 00:02:24,720
当然了

49
00:02:24,720 --> 00:02:26,040
在分布式训练之前呢，还会有一些规点，checkpoint，accumulate

50
00:02:30,180 --> 00:02:33,340
还有混合精度的一些功能

51
00:02:33,340 --> 00:02:36,220
接下来呢，将会从最底层的硬件

52
00:02:36,220 --> 00:02:38,260
然后再往上层不断的去走

53
00:02:38,260 --> 00:02:41,020
那最底层的肯定是 AI 集群

54
00:02:41,020 --> 00:02:45,080
AI 集群呢，以那个华为的 Atlas 系列作为一个例子

55
00:02:45,679 --> 00:02:50,079
从这个渲染图呢，可以看到在整个机房里面呢，有非常多的机柜

56
00:02:50,079 --> 00:02:52,740
每排机柜都有非常多的 Atlas 服务器

57
00:02:52,740 --> 00:02:54,960
所以在真正的服务器机房

58
00:02:54,960 --> 00:02:56,980
它是长这个样子的

59
00:02:56,980 --> 00:03:00,560
左右两边呢，这些都是训练服务器

60
00:03:00,600 --> 00:03:01,560
当然了

61
00:03:01,560 --> 00:03:03,720
更好看的可能是这些渲染图

62
00:03:03,720 --> 00:03:06,990
看到的现在其实是机器的屁股

63
00:03:06,990 --> 00:03:08,100
就是插网线

64
00:03:08,100 --> 00:03:10,660
插网口风扇排气的地方

65
00:03:10,660 --> 00:03:12,660
这里面呢，叫做热巢

66
00:03:12,660 --> 00:03:18,150
而另外一面呢，就是能看到的真实的产品的里面呢，叫做冷风巢

67
00:03:18,150 --> 00:03:19,800
实际上是通冷风的

68
00:03:19,800 --> 00:03:21,720
当然呢，没去过机房的人

69
00:03:21,720 --> 00:03:24,579
可能以为机房有可能是长这样的

70
00:03:24,579 --> 00:03:27,579
但是呢，实际上现在的机房啊，还是比较规约的

71
00:03:27,579 --> 00:03:29,079
网线都是一簇一簇

72
00:03:29,079 --> 00:03:29,860
做好了

73
00:03:29,860 --> 00:03:32,140
排线还是比较好看的

74
00:03:32,140 --> 00:03:34,000
有了 AI 集群之后呢

75
00:03:34,000 --> 00:03:38,330
不能简单地以为，假设我的集群的数量

76
00:03:38,330 --> 00:03:39,590
我的芯片的数量

77
00:03:39,590 --> 00:03:42,230
我的服务器的数量不断的增加

78
00:03:42,230 --> 00:03:45,590
我计算的性能和效率就会不断的提升，其实这里面有个概念叫做加速比

79
00:03:49,260 --> 00:03:53,780
当集群的服务器的数量多到一定程度的时候

80
00:03:53,880 --> 00:03:55,740
计算性能的提升

81
00:03:55,740 --> 00:03:59,220
边际收益呢，就会受到限制

82
00:03:59,220 --> 00:04:03,000
可能后面不断的增加服务器集群

83
00:04:03,160 --> 00:04:08,370
实际系统的计算量和吞吐量呢，可能就已经维持在一个水平了

84
00:04:08,370 --> 00:04:10,950
那这个水平的收益呢，或者吞吐量呢，通过加速比这个公式来去计算的

85
00:04:14,730 --> 00:04:17,310
那这个内容呢，就会放在第四节

86
00:04:17,310 --> 00:04:18,870
用哪种服务器架构去讲，在 AI 集群中如何去提升加速比

87
00:04:22,460 --> 00:04:26,289
然后通过一个环跟实际物理的拓扑的步数

88
00:04:26,289 --> 00:04:28,959
提升整个系统的吞吐量

89
00:04:28,959 --> 00:04:33,640
使得 AI 集群的训练的性能和效率不断的得到提升

90
00:04:35,060 --> 00:04:37,420
既然了解完 AI 集群之后

91
00:04:37,420 --> 00:04:40,590
其实现在已经有了非常多的服务器

92
00:04:40,590 --> 00:04:42,210
有了这么多服务器啊

93
00:04:42,210 --> 00:04:45,320
服务器跟服务器之间呢，是需要进行通信的

94
00:04:45,320 --> 00:04:48,860
会在第五节，讲如何实现集合通信的

95
00:04:48,860 --> 00:04:55,450
而集合通信最重要的或者最原始最硬核的就是硬件的一些通信方式

96
00:04:55,450 --> 00:04:59,820
可以看到下面这个图呢，就是 Atlas 的一个正面图

97
00:04:59,820 --> 00:05:01,080
在机房里面呢

98
00:05:01,080 --> 00:05:04,380
大部分时间看到的都是服务器的这个屁股

99
00:05:04,380 --> 00:05:05,940
就像很多风扇口啊

100
00:05:05,940 --> 00:05:07,750
很多网络口啊

101
00:05:07,750 --> 00:05:10,360
而这个呢，机器和机器之间的通信呢

102
00:05:10,360 --> 00:05:14,740
主要是依赖于 TCP/IP 或者 RDMA 的这种通信的方式

103
00:05:14,740 --> 00:05:16,420
另外呢，在机器内呢

104
00:05:16,420 --> 00:05:19,000
一般都会在一台机器塞八张卡

105
00:05:19,000 --> 00:05:21,040
就是单机多卡的情况下呢

106
00:05:21,040 --> 00:05:24,270
那这时候呢，就需要用到机器内的通信

107
00:05:24,270 --> 00:05:30,060
机器内的主要是通过内存共享 PCIE 还有 NVLink 的方式进行一个通信的

108
00:05:30,060 --> 00:05:33,330
那 NVLink 呢，主要是卡跟卡之间通信

109
00:05:33,330 --> 00:05:38,620
也会在第五节里面如何实现集群通信里面去介绍

110
00:05:39,340 --> 00:05:40,950
有了通信的硬件

111
00:05:40,950 --> 00:05:44,530
其实还需要在软件上面做很多工作

112
00:05:44,530 --> 00:05:46,930
所以在第五节的下里面呢

113
00:05:46,930 --> 00:05:50,280
去介绍通信的原理到底是什么

114
00:05:50,500 --> 00:05:52,240
机器跟机器之间

115
00:05:52,240 --> 00:05:53,500
卡跟卡之间呢

116
00:05:53,500 --> 00:05:56,080
就要进行一个集合的通信

117
00:05:56,080 --> 00:05:59,620
所以这里面呢就会介绍一个 MPI，NCCL

118
00:05:59,620 --> 00:06:01,960
HCCL 的通信的方式

119
00:06:01,960 --> 00:06:03,400
通信的原理

120
00:06:03,400 --> 00:06:08,180
最底层的通信的逻辑，还是回到这个图里面呢

121
00:06:11,530 --> 00:06:14,470
那下面呢，来聊一聊大模型

122
00:06:14,470 --> 00:06:15,490
什么为之大

123
00:06:15,490 --> 00:06:17,289
怎么才能叫做大

124
00:06:23,810 --> 00:06:26,840
通过 Transformer 的下面这个结构啊

125
00:06:26,840 --> 00:06:29,450
可以输入一个长的序列

126
00:06:29,450 --> 00:06:33,140
甚至把图片呢，变成不同的 batch

127
00:06:33,140 --> 00:06:34,730
放在网络模型里面

128
00:06:34,730 --> 00:06:36,260
再做一个输入

129
00:06:36,280 --> 00:06:39,460
另外大模型呢，其实还炒了一个冷饭

130
00:06:39,460 --> 00:06:45,720
就是从 90 年代已经提出的 MoE 就是稀疏混合专家模型这个结构

131
00:06:45,720 --> 00:06:47,430
然后重新炒了一遍

132
00:06:47,430 --> 00:06:49,340
又结合了 Transformer

133
00:06:49,400 --> 00:06:51,020
引入了 MoE 结构

134
00:06:51,020 --> 00:06:55,240
使得网络模型呢，上到一个万亿规模的级别

135
00:06:55,240 --> 00:06:58,420
有了 Transformer 和 MoE 这两种结构呢

136
00:06:58,420 --> 00:07:02,280
就可以迎来了真正的大模型爆发的时代

137
00:07:02,580 --> 00:07:07,030
于是呢，在 06 的上去讲讲大模型有哪几种算法结构

138
00:07:07,030 --> 00:07:10,390
刚才已经简单的去介绍了几个概念的名词

139
00:07:10,390 --> 00:07:11,590
第一个是 Transformer 嘛

140
00:07:11,590 --> 00:07:13,090
第二个是 MoE 

141
00:07:13,090 --> 00:07:14,890
但是有了这些结构以外啊

142
00:07:14,890 --> 00:07:17,920
它跟网络模型跟大模型之间是什么关系呢

143
00:07:17,920 --> 00:07:18,920
怎么拼接呢

144
00:07:18,920 --> 00:07:23,660
所以会在 06 的下里面去介绍一些 SOTA 的大模型

145
00:07:23,660 --> 00:07:28,360
那这些 SOTA 的大模型都是从 17 年到 22 年之间

146
00:07:28,360 --> 00:07:31,040
这些非常经典的大模型

147
00:07:31,360 --> 00:07:33,460
有了 AI 集群的硬件

148
00:07:33,460 --> 00:07:36,340
这些硬件之间的中间可以通信

149
00:07:36,340 --> 00:07:38,740
然后呢，现在又有了算法

150
00:07:38,740 --> 00:07:40,300
接下来缺什么呢

151
00:07:40,300 --> 00:07:42,400
我这些算法要训练起来对吧

152
00:07:42,400 --> 00:07:45,420
那训练起来需要 AI 框架

153
00:07:45,420 --> 00:07:49,470
所以呢，在 AI 框架里面呢，就提出了分布式训练系统

154
00:07:49,470 --> 00:07:54,540
就是通过 AI 框架去实现分布式的训练过程

155
00:07:54,540 --> 00:07:59,280
所以会在第三节里面去讲到 AI 框架的分布式训练的功能

156
00:07:59,280 --> 00:08:00,780
分别用 pytorch 呢

157
00:08:00,780 --> 00:08:01,620
TensorFlow

158
00:08:01,620 --> 00:08:08,440
还有 MindSpore 去讲讲 AI 框架里面是如何去支持分布式训练系统的

159
00:08:09,199 --> 00:08:11,829
下面呢，再简略的去打开一下

160
00:08:11,829 --> 00:08:14,500
刚才已经讲了大模型的算法

161
00:08:14,500 --> 00:08:18,520
还讲了 AI 集群里面如何进行一个通信的方式

162
00:08:18,520 --> 00:08:22,360
那接下来就是 AI 框架要实现一个分布式训练的系统

163
00:08:22,360 --> 00:08:24,760
而他要实现分布式训练的系统呢

164
00:08:24,760 --> 00:08:27,190
就离不开两个很重要的内容

165
00:08:27,190 --> 00:08:29,660
第一个呢，就是分布式的并行和同步

166
00:08:29,660 --> 00:08:34,960
那第二个呢，就是硬件的内存优化和计算 AI 框架支持的分布式

167
00:08:34,960 --> 00:08:35,920
并行之后呢

168
00:08:35,920 --> 00:08:38,870
就可以基于 AI 框架和 AI 集群

169
00:08:38,870 --> 00:08:42,050
用大模型训练非常多好的精度

170
00:08:42,050 --> 00:08:42,860
好的结果

171
00:08:42,860 --> 00:08:45,500
做很多不同的实验

172
00:08:45,920 --> 00:08:49,040
最后呢，发一篇非常完美的 paper

173
00:08:49,820 --> 00:08:52,650
完成我整个学术的生涯

174
00:08:52,650 --> 00:08:56,070
但是成功的路上没有那么简单

175
00:08:56,070 --> 00:08:58,420
总是有绊脚石在出现

176
00:08:58,420 --> 00:08:59,980
那有哪些绊脚石呢

177
00:08:59,980 --> 00:09:03,880
可以在 02 就是大模型训练会遇到什么挑战

178
00:09:03,880 --> 00:09:05,640
这里面呢，去讲讲

179
00:09:05,640 --> 00:09:10,069
其实要训练大模型是遇到非常多的阻碍的

180
00:09:10,069 --> 00:09:11,989
第一个呢，就是内存墙

181
00:09:11,989 --> 00:09:13,429
网络模型太大了

182
00:09:13,429 --> 00:09:15,259
一个内存塞不下怎么办

183
00:09:15,259 --> 00:09:17,250
这个呢，就是通信墙

184
00:09:17,250 --> 00:09:19,470
既然有这么多机器网络模型呢

185
00:09:19,470 --> 00:09:21,810
分布在不同的机器通信起来了

186
00:09:21,810 --> 00:09:23,479
肯定是很困难的

187
00:09:23,520 --> 00:09:25,140
什么时候进行同步

188
00:09:25,140 --> 00:09:26,280
什么时候进行异步

189
00:09:26,280 --> 00:09:27,570
什么时候进行通信

190
00:09:27,570 --> 00:09:28,800
通信慢怎么办

191
00:09:28,800 --> 00:09:30,390
引起了一系列的问题

192
00:09:30,390 --> 00:09:34,239
另外还会有性能墙，大模型的训练起来呢

193
00:09:34,239 --> 00:09:37,330
确实性能可能很重要啊

194
00:09:37,330 --> 00:09:43,319
不可能让我一等等几个月，才告诉我训练的大模型精度不达标

195
00:09:43,360 --> 00:09:46,140
导师只能让我延期毕业

196
00:09:46,140 --> 00:09:49,920
那最后一个呢，就是调优墙，大模型要调优

197
00:09:49,920 --> 00:09:54,840
在分布式集群里面调优真的没有想象中那么简单哦

198
00:09:54,840 --> 00:09:56,940
啊其实刚才讲了很多挑战

199
00:09:56,940 --> 00:10:01,140
这些挑战归结起来了还是只有一个目标

200
00:10:01,140 --> 00:10:03,240
就是提升 TTA

201
00:10:03,400 --> 00:10:05,440
减少训练的耗时

202
00:10:05,440 --> 00:10:07,930
提升训练的速率

203
00:10:07,930 --> 00:10:11,420
那提升训练的速率呢，就有了三种方法

204
00:10:11,440 --> 00:10:14,740
第一种就是单设备计算速率的提升

205
00:10:14,740 --> 00:10:16,480
可以做很多的算法呀

206
00:10:16,480 --> 00:10:18,400
混合精度、算子融合、激活重计算、加速优化器

207
00:10:22,090 --> 00:10:24,800
第二个呢，就是设备数的提升

208
00:10:25,200 --> 00:10:26,460
脑子不够用

209
00:10:26,460 --> 00:10:27,210
没关系

210
00:10:27,210 --> 00:10:28,859
多几台机器嘛

211
00:10:29,620 --> 00:10:32,640
第三个就是多设备的并行效率

212
00:10:32,640 --> 00:10:34,320
又提出了数据并行模型

213
00:10:34,320 --> 00:10:35,959
并行流水线并行

214
00:10:36,060 --> 00:10:38,160
多设备的运行效率的提升

215
00:10:38,160 --> 00:10:41,520
是大模型训练或者大模型效率提升的一个关键

216
00:10:41,520 --> 00:10:43,339
所以往下打开

217
00:10:43,960 --> 00:10:45,480
在第七的上里面呢

218
00:10:45,480 --> 00:10:47,400
去讲了数据的并行

219
00:10:47,400 --> 00:10:50,370
数据并行其实有 DP DDP FSDP

220
00:10:50,370 --> 00:10:55,440
针对网络模型里面的不同的参数进行不同的并行策略

221
00:10:55,440 --> 00:10:58,260
那第二个呢，就是张量并行啊

222
00:10:58,260 --> 00:11:00,230
张量并行是模型并行的一种哦

223
00:11:00,230 --> 00:11:05,490
就把张量呢，切换到不同的机器上面去做一个并行处理的

224
00:11:05,490 --> 00:11:07,230
另外的话，流水线并行呢

225
00:11:07,230 --> 00:11:09,510
会 07 的下里面去介绍

226
00:11:09,510 --> 00:11:12,890
那流水线并行也是模型并行的一种

227
00:11:12,890 --> 00:11:15,640
因为它大部分都是对模型进行处理

228
00:11:15,640 --> 00:11:19,540
会对网络模型的层呢，拆分成不同的 stage

229
00:11:19,540 --> 00:11:22,620
然后交给不同的机器进行并行的

230
00:11:23,060 --> 00:11:24,920
讲了这么多模型并行，不是每个并行独立去用的

231
00:11:27,560 --> 00:11:29,580
我是混合在一起用的哦

232
00:11:29,580 --> 00:11:32,290
所以呢，又出现了多维混合并行

233
00:11:32,290 --> 00:11:35,950
而作为混合并行里面呢，用了两个例子

234
00:11:35,950 --> 00:11:38,110
第一个例子就是推荐大模型啊

235
00:11:38,110 --> 00:11:41,330
deep learning recommendation model

236
00:11:41,330 --> 00:11:42,290
推荐大模型

237
00:11:42,290 --> 00:11:50,860
第二个呢，就是 Megatron-LM 语言大模型去介绍混合并行是怎么实现的呢

238
00:11:50,860 --> 00:11:52,979
这是第八章里面的内容

239
00:11:53,460 --> 00:11:55,940
最后回到对训练性能的提升

240
00:11:55,940 --> 00:12:00,080
刚才呢，通过第七章第八章去讲了多设备的并行

241
00:12:00,080 --> 00:12:02,870
实际上单设备也要提升速率

242
00:12:02,870 --> 00:12:06,199
于是呢，单设备又有了很多不同的算法

243
00:12:06,880 --> 00:12:11,070
现在看回这个内容呢，有没有了一些感觉呢

244
00:12:11,070 --> 00:12:14,440
首先去看看 AI 集群的架构

245
00:12:14,440 --> 00:12:15,580
然后呢，有了集群

246
00:12:15,580 --> 00:12:17,140
需要通信嘛

247
00:12:17,140 --> 00:12:20,410
集群能够通信的证明硬件都 ok 了

248
00:12:20,410 --> 00:12:23,430
于是呢，就去研究大模型的算法

249
00:12:23,430 --> 00:12:27,329
但是大模型要训练起来就会遇到很多挑战

250
00:12:27,329 --> 00:12:32,710
这个时候呢 AI 框架就可以帮助去构建一些分布式训练的能力

251
00:12:32,710 --> 00:12:35,770
但是有分布式训练的能力还不够

252
00:12:35,770 --> 00:12:37,660
需要提升训练的性能

253
00:12:37,660 --> 00:12:41,080
于是呢，就提出了很多并行维度的策略

254
00:12:41,080 --> 00:12:45,880
对这些策略的混合在一起去提升通信的性能

255
00:12:45,880 --> 00:12:48,180
最后呢，针对单机单卡

256
00:12:48,180 --> 00:12:51,810
还有一些内存和计算的优化的方式

257
00:12:51,810 --> 00:12:55,780
使得整个大模型训练的又快又好

258
00:12:57,700 --> 00:12:58,740
卷的不行了

259
00:12:58,740 --> 00:12:59,640
卷的不行了

260
00:12:59,640 --> 00:13:01,320
记得一键三连加关注哦

261
00:13:01,320 --> 00:13:05,740
所有的内容都会开源在下面这条链接里面拜了个拜