1
00:00:00,000 --> 00:00:04,560
字幕生成: BLACK 字幕校对: 方鸿渐

2
00:00:06,320 --> 00:00:07,400
哈喽大家好

3
00:00:07,400 --> 00:00:08,200
我是 ZOMI

4
00:00:08,200 --> 00:00:09,440
好久没有更新了

5
00:00:09,440 --> 00:00:11,120
因为之前患了新冠

6
00:00:11,120 --> 00:00:13,640
到了晚上 12 点之后就特别地困

7
00:00:13,640 --> 00:00:15,000
然后就不能再肝了

8
00:00:16,080 --> 00:00:18,640
虽然 B 站上面有些同学叫我肝帝

9
00:00:18,720 --> 00:00:21,280
但实际上还是肝不动了

10
00:00:21,480 --> 00:00:23,200
今天来到一个新的内容

11
00:00:23,200 --> 00:00:25,120
叫做推理系统

12
00:00:25,120 --> 00:00:26,200
推理系统系列

13
00:00:27,200 --> 00:00:29,960
而正式去了解什么是推理系统之前

14
00:00:30,080 --> 00:00:32,440
去了解一下推理系统系列

15
00:00:32,440 --> 00:00:35,160
将会给大家汇报哪些内容

16
00:00:36,480 --> 00:00:39,760
主要给大家汇报的内容分开四块

17
00:00:39,920 --> 00:00:42,400
第一块就是整个推理系统的介绍

18
00:00:42,840 --> 00:00:45,880
第二个内容就是模型的小型化

19
00:00:45,880 --> 00:00:48,440
这块更多的是聚焦一些算法

20
00:00:48,440 --> 00:00:51,800
第三个就是离线优化压缩的一些算法

21
00:00:52,240 --> 00:00:55,600
最后一块就是部署和运行的优化

22
00:00:55,800 --> 00:00:57,400
逐块打开来去看一下

23
00:00:57,400 --> 00:00:59,600
将会讲解或者分享哪些内容

24
00:00:59,600 --> 00:01:01,080
第一个就是推理系统

25
00:01:01,360 --> 00:01:04,040
可以看到其实推理系统和推理引擎

26
00:01:04,040 --> 00:01:05,320
是不太一样的

27
00:01:05,320 --> 00:01:08,600
系统更多的是聚焦于整个推理的服务

28
00:01:08,600 --> 00:01:10,960
而推理的引擎更多的是指

29
00:01:10,960 --> 00:01:13,360
一个把 AI 算法跑起来

30
00:01:13,480 --> 00:01:16,480
接着去看看推理的一个工作的流程

31
00:01:16,480 --> 00:01:19,040
去了解一下推理系统和推理引擎

32
00:01:19,040 --> 00:01:21,480
它整个工作流需要做哪些内容

33
00:01:21,480 --> 00:01:25,040
然后就会去深入的去看看推理系统

34
00:01:25,160 --> 00:01:26,600
具体有哪些工作

35
00:01:26,600 --> 00:01:28,560
推理系统有哪些系统

36
00:01:28,560 --> 00:01:30,640
比较好的系统性的介绍一下

37
00:01:30,640 --> 00:01:33,120
接着会比较宏观的去介绍一下

38
00:01:33,120 --> 00:01:35,160
推理引擎的整体的架构

39
00:01:35,160 --> 00:01:37,200
还有推理引擎的一个工作的流程

40
00:01:37,200 --> 00:01:39,080
这一块可能推理引擎

41
00:01:39,360 --> 00:01:41,520
是后面所有工作的一个重点

42
00:01:41,520 --> 00:01:43,640
包括模型小型化、离线的优化

43
00:01:43,640 --> 00:01:45,800
还有在线部署的优化

44
00:01:45,800 --> 00:01:48,320
都是围绕着推理引擎去展开的

45
00:01:49,800 --> 00:01:52,120
在第二个大节的内容里面

46
00:01:52,280 --> 00:01:53,800
就是模型小型化

47
00:01:53,800 --> 00:01:56,680
其实这个更多的是聚焦于一些

48
00:01:57,040 --> 00:01:58,320
小型化的 BadBomb

49
00:01:58,320 --> 00:02:00,240
或者小型化的 Sota 网络模型

50
00:02:00,360 --> 00:02:03,680
例如会讲很多 CNN 的一些小型化的结构

51
00:02:03,680 --> 00:02:06,440
包括 MobileNet, EfficientNet, ShuffleNet, SqueezeNet

52
00:02:06,440 --> 00:02:08,840
还有诺亚的 GhostNet

53
00:02:08,840 --> 00:02:10,760
这一块更多的是围绕着

54
00:02:10,760 --> 00:02:13,320
神经网络的一个小型化去展开

55
00:02:13,320 --> 00:02:16,320
接着因为最近 Transformer 特别的火

56
00:02:16,320 --> 00:02:20,280
而 Transformer 的小型化的研究也是非常的热门

57
00:02:20,280 --> 00:02:23,200
至少在这两年来说特别的热门

58
00:02:23,240 --> 00:02:25,440
所以会讲 Transformer 小型化的

59
00:02:25,440 --> 00:02:27,400
一个具体的算法的结构

60
00:02:28,240 --> 00:02:29,480
在第二个大的内容里面

61
00:02:29,720 --> 00:02:31,920
模型的小型化可能更多的

62
00:02:31,920 --> 00:02:33,480
不是跟系统相关的

63
00:02:33,480 --> 00:02:34,760
而是跟算法相关

64
00:02:34,760 --> 00:02:36,720
接着在第三个内容

65
00:02:36,720 --> 00:02:37,920
离线的优化压缩

66
00:02:37,920 --> 00:02:38,880
离线的优化压缩

67
00:02:38,880 --> 00:02:42,000
其实跟系统相关性也不太大

68
00:02:42,000 --> 00:02:43,960
更多的也是跟算法相关

69
00:02:43,960 --> 00:02:46,160
第一个就是低比特的量化

70
00:02:46,160 --> 00:02:48,800
就可能 4 比特 8 比特的

71
00:02:48,800 --> 00:02:50,160
一些量化的算法

72
00:02:50,160 --> 00:02:52,760
会去系统性的去介绍

73
00:02:52,880 --> 00:02:55,000
接着去介绍一下二值化网络

74
00:02:55,800 --> 00:02:57,200
二值化网络很有意思

75
00:02:57,200 --> 00:03:00,440
二值化就是 0 跟 1 这种二值化的网络

76
00:03:00,720 --> 00:03:02,880
这一块会简单的去介绍一下

77
00:03:02,880 --> 00:03:04,480
最新的一个研究

78
00:03:04,800 --> 00:03:06,960
接着去看看模型的剪枝

79
00:03:06,960 --> 00:03:08,400
还有模型的蒸馏

80
00:03:08,640 --> 00:03:10,880
这一块其实整个小型化的压缩

81
00:03:10,880 --> 00:03:13,200
在端侧是非常的热门

82
00:03:13,200 --> 00:03:14,880
或者基本上你是离不开的

83
00:03:16,640 --> 00:03:18,200
在最后第 4 部分

84
00:03:18,320 --> 00:03:20,600
正式的进入到推理引擎的

85
00:03:20,600 --> 00:03:22,560
一个在线部署和优化的

86
00:03:23,240 --> 00:03:25,400
首先第一个就是图的转换优化

87
00:03:25,400 --> 00:03:27,680
包括一些算子的融合重排替换

88
00:03:28,320 --> 00:03:29,960
这块其实跟 AI 框架

89
00:03:29,960 --> 00:03:31,000
或者 AI 系统

90
00:03:31,000 --> 00:03:31,960
或者 AI 编译器

91
00:03:32,320 --> 00:03:33,880
其实比较相关

92
00:03:33,880 --> 00:03:35,840
会把很多相关的知识

93
00:03:35,960 --> 00:03:37,000
把它串起来

94
00:03:37,040 --> 00:03:38,560
接着会去看看

95
00:03:38,560 --> 00:03:40,160
在线部署的一些并发自行

96
00:03:40,160 --> 00:03:41,240
还有内存分配

97
00:03:42,320 --> 00:03:44,240
最后会看一个比较难的问题

98
00:03:44,240 --> 00:03:45,760
动态的 batch 和 binpacking

99
00:03:45,760 --> 00:03:47,440
还有一些推力引擎具体

100
00:03:47,440 --> 00:03:48,280
是怎么实现的

101
00:03:48,280 --> 00:03:50,280
一些底层的 runtime 的优化

102
00:03:50,480 --> 00:03:52,520
这一块就是第 4 部分

103
00:03:52,720 --> 00:03:55,280
接下来将会进入正式的内容

104
00:03:56,920 --> 00:03:57,920
现在来看一下

105
00:03:57,920 --> 00:04:00,320
典型的深度学习的推理的一些应用

106
00:04:01,480 --> 00:04:02,360
像左边的这个

107
00:04:02,480 --> 00:04:04,760
就是人脸 landmark 的一个应用

108
00:04:04,960 --> 00:04:06,120
除了人脸 landmark

109
00:04:06,120 --> 00:04:08,000
它还会做一些人脸的识别

110
00:04:08,000 --> 00:04:08,800
眼睛的识别

111
00:04:08,800 --> 00:04:10,240
人脸头像的朝向

112
00:04:10,480 --> 00:04:11,680
右边的这两张图

113
00:04:11,840 --> 00:04:12,960
还是比较有意思的

114
00:04:13,160 --> 00:04:15,680
利用华为 HMS Core 里面去实现的

115
00:04:15,680 --> 00:04:17,440
而 HMS Core 里面

116
00:04:18,120 --> 00:04:19,120
很多技术的支撑

117
00:04:19,280 --> 00:04:21,360
就是我在后面提供相关的技术的

118
00:04:21,360 --> 00:04:23,400
当然了包括我很多的同事的努力

119
00:04:24,040 --> 00:04:25,280
这个就是玩游戏

120
00:04:25,280 --> 00:04:26,240
去检测

121
00:04:26,240 --> 00:04:28,360
人脸的头像的位置在哪里

122
00:04:28,360 --> 00:04:30,200
然后人脸像上了小机器人

123
00:04:30,200 --> 00:04:32,680
或者小飞船就往上往下

124
00:04:32,880 --> 00:04:35,240
这个就检测手势的识别

125
00:04:35,600 --> 00:04:36,520
要是开炮

126
00:04:36,840 --> 00:04:38,960
就可能把手张开就可以了

127
00:04:39,160 --> 00:04:41,120
像这种应用还是很有意思的

128
00:04:41,120 --> 00:04:43,160
而且应用也是非常的多

129
00:04:44,720 --> 00:04:45,960
往下看一下

130
00:04:45,960 --> 00:04:47,680
特别是现在在

131
00:04:48,480 --> 00:04:50,320
典型的对话机器人

132
00:04:50,320 --> 00:04:52,400
在淘宝或者在拼多多

133
00:04:52,400 --> 00:04:54,680
经常去咨询一些客户的时候

134
00:04:54,680 --> 00:04:55,920
我其实个人来说

135
00:04:55,920 --> 00:04:56,560
我最讨厌的

136
00:04:56,560 --> 00:04:58,320
就是遇到一些对话机器人

137
00:04:58,320 --> 00:04:59,320
每次我问问题

138
00:04:59,480 --> 00:05:01,160
他就弹个对话机器人出来

139
00:05:01,160 --> 00:05:04,000
然后帮我解答一些最基础的问题

140
00:05:04,160 --> 00:05:05,920
这种的服务体验不是很好

141
00:05:05,920 --> 00:05:08,920
但是对于那些平台厂商来说

142
00:05:09,280 --> 00:05:11,680
能够节省他们大量的人力咨询的问题

143
00:05:11,680 --> 00:05:12,880
和人力压力的问题

144
00:05:12,880 --> 00:05:15,680
例如我只是简单的去问一个物流

145
00:05:15,680 --> 00:05:16,480
现在的物流

146
00:05:16,480 --> 00:05:17,480
你发哪个物流

147
00:05:17,480 --> 00:05:19,480
或者你现在的物流情况怎么样了

148
00:05:19,480 --> 00:05:22,600
像这种完全可以用对话机器人来去解决

149
00:05:22,600 --> 00:05:24,280
而最新的 chatgpt

150
00:05:24,440 --> 00:05:25,960
确实也是非常的火

151
00:05:26,240 --> 00:05:27,680
或者可以说火到一塌糊涂

152
00:05:27,680 --> 00:05:29,320
大家可以去了解一下

153
00:05:31,280 --> 00:05:32,520
接下来看一下

154
00:05:32,520 --> 00:05:34,840
另外一个应用就是推荐系统

155
00:05:35,000 --> 00:05:36,480
推荐系统可能更多的

156
00:05:36,480 --> 00:05:38,680
是不是说离线推荐

157
00:05:38,680 --> 00:05:39,880
而是在线推荐

158
00:05:40,560 --> 00:05:42,240
但是推荐系统现在大部分

159
00:05:42,440 --> 00:05:43,800
至少我认识阿里巴巴

160
00:05:43,800 --> 00:05:44,760
或者我当时候

161
00:05:44,760 --> 00:05:45,760
应该是几年前

162
00:05:45,760 --> 00:05:47,160
去面试阿里巴巴的时候

163
00:05:47,520 --> 00:05:50,120
他就去问我很多相关的工作

164
00:05:50,120 --> 00:05:52,560
而里面我当时候面试的一个岗位

165
00:05:52,920 --> 00:05:55,200
也是从事于淘宝推荐

166
00:05:55,200 --> 00:05:56,360
就下面很多推荐

167
00:05:56,480 --> 00:06:00,760
其实这个也是用了非常多的 AI 的算法

168
00:06:00,760 --> 00:06:02,920
然后更多的是 AI 的推理的应用

169
00:06:02,920 --> 00:06:03,960
或者推理的算法

170
00:06:04,680 --> 00:06:06,200
接下来再看一个

171
00:06:06,200 --> 00:06:10,160
最近比较火的一个应用

172
00:06:10,160 --> 00:06:12,000
叫做 AIGC

173
00:06:12,200 --> 00:06:15,160
这个是我摘自于量子位的一篇报道

174
00:06:15,160 --> 00:06:16,240
关于抖音的报道

175
00:06:16,240 --> 00:06:18,440
你可以看到一开始我输一张图片

176
00:06:18,440 --> 00:06:19,200
然后这张图片

177
00:06:19,200 --> 00:06:21,000
我可以选各种的风格

178
00:06:21,000 --> 00:06:22,360
我是一个肌肉男

179
00:06:22,360 --> 00:06:23,960
然后我输入进去

180
00:06:24,120 --> 00:06:26,840
也是变成非常多的不同的风格

181
00:06:26,840 --> 00:06:28,840
这种就是 AIGC

182
00:06:28,840 --> 00:06:30,800
也是我应该是一年前

183
00:06:30,880 --> 00:06:32,520
我就非常留意这个技术了

184
00:06:32,520 --> 00:06:35,240
也启动了一些相关的一些合作技术

185
00:06:35,240 --> 00:06:37,880
所以说这块应该是在后半年才

186
00:06:37,880 --> 00:06:38,560
火起来的

187
00:06:38,560 --> 00:06:39,840
也是非常有意思

188
00:06:41,480 --> 00:06:43,200
像刚才所说到的

189
00:06:43,200 --> 00:06:46,520
很多都是深度学习的一些推理的应用

190
00:06:46,520 --> 00:06:47,960
里面没有训练相关

191
00:06:47,960 --> 00:06:49,480
更多的是集中在推理

192
00:06:49,480 --> 00:06:50,720
而在这个过程当中

193
00:06:50,880 --> 00:06:52,360
整个推理系统

194
00:06:52,360 --> 00:06:53,960
以淘宝的推荐为例

195
00:06:54,240 --> 00:06:55,680
可能在推理系统

196
00:06:55,680 --> 00:06:56,520
而不是推理引擎

197
00:06:56,640 --> 00:06:57,240
是系统

198
00:06:58,120 --> 00:06:59,480
会考虑的问题

199
00:06:59,640 --> 00:07:00,800
可能会非常多了

200
00:07:00,800 --> 00:07:02,560
例如被用户所调用的

201
00:07:02,560 --> 00:07:03,320
API 的接口

202
00:07:03,640 --> 00:07:05,520
数据怎么去生成

203
00:07:05,520 --> 00:07:07,640
怎么去在网络的

204
00:07:07,640 --> 00:07:08,920
影响下了低延时的

205
00:07:08,920 --> 00:07:10,120
反馈用户的结果

206
00:07:10,120 --> 00:07:11,040
另外的话

207
00:07:11,040 --> 00:07:12,280
因为手机上面

208
00:07:12,480 --> 00:07:14,600
怎么利用多样性的一个加速器

209
00:07:14,600 --> 00:07:15,840
手机里面

210
00:07:15,840 --> 00:07:17,760
SoC 加速的资源

211
00:07:17,760 --> 00:07:18,840
怎么把它利用起来

212
00:07:18,840 --> 00:07:19,320
另外的话

213
00:07:19,320 --> 00:07:21,560
可能用户的吞吐量大了

214
00:07:21,880 --> 00:07:23,480
这个访问的服务

215
00:07:23,480 --> 00:07:24,920
怎么去做一些容灾

216
00:07:24,920 --> 00:07:26,080
或者扩容的问题

217
00:07:26,680 --> 00:07:27,240
另外的话

218
00:07:27,240 --> 00:07:28,280
对于网络来说

219
00:07:28,280 --> 00:07:31,040
我怎么上线新的一些网络模型

220
00:07:31,240 --> 00:07:33,000
这个时候怎么做 AB test

221
00:07:33,920 --> 00:07:35,320
都是一些很大的挑战

222
00:07:35,320 --> 00:07:36,560
也是做系统里面

223
00:07:36,560 --> 00:07:38,240
需要考虑的一些问题

224
00:07:38,440 --> 00:07:40,000
现在总结两个点

225
00:07:42,720 --> 00:07:43,840
如果简单的复用

226
00:07:43,840 --> 00:07:45,040
原有的 web 的服务

227
00:07:45,280 --> 00:07:47,400
其实是没有办法去解决所有的问题的

228
00:07:47,400 --> 00:07:49,360
特别是在深度学习

229
00:07:49,720 --> 00:07:51,000
大部分都用推理的时候

230
00:07:51,400 --> 00:07:52,840
很多系统性的问题

231
00:07:52,840 --> 00:07:54,320
它挑战就会出现了

232
00:07:55,720 --> 00:07:56,800
第二点就是

233
00:07:56,800 --> 00:07:59,720
深度学习的训练和推理过程

234
00:07:59,720 --> 00:08:00,760
其实是不同的

235
00:08:01,240 --> 00:08:03,760
而他们的生命周期也是不同的

236
00:08:06,600 --> 00:08:08,360
今天整体的介绍

237
00:08:08,520 --> 00:08:09,760
就先到这里为止

238
00:08:09,760 --> 00:08:10,320
好了

239
00:08:10,320 --> 00:08:11,040
谢谢各位

240
00:08:11,040 --> 00:08:11,960
拜拜

241
00:08:13,280 --> 00:08:14,440
卷的不行了

242
00:08:14,440 --> 00:08:15,280
卷的不行了

243
00:08:15,280 --> 00:08:16,720
记得一键三连加关注

244
00:08:17,160 --> 00:08:18,480
所有的内容都会开源

245
00:08:18,480 --> 00:08:20,200
在下面这条链接里面

246
00:08:20,720 --> 00:08:22,165
拜拜

