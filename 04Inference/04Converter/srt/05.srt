1
00:00:00,000 --> 00:00:04,375
字幕生成：qiaokai  字幕校对：A 是传奇

2
00:00:05,500 --> 00:00:07,080
Hello 大家好，我是 ZOMI

3
00:00:07,080 --> 00:00:11,280
今天还是在推理引擎模型转换和优化这个内容里面

4
00:00:11,280 --> 00:00:13,960
今天我要给大家带来的一个新的内容

5
00:00:13,960 --> 00:00:17,360
就是模型转换的另外一个模块计算图优化

6
00:00:17,360 --> 00:00:19,320
最后的一个内容

7
00:00:19,320 --> 00:00:21,400
今天刚下班回来有点累

8
00:00:21,400 --> 00:00:23,400
我先去找家店按个摩洗个澡

9
00:00:23,400 --> 00:00:24,400
然后再回来

10
00:00:36,240 --> 00:00:37,160
我又回来了

11
00:00:37,160 --> 00:00:40,080
今天来到了计算图优化这个系列

12
00:00:40,080 --> 00:00:42,520
这个系列其实应该是这个内容

13
00:00:42,520 --> 00:00:45,360
会分开两大节去给大家介绍

14
00:00:45,360 --> 00:00:50,640
第一大节就是去看一看计算图优化里面的挑战和整体的架构

15
00:00:50,640 --> 00:00:54,360
然后看一下计算图优化是怎么样一个分类

16
00:00:54,400 --> 00:00:57,880
然后以一个 ONNX Runtime 的一个计算图优化的一个执行

17
00:00:57,880 --> 00:01:00,960
来去了解一下具体的一些优化是怎么做的

18
00:01:00,960 --> 00:01:07,200
在第二个内容就会对计算图优化这一大个内容来进行详细的展开

19
00:01:07,200 --> 00:01:09,680
所以它叫做详解也是 Details

20
00:01:09,680 --> 00:01:11,680
把所有很多细节展开起来

21
00:01:11,680 --> 00:01:13,680
但这一个也是最核心的内容

22
00:01:13,680 --> 00:01:16,280
留在后面给大家慢慢的汇报

23
00:01:17,280 --> 00:01:20,760
现在来到推理引擎转换模块里面的图优化

24
00:01:20,800 --> 00:01:23,640
图优化会做很多对计算图做算子融合

25
00:01:23,640 --> 00:01:25,640
布局转换、算子替换、内存优化

26
00:01:25,640 --> 00:01:28,120
非常多不同的类型的优化的 parts

27
00:01:28,120 --> 00:01:31,720
现在看一看整体的一个挑战和架构

28
00:01:31,720 --> 00:01:35,760
在最开始第一节内容的时候其实已经跟大家详细的普及过

29
00:01:35,760 --> 00:01:38,240
这里面简单的去重复一下

30
00:01:38,240 --> 00:01:41,880
首先第一个就是优化模块的挑战

31
00:01:41,880 --> 00:01:45,080
优化模块其实遇到很多各种各样的冗余

32
00:01:45,080 --> 00:01:48,600
有结构的冗余、有精度的冗余、有算法的冗余

33
00:01:48,600 --> 00:01:50,160
还有读写的冗余

34
00:01:50,480 --> 00:01:55,600
针对每一种冗余其实在离线优化模块里面是有对应的去处理的

35
00:01:55,600 --> 00:01:59,520
例如针对结构冗余会对计算图进行优化

36
00:01:59,520 --> 00:02:02,400
算子融合、算子替换、还有常量折叠

37
00:02:02,400 --> 00:02:05,040
这些常用的计算图的优化的方式

38
00:02:05,040 --> 00:02:08,440
就会去去除结构上的冗余

39
00:02:08,440 --> 00:02:13,240
第二种针对算法上面的冗余就是具体到某个算法了

40
00:02:13,240 --> 00:02:16,160
除了统一算子还有计算图的表达

41
00:02:16,160 --> 00:02:18,560
就是统一自己的自定义 IR 之外

42
00:02:18,560 --> 00:02:21,520
还会对 Kernel 提升它的一个范化性

43
00:02:21,520 --> 00:02:26,000
把相类似的 Kernel 把它提炼成为相同的一些 Kernel 的操作

44
00:02:26,720 --> 00:02:28,960
最后就是针对读写的冗余

45
00:02:28,960 --> 00:02:31,960
读写的冗余会做一些数据排布的优化

46
00:02:31,960 --> 00:02:33,840
还有内存分配的优化

47
00:02:34,280 --> 00:02:37,440
上面四个就是遇到的一些挑战

48
00:02:38,200 --> 00:02:42,280
针对这些挑战设计了整个转换模块的架构图

49
00:02:42,280 --> 00:02:44,640
可以看到转换模块分为两层

50
00:02:44,640 --> 00:02:46,760
第一层就是图的转换

51
00:02:47,280 --> 00:02:50,120
把从不同 AI 框架训练得到的计算图

52
00:02:50,120 --> 00:02:52,880
转换成为推理引擎的计算图

53
00:02:52,880 --> 00:02:54,680
或者推理引擎自己的 IR

54
00:02:55,360 --> 00:02:57,280
第二层就是图的优化

55
00:02:57,280 --> 00:03:01,400
图的优化也就是现在红色框所标示的这一个模块

56
00:03:01,400 --> 00:03:04,000
整体会做很多 OPFusion 的算子

57
00:03:04,000 --> 00:03:07,160
就和算子这些块布局的转换内存的分配

58
00:03:07,160 --> 00:03:10,160
很多不同的计算图的优化的内容

59
00:03:11,040 --> 00:03:15,760
下面再来整体的看一看转换模块的工作流程

60
00:03:15,760 --> 00:03:19,480
左边转换模块其实在上一节里面已经详细的介绍了

61
00:03:19,480 --> 00:03:21,080
特别是自定义的 IR

62
00:03:21,080 --> 00:03:23,240
这个 IR 怎么用、怎么做、怎么定义

63
00:03:23,240 --> 00:03:24,720
已经详细介绍过了

64
00:03:24,720 --> 00:03:27,400
在优化模块其实它分开三个

65
00:03:27,400 --> 00:03:29,440
第一个就是 Pre Optimize

66
00:03:29,440 --> 00:03:32,400
在预优化阶段大部分都是会把常用的代数优化

67
00:03:32,400 --> 00:03:34,280
变成计算图的一种优化

68
00:03:34,280 --> 00:03:36,440
在真正的中间优化阶段

69
00:03:36,560 --> 00:03:39,360
就会做很多跟算子相关的一些优化

70
00:03:39,360 --> 00:03:41,960
也会把神经网络相关的知识融合进来

71
00:03:42,680 --> 00:03:45,400
Pos Optimize 就是最后的一个优化阶段

72
00:03:45,440 --> 00:03:48,000
就会对数据的格式转换、类似的布局

73
00:03:48,320 --> 00:03:50,600
还有重复算子进行一些合并

74
00:03:50,880 --> 00:03:52,280
这个也是最后的优化

75
00:03:52,280 --> 00:03:54,680
一般在推理引擎里面的优化顺序

76
00:03:54,680 --> 00:03:56,040
就是长这个样子的

77
00:03:56,960 --> 00:04:00,000
往下看一看下一个比较核心的内容

78
00:04:00,760 --> 00:04:03,920
就是离线优化模块的计算图优化

79
00:04:03,920 --> 00:04:08,120
真正的来到计算图优化这个内容

80
00:04:08,600 --> 00:04:11,400
其实在 AI 编译器的前端优化

81
00:04:11,400 --> 00:04:13,680
它也是针对计算图进行优化的

82
00:04:13,840 --> 00:04:16,760
在这里面就讲了很多相关的内容

83
00:04:17,040 --> 00:04:19,280
有 Graph 的 IR 就是图的 IR

84
00:04:19,400 --> 00:04:21,080
有算子融合、布局转换

85
00:04:21,080 --> 00:04:22,280
类似的分配常量折叠

86
00:04:22,280 --> 00:04:24,720
还有公共值的表达式的消除

87
00:04:24,720 --> 00:04:26,280
有非常多的优化的 parts

88
00:04:26,760 --> 00:04:28,840
这些是基于 AI 框架去做的

89
00:04:28,840 --> 00:04:31,040
也就是在训练场景会非常的多

90
00:04:31,040 --> 00:04:33,640
而训练场景其实在在线训练的过程当中

91
00:04:33,800 --> 00:04:36,200
对时间实验的要求没有那么苛刻

92
00:04:36,440 --> 00:04:38,880
所以可以在里面可以做很多 GIT 的编译

93
00:04:38,880 --> 00:04:40,000
或者其他的编译

94
00:04:40,320 --> 00:04:43,400
但是在推理引擎计算图的优化

95
00:04:43,800 --> 00:04:45,640
更多的是采用预先写好的模板

96
00:04:45,720 --> 00:04:47,640
而不是通过 AI 编译去实现的

97
00:04:47,640 --> 00:04:49,840
如果真的需要通过 AI 编译去实现

98
00:04:49,840 --> 00:04:53,000
其实个人来说或者我看到很多项目

99
00:04:53,000 --> 00:04:54,760
基本上很少除了 TVM 之外

100
00:04:55,400 --> 00:04:56,640
但是像 TVM 这种项目

101
00:04:56,760 --> 00:04:58,680
它也不是专门针对推理引擎的

102
00:04:58,680 --> 00:05:01,520
所以现在大部分大家能看到的推理引擎

103
00:05:01,520 --> 00:05:03,320
包括 TensorIR、ONLIX Runtime

104
00:05:03,600 --> 00:05:06,160
还有 MMN、MCNN 这些推理引擎

105
00:05:06,160 --> 00:05:08,120
大部分都是已经预先写好的模板

106
00:05:08,400 --> 00:05:09,560
进行转换的

107
00:05:10,160 --> 00:05:13,440
转换的目的就是减少计算图中的

108
00:05:13,440 --> 00:05:14,800
冗余的计算

109
00:05:15,200 --> 00:05:17,120
于是就会衍生很多各种各样的

110
00:05:17,120 --> 00:05:18,280
图优化的技术

111
00:05:18,640 --> 00:05:21,160
在特定场景确实图优化

112
00:05:21,400 --> 00:05:25,000
能够给带来相当大的计算的收益

113
00:05:25,720 --> 00:05:27,640
但是基于这种模板的方式

114
00:05:27,760 --> 00:05:30,560
有个缺点就是需要根据先验的知识

115
00:05:30,800 --> 00:05:32,320
去做一个优化的

116
00:05:32,640 --> 00:05:34,280
相对比于 AI 网络模型

117
00:05:34,440 --> 00:05:38,040
确实它有非常多的各种的创新

118
00:05:38,040 --> 00:05:40,800
所以没有办法完完全全的去掉冗余

119
00:05:41,800 --> 00:05:44,400
下面来到图优化的具体的方式

120
00:05:44,640 --> 00:05:47,440
可以看到左边我有三个圈圈

121
00:05:47,440 --> 00:05:48,200
1、2、3

122
00:05:48,200 --> 00:05:51,480
三个圈圈代表三种不同的图优化的方式

123
00:05:51,480 --> 00:05:54,800
这里面 ZOMI 就做了一个简单的总结

124
00:05:54,800 --> 00:05:57,520
首先第一种就是 basic 基础的优化

125
00:05:57,520 --> 00:06:00,080
基础优化主要是涵盖很多

126
00:06:00,320 --> 00:06:02,040
保留计算图语义的一些修改

127
00:06:02,040 --> 00:06:04,120
就是不改变原来计算图的语义

128
00:06:04,120 --> 00:06:05,880
做一些真正的修改

129
00:06:06,240 --> 00:06:07,320
例如有常量折叠

130
00:06:07,560 --> 00:06:08,520
冗余节点的消除

131
00:06:08,640 --> 00:06:10,320
还有有限数量的算子融合

132
00:06:10,640 --> 00:06:13,360
这些都是属于最基础的优化

133
00:06:13,360 --> 00:06:16,200
接着还有 extend 就是扩展性的优化

134
00:06:16,200 --> 00:06:19,280
扩展性的优化会根据具体的后端

135
00:06:19,280 --> 00:06:20,720
例如 CPU GPU

136
00:06:20,720 --> 00:06:23,280
还有 NPU 等具体的后端

137
00:06:23,280 --> 00:06:26,000
针对具体或者比较复杂的一些 kernel

138
00:06:26,000 --> 00:06:28,200
进行融合优化的策略

139
00:06:28,200 --> 00:06:31,760
最后一个就是 layout 和 memory 的优化

140
00:06:31,760 --> 00:06:33,760
例如布局转换优化

141
00:06:33,760 --> 00:06:35,360
还有内存排布的优化

142
00:06:35,360 --> 00:06:37,520
这个就是最后的一种

143
00:06:38,160 --> 00:06:39,320
ZOMI 老师你好

144
00:06:39,920 --> 00:06:41,120
我想问一下

145
00:06:42,680 --> 00:06:43,680
你说你说

146
00:06:44,120 --> 00:06:45,920
你这里面三种优化方式

147
00:06:45,920 --> 00:06:48,640
跟架构图好像没有一一对应

148
00:06:49,360 --> 00:06:49,800
是的

149
00:06:49,800 --> 00:06:50,800
这里面的优化方式

150
00:06:50,800 --> 00:06:53,480
确实没有跟架构图一一对应起来

151
00:06:53,480 --> 00:06:56,920
看一下下面的一个工作的流程图

152
00:06:56,920 --> 00:06:59,240
可以看到像第一个 pre-optimized

153
00:06:59,360 --> 00:07:01,320
就是最开始的 basic

154
00:07:01,320 --> 00:07:03,880
一些最基础的优化的方式

155
00:07:03,880 --> 00:07:06,640
而中间的这个就有可能会涉及到

156
00:07:06,640 --> 00:07:07,760
最基础的优化方式

157
00:07:07,760 --> 00:07:09,240
还有 extend 的优化方式

158
00:07:09,320 --> 00:07:10,960
最后的 post-optimized

159
00:07:11,120 --> 00:07:13,360
会涉及到 extend 的优化方式

160
00:07:13,360 --> 00:07:16,160
还有最后的 layout 和 memory 的优化方式

161
00:07:17,120 --> 00:07:18,000
接下来的内容

162
00:07:18,160 --> 00:07:20,560
更多的是通过图优化的方式

163
00:07:20,560 --> 00:07:21,760
做一个简单的分类

164
00:07:21,760 --> 00:07:25,160
更好的去让大家去学习和了解

165
00:07:25,520 --> 00:07:28,040
当然了这里面的优化的模块的顺序

166
00:07:28,040 --> 00:07:28,840
不是固定的

167
00:07:28,840 --> 00:07:30,360
大家也可以按照自己的理解

168
00:07:30,360 --> 00:07:32,200
还有自己推理引擎的一些特性

169
00:07:32,200 --> 00:07:34,600
来对这些 parts 进行排序

170
00:07:35,360 --> 00:07:37,080
下面看一下

171
00:07:37,120 --> 00:07:39,520
onlix one time 的一个图优化具体

172
00:07:39,520 --> 00:07:40,920
是怎么去使用

173
00:07:40,920 --> 00:07:42,560
这里面简单的去讲一讲

174
00:07:42,560 --> 00:07:44,600
具体的使用 usage

175
00:07:45,120 --> 00:07:46,080
在 onlix 里面

176
00:07:46,320 --> 00:07:48,760
这有 GraphOptimizationLevel

177
00:07:48,760 --> 00:07:51,120
去选择具体对哪一层 level

178
00:07:51,120 --> 00:07:52,080
进行优化

179
00:07:52,280 --> 00:07:53,880
有 basic 刚才讲到的

180
00:07:53,880 --> 00:07:54,640
还有 extend

181
00:07:54,640 --> 00:07:55,480
还有所有

182
00:07:55,480 --> 00:07:57,480
当然了我所有优化都不执行

183
00:07:57,480 --> 00:07:58,800
这也是可以的

184
00:07:58,800 --> 00:08:02,120
这就是 onlix 的一个使用的方式

185
00:08:02,440 --> 00:08:03,320
下面来看一下

186
00:08:03,320 --> 00:08:06,640
具体的代码是怎么去 usage 使用

187
00:08:06,840 --> 00:08:09,600
这里面启动了一个 section 的对象

188
00:08:09,600 --> 00:08:12,600
然后去设置需要优化的 level

189
00:08:12,600 --> 00:08:13,680
这里面就是说

190
00:08:13,680 --> 00:08:17,040
我需要开通一个 extend 的优化的方式

191
00:08:17,040 --> 00:08:19,080
然后就指定优化模型的地址

192
00:08:19,080 --> 00:08:20,720
最后就导出网络模型

193
00:08:20,720 --> 00:08:22,600
执行具体的模型的优化

194
00:08:22,600 --> 00:08:24,320
就是这种方式去执行的

195
00:08:25,960 --> 00:08:26,600
回顾一下

196
00:08:26,600 --> 00:08:29,480
今天在离线计算图优化模块

197
00:08:29,480 --> 00:08:32,400
这里面去讲了它遇到的一些挑战

198
00:08:32,400 --> 00:08:35,200
还有最后设计的一个架构和流程图

199
00:08:35,600 --> 00:08:37,200
接着去了解了一下

200
00:08:37,200 --> 00:08:39,200
计算图的优化其实分为三种

201
00:08:39,200 --> 00:08:40,560
一种是 basic extend

202
00:08:40,560 --> 00:08:42,920
还有 layout and memory 的优化的方式

203
00:08:42,920 --> 00:08:44,040
最后看了一下

204
00:08:44,040 --> 00:08:46,640
onlix one time 图优化具体是怎么使用的

205
00:08:46,640 --> 00:08:49,360
接下来的内容可能会很复杂

206
00:08:49,360 --> 00:08:51,360
将会分开三个小视频

207
00:08:51,360 --> 00:08:53,160
给大家分别的去介绍

208
00:08:53,160 --> 00:08:55,080
第二个内容里面的 basic extend

209
00:08:55,080 --> 00:08:57,880
layout and memory 三种的优化的方式

210
00:08:58,080 --> 00:09:00,600
虽然推理引擎模型转换的计算图优化

211
00:09:00,720 --> 00:09:02,240
跟 A 编译器的前端优化

212
00:09:02,560 --> 00:09:04,760
在实现上面有着本质的区别

213
00:09:04,800 --> 00:09:07,400
但是它们的原理是非常的相似

214
00:09:07,400 --> 00:09:09,040
所以也鼓励大家去看一下

215
00:09:09,040 --> 00:09:12,240
AI 编译器的前端优化的一些相关的原理和概念

216
00:09:12,240 --> 00:09:14,440
当然我在后面也会详细的去展开

217
00:09:14,440 --> 00:09:16,080
后面详细的展开更多是

218
00:09:16,080 --> 00:09:17,080
工程性的一些

219
00:09:17,080 --> 00:09:18,960
展开工程性的一些优化的 parts

220
00:09:18,960 --> 00:09:21,080
好了今天的内容就到这里为止

221
00:09:21,080 --> 00:09:22,080
谢谢各位

222
00:09:22,080 --> 00:09:23,080
拜了个拜

223
00:09:23,960 --> 00:09:25,600
卷的不行了卷的不行了

224
00:09:25,600 --> 00:09:27,400
记得一键三连加关注哦

225
00:09:27,400 --> 00:09:30,560
所有的内容都会开源在下面这条链接里面

226
00:09:31,040 --> 00:09:31,840
拜了个拜

