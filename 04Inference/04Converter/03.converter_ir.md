# 自定义计算图IR

模型转换涉及对模型的结构和参数进行重新表示。在进行模型转换时，通常需要理解模型的计算图结构，并根据目标格式的要求对其进行调整和转换,这可能包括添加、删除或修改节点、边等操作，以确保转换后的计算图能够正确地表示模型的计算流程。本节主要介绍自定义计算图的方法以及模型转换的流程和细节。

## 计算图定义回顾

转换模块架构分为转换模块和图优化，中间的IR(Intermediate Representation)用来承载，把不同的AI框架对接到同一个IR。

![模型转换模块架构](image/converter01.png)

有了IR，我们就可以很方便地做各种图优化工作，图优化是对计算图进行优化，以提高模型的计算效率和性能。通过对计算图进行算子融合、算子替换等各种优化技术的应用，可以减少冗余计算、提高并行性、减少内存占用等，从而加速训练和推理过程。

![基于计算图的图优化](image/converter02.png)

### 计算图组成

无论是AI框架还是推理引擎，其计算图的组成都是相同的。

- 基本数据结构张量（Tensor）
  - 在机器学习领域内将多维数据称为张量，使用秩来表示张量的轴数或维度。
  - 标量为零秩张量，包含单个数值，没有轴；向量为一秩张量，拥有一个轴；拥有RGB三个通道的彩色图像即为三秩张量，包含三个轴。
  - 下图所示的Tensor形状（Shape）： [3, 2, 5]
  
  ![张量](../../05Framework/03DataFlow/images/data_type02.png)

  - Tensor中的元素类型可以为：int, float, string等。
- 基本运算单元算子（Operator）
  - 算子是构成神经网络的基本计算单元，对张量数据进行加工处理，实现了多种机器学习中常用的计算逻辑，包括数据转换、条件控制、数学运算等。
  - 算子通常由最基本的代数算子组成，并根据深度学习结构组合形成复杂算子。
  - N个输入张量经过算子的计算产生M个输出张量。举例来说，一个基本的加法算子可以接受两个输入张量，并将它们按元素进行相加，生成一个输出张量。而一个更复杂的卷积算子可能包含多个输入张量（如输入数据和卷积核），并输出一个张量，通过卷积运算实现特征提取。

  ![算子](image/converter07.png)

### AI框架中的计算图

**AI框架：** 如TensorFlow、PyTorch等，是开发和训练机器学习模型的软件环境。这些框架提供了一套丰富的工具和库，使得研究人员和开发人员能够更加便捷地构建、训练和部署模型。

**计算图：** 深度学习模型的一种表达方式。现代机器学习模型的拓扑结构日益复杂，需要机器学习框架对模型算子的执行依赖关系、梯度计算以及训练参数进行快速高效的分析，便于优化模型结构、制定调度执行策略以及实现自动化梯度计算，从而提高机器学习框架训练复杂模型的效率。为了兼顾编程的灵活性和计算的高效性，设计了基于计算图的机器学习框架。在AI框架中，计算图被用来表示模型的前向传播过程，即输入数据经过各种操作和层次的处理，最终生成输出结果。

### 推理引擎中的计算图

先来回顾一下推理引擎的概念：

推理引擎是用于执行模型推理任务的软件组件或系统。一旦模型训练完成，推理引擎被用来部署模型并在真实环境中进行推理，即根据输入数据生成预测结果。推理引擎通常会优化推理过程，以提高推理速度和效率。

![推理引擎架构图](../01Inference/images/inference01.png)

推理引擎本身也可以认为是一个基础软件，它提供了一组API用于在特定平台（如CPU、GPU和 VPU）上进行推理任务。（注：执行推理任务时模型已稳定无需训练，服务于真实数据进行推理预测。）

英特尔的 OpenVINO 这样定义推理引擎：

> （OpenVINO）推理引擎是一组C++库，提供通用 API，可在您选择的平台（CPU、GPU或 VPU）上提供推理解决方案。使用推理引擎API读取中间表示（IR）、设置输入和输出格式并在设备上执行模型。虽然C++库是主要实现，但C库和Python bindings（通过 Python 调用 C/C++ 库）也可用。

计算图是实现高效推理和跨平台部署的关键。在推理过程中，模型通常会被转换为一种中间表示，计算图优化可以作用于这一中间表示，进一步提升推理效率。通过计算图优化，推理引擎能够提供更快、更省资源的模型执行方式。

### AI框架计算图 vs 推理引擎计算图

AI框架计算图与推理引擎计算图有什么区别？

- 正反向传播
  - 推理引擎聚焦的是前向传播的过程，因为在推理阶段通常不需要进行反向传播（即梯度计算和参数更新）。
  - AI框架计算图需要支持正向和反向传播，因为在训练过程中需要进行梯度计算和参数更新。
- 动静态图
  - AI框架通常支持灵活的动态图，这使得模型构建过程更加灵活。在训练过程中，有时可能会选择使用静态图以提高训练效率，例如在使用TensorFlow等框架时。
  - 推理引擎更倾向于使用静态图，因为静态图在执行时更易于优化，动态图可能会对执行时间、运行时调度和kernel调度产生影响。
- 分布式并行
  - 在训练场景中，AI框架的计算图通常支持各种分布式并行策略，以加速模型的训练过程。这包括数据并行、张量并行、流水线并行等，并行切分策略，可以利用AI集群计算中心的多个计算节点来同时处理大规模的训练数据和计算任务，以提高训练效率和扩展性。
  - 在推理场景中，推理引擎计算图往往以单卡推理服务为主，很少考虑分布式推理。因为推理任务通常是针对单个输入进行的，并不需要大规模的并行化处理。相反，推理引擎更注重于模型工业级部署应用，在对外提供服务时，需要保证推理任务的高效执行和低延迟响应。
- 使用场景
  - AI框架计算图主要用于模型的训练场景，适用于科研创新、模型训练和微调等场景。研究人员可以利用AI框架的计算图来构建、训练和优化各种类型的深度学习模型，以提高模型的性能和精度。
  - 推理引擎计算图主要用于模型的推理场景，适合模型的工业级部署应用。推理引擎计算图注重模型的高效执行和低延迟响应，在对外提供服务时需要保证推理任务的快速执行和稳定性。

![AI框架计算图vs推理引擎计算图](image/converter08.png)

## 推理引擎计算图实例

通常深度学习网络都可以看成一个计算图，而推理可以理解成数据从计算图起点到终点的过程。为了在推理引擎中自定义一个高效的计算图，可以通过Protobuf或者FlatBuffers定义计算图的整体流程：

1. **构建计算图 IR：** 根据自身推理引擎的特殊性和竞争力点，构建自定义的计算图。
   - 利用Protobuf或FlatBuffers等序列化库来定义计算图的中间表示(IR)。这一步骤需要考虑推理引擎的特性和性能优化点，以确保计算图能够满足特定的性能和功能需求。
   - 设计计算图的节点和边的数据结构，包括操作类型、参数、数据流等，以便能够准确表示模型的计算流程。
2. **解析训练模型：** 通过解析AI框架导出的模型文件，使用 Protobuf / FlatBuffers提供的API定义对接到自定义IR的对象。
3. **生成自定义计算图：** 通过使用 Protobuf / FlatBuffers的API导出自定义计算图。
   - 根据解析得到的信息，使用Protobuf或FlatBuffers的API来生成自定义的计算图。这一步骤中，可以开始应用各种优化策略，如算子融合、内存布局优化等。
   - 对生成的计算图进行深度优化，以提高推理性能和降低资源消耗。例如公共表达式消除、死代码消除、算子替换等优化手段。

### 推理引擎计算图：Tensor张量的表示

**Tensor数据存储格式：** 定义了一个名为 DataType的枚举类型，它包含了几种常见的数据类型，如浮点型（float）、双精度浮点型（double）、32位整型（int32）、8位无符号整型（uint8）等。每个数据类型都有一个与之对应的整数值来表示，例如 DT_FLOAT 对应整数值 1，DT_DOUBLE 对应整数值 2，以此类推。
  
```
// 定义 Tensor 的数据类型
enum DataType : int {
DT_INVALID = 0,
DT_FLOAT = 1,
DT_DOUBLE = 2,
DT_INT32 = 3,
DT_UINT8 = 4,
DT_INT16 = 5,
DT_INT8 = 6,
// ...
}
```

**Tensor 数据内存排布格式：** 即张量在内存中的存储顺序，不同的框架和算法可能使用不同的数据排布格式来表示张量数据。

- ND： 表示多维数组（N-dimensional），即没有特定的数据排布格式，各维度的数据顺序不固定。
- NCHW： 表示通道-高度-宽度的排布格式，通常在卷积神经网络中使用，数据按照批次（Batch）、通道（Channel）、高度（Height）、宽度（Width）的顺序排列。
- NHWC： 表示高度-宽度-通道的排布格式，通常在某些框架中使用，数据按照批次、高度、宽度、通道的顺序排列。
- NC4HW4： 表示通道-高度-宽度的排布格式，通常在某些硬件加速器（如GPU）中使用，数据按照批次、通道、高度、宽度的顺序排列，同时对通道和高度宽度做了4的倍数的扩展。
- NC1HWC0： 表示通道-1-高度-宽度-0的排布格式，通常在某些硬件加速器（如Ascend芯片）中使用，数据按照批次、通道、高度、宽度的顺序排列，并对高度和宽度做了一定的扩展。
- UNKNOWN： 表示未知的数据排布格式，可能由于某些特定的需求或算法而无法归类到已知的排布格式中。

```
// 定义 Tensor 数据排布格式
enum DATA_FORMAT : byte {
    ND,
    NCHW,
    NHWC,
    NC4HW4,
    NC1HWC0,
    UNKNOWN,
    // ...
}
```

**Tensor张量的定义：** 定义了一个名为Tensor的数据结构，用于表示张量（Tensor）的一些属性，如形状（shape）、数据排布格式（dataFormat）和数据类型（dataType）等。

```
// 定义 Tensor
table Tensor {
    // shape
    dims: [int];
    dataFormat: DATA_FORMAT;

    // data type
    dataType: DataType = DT_FLOAT;

    // extra
    // ...
}
```

### 推理引擎计算图：Operator算子的表示

算子的定义与张量不同，因为要对接到不同的AI框架，同一个算子在不同AI框架里的定义可能不同。所以在推理引擎中，对每一个算子都要有独立的定义。

**算子列表：** 算子是构成神经网络计算图的基本单元，每个算子代表了一种特定的计算操作，如卷积、池化、全连接等。算子数量建议控制在200-300个之间，基本上能够覆盖到95%的场景。Pytorch中有1200多个算子，TensorFlow中有1500多个算子，但推理引擎有时可能不需要这么多算子。每个算子实现时，可能有好几个kernel，这会影响推理引擎的大小。

```
// 算子列表
enum OpType : int {
    Const,
    Concat,
    Convolution,
    ConvolutionDepthwise,
    Deconvolution,
    DeconvolutionDepthwise,
    MatMul,
    // ...
}
```

**算子公共属性和特殊算子列表：** 不同的算子可能需要不同的属性和参数来进行操作，通过使用联合体的方式，可以在统一的数据结构中存储这些信息，并根据具体的算子类型来选择使用合适的成员。

```
// 算子公共属性和参数
union OpParameter {
    Axis,
    shape,
    Size,
    WhileParam,
    IfParam,
    LoopParam,
    // ...
}
```

**算子的基础定义：** 每个Op对象包含了算子的输入输出索引、类型、参数和名称等信息，通过这些信息可以清晰地表示和描述算子的功能和作用。

```
// 算子基本定义
table Op {
    inputIndexes: [int];
    outputIndexes: [int];
    main: OpParameter;
    type: OpType;
    name: string;
    // ...
}
```

### 推理引擎计算图：计算图的表示

**定义网络模型：** 表示网络模型的定义，存储网络模型的以下信息：
- 网络模型名称
- 输入输出张量名称、
- 算子列表：告诉推理引擎应该先执行哪个算子，后执行哪个算子，算子和算子之间的关系。
- 子图信息：如果有子图，就调用下面对子图的定义。

```
// 网络模型定义
table Net {
    name: string;
    inputName: [string];
    outputName: [string];
    oplists: [Op];
    sourceType: NetSource;

    // Subgraphs of the Net.
    subgraphs: [SubGraph];
    // ...
}
```

对于一些分类的网络，可能没有子图。但在具体实现过程中，遇到if-else、while或者for等语句时，就会拆分成子图。

**定义网络模型子图：** 表示子图的概念，并存储子图的输入输出信息、张量名称和节点信息。子图的定义与上面的网络模型定义是相似的，但子图的信息相较于整个图更少。

```
// 子图概念的定义
table SubGraph {
    // Subgraph unique name.
    name: string;
    inputs: [int];
    outputs: [int];

    // All tensor names.
    tensors: [string];

    // Nodes of the subgraph.
    nodes: [Op];
}
```

### 推理引擎计算图：自定义神经网络示例

下面使用FlatBuffers定义一个简单的神经网络结构，其中包含了卷积层和池化层操作：

```
namespace MyNet;
 ​
 table Pool {
     padX:int;
     padY:int;
     // ...
 }
 table Conv {
     kernelX:int = 1;
     kernelY:int = 1;
     // ...
 }
 union OpParameter {
     Conv,
     Pool,
 }
 enum OpType : int {
     Conv,
     Pool,
 }
 table Op {
     type: OpType;
     parameter: OpParameter;
     name: string;
     inputIndexes: [int];
     outputIndexes: [int];
 }
 table Net {
     oplists: [Op];
     tensorName: [string];
 }
 root_type Net;
```

声明了一个名为`MyNet`的命名空间，用于组织以下定义的数据结构：

- `table Pool { ... }`定义了一个名为Pool的表，表中包含了padX和padY两个整数字段，用于表示池化层的填充参数。
- `table Conv { ... }`定义了一个名为Conv的表，表中包含了kernelX和kernelY两个整数字段，用于表示卷积层的卷积核尺寸。
- `union OpParameter { ... }`定义了一个联合体（union），包含了Conv和Pool两种类型。
- `enum OpType : int { ... }`定义了一个枚举类型OpType，包含了Conv和Pool两种算子类型。
- `table Op { ... }`是算子的基础定义，包含了type字段，用于表示算子类型（属于Conv还是Pool），parameter字段，用于表示算子的参数，name字段表示算子的名称，inputIndexes和outputIndexes分别表示算子的输入和输出索引。
- `table Net { ... }`定义了网络模型，包含oplits字段，表示网络中的算子列表，tensorName字段表示张量的名称。
- `root_type Net`将Net表声明为根类型，表示FlatBuffers序列化和反序列化时的入口点。

## 总结

计算图是深度学习模型的一种抽象表达方式，通过图形结构来描述模型中各个操作之间的关系以及数据的流动路径。自定义计算图为推理引擎提供了优化和定制化的机会，使得模型转换和推理能够根据特定需求和场景进行高效执行。然而，现有推理IR存在一些局限性，例如ONNX引入过多的胶水算子，这些额外的算子是为了解决不同框架之间的不兼容性而引入的。另外，现有IR通常是开放的，不利于模型的加密和商业化。因此，自定义计算图成为必要的选择，可以更灵活地满足模型转换和推理的需求。

## 参考文章

1. [深入浅出：AI框架与计算图的关系](https://developer.baidu.com/article/details/3129186)
2. [4.1. 计算图的设计背景和作用](https://openmlsys.github.io/chapter_computational_graph/background_and_functionality.html#id1)
3. [【AI】推理系统和推理引擎的整体架构](https://blog.csdn.net/weixin_45651194/article/details/132872588)
4. [谈谈深度学习框架的数据排布](https://zhuanlan.zhihu.com/p/149464086)
5. [从零构建AI推理引擎系列](https://github.com/lucasjinreal/AI-Infer-Engine-From-Zero)
6. [一篇就够：高性能推理引擎理论与实践 (TensorRT)](https://developer.aliyun.com/article/995926)
7. [序列化之FlatBuffers](https://harmonyhu.com/2018/08/11/flatbuffers/)

## 本节视频

<html>
<iframe src="https://www.bilibili.com/video/BV1rx4y177R9/?vd_source=57ec244afa109ba4ee6346389a5f32f7" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</html>