1
00:00:00,000 --> 00:00:04,900
字幕生成：Galaxies     字幕校对：NaHS

2
00:00:04,900 --> 00:00:06,520
Hello 大家好我是 ZOMI

3
00:00:06,520 --> 00:00:09,720
在这一节课里面其实我已经 NG 了非常多遍

4
00:00:09,720 --> 00:00:11,600
才有今天这个视频

5
00:00:11,600 --> 00:00:13,960
现在还是来到卷积的优化

6
00:00:13,960 --> 00:00:17,800
看一下整体在推进期里面其实介绍了很多内容

7
00:00:17,800 --> 00:00:20,480
而现在集中在 Kernels 的优化

8
00:00:20,480 --> 00:00:24,520
而 Kernels 的优化更多的算法优化是最内核的

9
00:00:24,520 --> 00:00:27,440
而算法的优化终于来到一个很核心的概念

10
00:00:27,440 --> 00:00:29,560
就是 winograd 这个内容

11
00:00:29,600 --> 00:00:34,240
而现在所有的工作都沉淀在 Kernel 层里面

12
00:00:34,240 --> 00:00:38,440
可以看到了其实在上一节课或者上两节内容里面

13
00:00:38,440 --> 00:00:40,640
简单的去介绍一个卷积的概念

14
00:00:40,640 --> 00:00:43,840
什幺是 Img2Col 还有空间组合的优化

15
00:00:43,840 --> 00:00:49,720
在这一节里面重点的去看看 winograd 这个算法的优化

16
00:00:49,720 --> 00:00:52,120
这个算法叫做 winograd

17
00:00:52,120 --> 00:00:55,520
它不是 Grid 它不是球岛的缩写

18
00:00:55,520 --> 00:00:57,880
因为这个算法是 winograd

19
00:00:57,880 --> 00:00:59,480
这个人他是个人名

20
00:00:59,480 --> 00:01:02,760
最早在 1980 年的时候已经发表了这篇文章

21
00:01:02,760 --> 00:01:05,320
但是当时并没有引起太多的轰动了

22
00:01:05,320 --> 00:01:08,640
因为那个时候卷积的计算还不是没有现在这幺火

23
00:01:08,640 --> 00:01:11,440
而且计算量也没有今天这幺复杂

24
00:01:11,440 --> 00:01:15,280
到了 CVPR 2016 年又有人基于 winograd 这个算法

25
00:01:15,280 --> 00:01:18,760
重新的提出了一篇新的文章

26
00:01:18,760 --> 00:01:23,600
这个算法迅速的在整个算法的圈里面火起来

27
00:01:23,600 --> 00:01:27,440
现在有很多推理引擎都会去实现 winograd 这个算法

28
00:01:27,440 --> 00:01:28,960
包括 Mindspore Lite 了

29
00:01:28,960 --> 00:01:32,240
MMN 这些很多推理引擎都会去实现的

30
00:01:32,240 --> 00:01:37,760
里面最内核的一个原理就是使用把很多大量的矩阵乘

31
00:01:37,760 --> 00:01:41,600
或者大量的单点的乘法变成加法的操作

32
00:01:41,600 --> 00:01:43,280
或者减少乘法的操作

33
00:01:43,280 --> 00:01:46,360
那下面看一下具体的一个算法的原理

34
00:01:46,360 --> 00:01:48,400
算法原理我会很快的过掉

35
00:01:48,400 --> 00:01:52,000
然后更多的是希望跟大家去看看工程的实现部分

36
00:01:52,000 --> 00:01:55,120
首先现在有一个输入的信号是 FF

37
00:01:55,120 --> 00:01:56,480
有很多的数据

38
00:01:56,520 --> 00:01:59,760
然后现在有个卷积和卷积的最小的计算

39
00:01:59,760 --> 00:02:02,240
那肯定会有卷积核 G0 G1 G2

40
00:02:02,240 --> 00:02:06,200
那整个卷积的计算把它换成一个 Img2Col 的方式

41
00:02:06,200 --> 00:02:08,280
就变成两个矩阵相乘

42
00:02:08,280 --> 00:02:13,840
于是有 D0 D1 D2 乘以 G1 G2 G3 就变成 R0

43
00:02:13,840 --> 00:02:15,840
然后接着有 D1 D2 D3

44
00:02:15,840 --> 00:02:19,680
再同样的乘以 G0 G1 G2 就得到 R1

45
00:02:19,680 --> 00:02:23,760
这个就是卷积 Img2Col 的计算方式

46
00:02:24,240 --> 00:02:27,000
实际的计算操作 R0 就等于这条公式

47
00:02:27,000 --> 00:02:28,040
R1 等于这条公式

48
00:02:28,040 --> 00:02:32,480
里面的很内核的就是用了三次的乘法两次的加法

49
00:02:32,480 --> 00:02:35,680
一共就用了六次的乘法四次的加法

50
00:02:35,680 --> 00:02:39,560
数据量这幺少就已经用了非常多的乘加的操作

51
00:02:39,560 --> 00:02:41,040
于是 Winograd 这个算法

52
00:02:41,040 --> 00:02:46,600
确实希望能够极大的去减少乘法的操作

53
00:02:46,600 --> 00:02:49,480
因为这里面有很多元素都是相同的

54
00:02:49,480 --> 00:02:52,400
相同的元素能不能提前算出来

55
00:02:52,440 --> 00:02:54,160
不要每次都算一遍了

56
00:02:54,160 --> 00:02:57,360
据这个思想 Winograd 就证明了

57
00:02:57,360 --> 00:02:58,840
有几条公式

58
00:02:58,840 --> 00:03:00,960
首先刚才的那个矩阵乘

59
00:03:00,960 --> 00:03:07,040
实际上是可以等于 M1 M2 M3 M2-M3-M4

60
00:03:07,040 --> 00:03:09,440
那这些 M1 M2 M3 M4

61
00:03:09,440 --> 00:03:12,640
他们希望能够提前算出来的

62
00:03:12,640 --> 00:03:15,600
像这两个就先提前算出来

63
00:03:15,600 --> 00:03:17,920
另外一些就可以大量的复用

64
00:03:17,920 --> 00:03:20,560
就大量的复用里面的操作

65
00:03:20,560 --> 00:03:23,080
和里面已经算好的数据

66
00:03:23,080 --> 00:03:26,640
所以说整个算法或者整个卷迹的操作

67
00:03:26,640 --> 00:03:32,920
就变成 R0 R1 等加于上面的这条公式

68
00:03:32,920 --> 00:03:36,200
下面简单的去根据这条公式

69
00:03:36,200 --> 00:03:39,680
反向的推导它的一个成立的方式

70
00:03:41,080 --> 00:03:43,600
下面看一下 Winograd 的原理推导

71
00:03:43,600 --> 00:03:46,360
现在有刚才有那条公式

72
00:03:46,360 --> 00:03:50,800
所以现在 M1+M2+M3=R0，M2-M3-M4=R1

73
00:03:50,800 --> 00:03:52,680
等于 R0 下面等于 R1

74
00:03:52,680 --> 00:03:56,680
现在我令 M1 和 M4 等于下面两条

75
00:03:56,680 --> 00:03:59,520
于是下面就可以约掉 M1 和 M4

76
00:03:59,520 --> 00:04:03,240
于是重新得到了下面的一个新的公式

77
00:04:03,240 --> 00:04:04,520
约掉还不够

78
00:04:04,520 --> 00:04:05,840
现在观察 M2

79
00:04:05,840 --> 00:04:08,640
实际上它里面包含非常多的数据

80
00:04:08,640 --> 00:04:11,320
先把这里面的数据重新的减少

81
00:04:11,320 --> 00:04:13,400
将其转换成为多项式

82
00:04:13,400 --> 00:04:15,000
然后进行一个拆分

83
00:04:15,040 --> 00:04:17,920
于是重新的得到 M2 的公式

84
00:04:17,920 --> 00:04:20,800
同理对 M3 也进行如上的操作

85
00:04:20,800 --> 00:04:23,840
于是重新得到 M1 M2 M3

86
00:04:23,840 --> 00:04:26,800
这个时候实际上有两条公式

87
00:04:26,800 --> 00:04:28,120
就还是那条公式

88
00:04:28,120 --> 00:04:31,160
在 M2 和 M3 同时加上一个值

89
00:04:31,160 --> 00:04:33,080
其实 B 公式是不变的

90
00:04:33,080 --> 00:04:36,920
但是 A 公式需要给 M1 减去两倍的值

91
00:04:36,920 --> 00:04:38,400
那这个加上这个值

92
00:04:38,400 --> 00:04:39,520
这个值是什幺呢

93
00:04:39,520 --> 00:04:41,320
是下面的这条公式

94
00:04:41,320 --> 00:04:44,080
可以同时进行转换和约减

95
00:04:44,120 --> 00:04:47,280
那这个时候 M1 M2 M3 重新的计算

96
00:04:47,280 --> 00:04:48,920
就等于下面这条公式

97
00:04:48,920 --> 00:04:52,560
但是假设给 M2 同时也加上一个值

98
00:04:52,560 --> 00:04:54,440
给 M3 减去一个值

99
00:04:54,440 --> 00:04:56,880
这个值还是变成另外一条公式

100
00:04:56,880 --> 00:04:59,680
这个时候就可以重新的去计算

101
00:04:59,680 --> 00:05:02,160
整体的 M1 M2 M3 M4

102
00:05:02,160 --> 00:05:04,880
就有了一种新的计算的公式

103
00:05:04,880 --> 00:05:07,760
而下面这一个也是像刚才所说的

104
00:05:07,760 --> 00:05:10,840
它可以提前算好算出来

105
00:05:10,840 --> 00:05:13,920
而整个矩阵层就没有那幺复杂了

106
00:05:13,920 --> 00:05:15,280
通过 M1 M2 M3

107
00:05:15,280 --> 00:05:18,080
就可以极大的减少了计算

108
00:05:18,080 --> 00:05:20,440
当然了这里听不懂没有关系

109
00:05:20,440 --> 00:05:22,480
还是回到重点

110
00:05:22,480 --> 00:05:24,920
就是工程的实现

111
00:05:24,920 --> 00:05:27,320
那具体的算法原理为什幺这幺推导

112
00:05:27,320 --> 00:05:31,000
其实很多人或者在 kernel 的算法优化工程师里面

113
00:05:31,000 --> 00:05:33,440
不知道也不影响后续的工作

114
00:05:33,440 --> 00:05:36,040
大家只需要知道确实有这种算法

115
00:05:36,040 --> 00:05:38,280
能够很好的加快工作就行了

116
00:05:38,280 --> 00:05:40,200
加快 kernel 的计算

117
00:05:40,200 --> 00:05:42,680
下面把刚才的那条公式

118
00:05:42,720 --> 00:05:44,120
就 y 就是输出

119
00:05:44,280 --> 00:05:46,240
 g 有一个卷积核

120
00:05:46,240 --> 00:05:47,760
d 就是 feature map

121
00:05:47,760 --> 00:05:52,720
而小 g 就是一个卷积核的变换矩阵

122
00:05:52,720 --> 00:05:57,240
大 b 就是输入的数据的变换矩阵

123
00:05:57,240 --> 00:06:00,280
而 at 就是输出的数据的变换矩阵

124
00:06:00,280 --> 00:06:02,200
把刚才的那条计算公式

125
00:06:02,200 --> 00:06:03,480
就 Winograd 的这个算法

126
00:06:03,480 --> 00:06:05,920
转换成为具体的矩阵层

127
00:06:05,920 --> 00:06:11,320
而这里面三个参数其实都可以提前算出来的

128
00:06:11,320 --> 00:06:12,320
提前算出来之后

129
00:06:12,440 --> 00:06:13,760
只需要放在内存里面

130
00:06:13,760 --> 00:06:14,840
让它去读

131
00:06:14,840 --> 00:06:17,560
之后就会把 feature map 和权重

132
00:06:17,560 --> 00:06:19,240
进行一个简单的矩阵乘

133
00:06:19,440 --> 00:06:22,680
就可以得到最终的卷积核的输出

134
00:06:22,920 --> 00:06:24,840
这个就是最简单的原理

135
00:06:24,840 --> 00:06:27,680
同样放在二维里面也是成立的

136
00:06:27,680 --> 00:06:29,320
只不过二维的计算公式

137
00:06:29,680 --> 00:06:32,760
可能会稍微更加复杂一点点

138
00:06:32,760 --> 00:06:36,080
下面来看看整体的一个

139
00:06:36,080 --> 00:06:37,600
Img2Col 的展开的方式

140
00:06:37,600 --> 00:06:38,640
是下面这一条

141
00:06:38,640 --> 00:06:40,560
把所有的输入的 feature map

142
00:06:40,640 --> 00:06:42,000
进行一个重排

143
00:06:42,320 --> 00:06:44,360
另外一方面对 kernels 的数据

144
00:06:44,520 --> 00:06:45,520
进行重排

145
00:06:45,520 --> 00:06:46,920
得到新的数据

146
00:06:46,920 --> 00:06:49,440
有人就会想问了

147
00:06:49,440 --> 00:06:51,800
或者小新就可能会跳出来问了

148
00:06:51,800 --> 00:06:54,080
这个跟 Winograd 有什幺区别呢

149
00:06:54,080 --> 00:06:56,520
这不就 Img2Col 的计算方式吗

150
00:06:56,520 --> 00:06:57,520
很有意思的

151
00:06:57,520 --> 00:07:00,160
看一看下面这条内容

152
00:07:00,160 --> 00:07:01,120
这里面可以看到

153
00:07:01,360 --> 00:07:02,440
基本上就变成

154
00:07:02,440 --> 00:07:04,360
winograd 的计算方式了

155
00:07:04,760 --> 00:07:06,560
而 m1+m2+m3

156
00:07:06,560 --> 00:07:08,240
m2-m3-m4

157
00:07:09,040 --> 00:07:10,440
这条公式的计算

158
00:07:10,680 --> 00:07:15,160
就是对应于刚才的 m1-m2-m3-m4

159
00:07:15,160 --> 00:07:16,640
四个数的计算了

160
00:07:17,680 --> 00:07:18,960
下面看一下

161
00:07:18,960 --> 00:07:21,480
具体 winograd 的工程实现

162
00:07:21,480 --> 00:07:22,880
大家听不懂也没有关系

163
00:07:22,880 --> 00:07:26,680
后面我会把这些都整理成一个文档

164
00:07:26,680 --> 00:07:28,680
然后方便大家去取阅

165
00:07:28,680 --> 00:07:30,440
下面重新的看一下

166
00:07:30,440 --> 00:07:31,440
整体的工程实现

167
00:07:31,440 --> 00:07:33,320
工程实现主要分开四个步骤

168
00:07:33,320 --> 00:07:36,000
往下面这个图看一看

169
00:07:36,000 --> 00:07:39,640
首先会对输入的卷积和

170
00:07:39,640 --> 00:07:40,680
进行一个变换

171
00:07:40,680 --> 00:07:42,600
变换就是 U

172
00:07:42,600 --> 00:07:45,280
U = G*g*GT

173
00:07:45,800 --> 00:07:46,960
接着第二步

174
00:07:46,960 --> 00:07:50,600
就是对输入的数据进行变换

175
00:07:50,600 --> 00:07:51,800
得到 V

176
00:07:51,800 --> 00:07:53,400
V = BT* D* B

177
00:07:53,400 --> 00:07:54,720
输入的 feature map

178
00:07:55,080 --> 00:07:56,440
然后再乘以 B

179
00:07:56,440 --> 00:07:59,520
第三步就是对 m 矩阵

180
00:07:59,520 --> 00:08:00,480
进行计算

181
00:08:00,480 --> 00:08:02,400
就 winograd 具体的算法

182
00:08:02,400 --> 00:08:06,560
把 V 和 U 两个矩阵进行相乘

183
00:08:06,560 --> 00:08:09,440
最后一步就是计算输出的结果

184
00:08:09,560 --> 00:08:11,120
乘以 AT

185
00:08:11,120 --> 00:08:14,680
看上去好像还是挺简单的

186
00:08:14,680 --> 00:08:15,520
并不复杂

187
00:08:15,520 --> 00:08:18,360
而且这里面的 G B 和 A

188
00:08:18,600 --> 00:08:21,000
都是提前算出来的

189
00:08:21,000 --> 00:08:22,040
至于怎幺算出来

190
00:08:22,200 --> 00:08:23,680
就是根据我刚才推导的公式

191
00:08:23,680 --> 00:08:24,680
来去算出来的

192
00:08:24,680 --> 00:08:26,360
现在看一下

193
00:08:26,360 --> 00:08:28,360
具体的实现的步骤

194
00:08:28,360 --> 00:08:29,240
刚才说第一步

195
00:08:29,440 --> 00:08:32,080
是首先算 G 和 GT

196
00:08:32,080 --> 00:08:33,360
那这个 GT 怎幺来的

197
00:08:33,360 --> 00:08:35,360
就是真的是通过公式推导的

198
00:08:35,360 --> 00:08:36,520
通过公式推导之前

199
00:08:36,840 --> 00:08:39,320
提前算好这个 G

200
00:08:39,400 --> 00:08:40,160
而这个大 G

201
00:08:40,280 --> 00:08:41,920
确实有一条公式可以算

202
00:08:41,920 --> 00:08:43,640
现在也有一个 GitHub 的网站

203
00:08:43,640 --> 00:08:45,120
可以给大家去算出来

204
00:08:46,240 --> 00:08:48,080
大家打开 GitHub 的网站

205
00:08:48,240 --> 00:08:50,040
就可以把刚才的

206
00:08:50,040 --> 00:08:53,280
winograd 的 CNN 的一些权重

207
00:08:53,440 --> 00:08:55,000
提前的算出来

208
00:08:55,000 --> 00:08:56,920
我这边就不带着大家一起去算了

209
00:08:56,920 --> 00:08:58,160
大家可以去用一下

210
00:08:58,160 --> 00:08:59,680
这边就可以看到 A T

211
00:08:59,680 --> 00:09:01,080
它提前给算出来

212
00:09:01,080 --> 00:09:02,280
B 也给算出来

213
00:09:02,280 --> 00:09:03,840
G 也给算出来了

214
00:09:03,840 --> 00:09:05,320
所以还是挺有意思的

215
00:09:05,520 --> 00:09:06,840
现在重新的回到

216
00:09:06,840 --> 00:09:08,760
 slide ppt 里面

217
00:09:08,880 --> 00:09:11,640
假设 G 已经提前算出来了

218
00:09:11,640 --> 00:09:13,320
现在需要通过

219
00:09:13,320 --> 00:09:14,520
winograd 这个变换

220
00:09:14,920 --> 00:09:16,200
把 G 和 G T

221
00:09:16,680 --> 00:09:18,200
把三乘三的权重

222
00:09:18,440 --> 00:09:21,200
转换成为四乘四的矩阵

223
00:09:21,480 --> 00:09:24,680
下面首先第一步是对权重进行转换

224
00:09:24,960 --> 00:09:25,880
权重进行转换

225
00:09:26,200 --> 00:09:27,240
前面有个大 G

226
00:09:27,240 --> 00:09:28,080
后面有个大 G

227
00:09:28,080 --> 00:09:29,680
就把权重的数据

228
00:09:29,920 --> 00:09:32,760
转换成为一个四乘四的矩阵

229
00:09:32,760 --> 00:09:33,800
而这里面 IC

230
00:09:33,800 --> 00:09:35,560
就是 channels 的大小

231
00:09:35,560 --> 00:09:38,120
然后把这个张量里面相同位置的点

232
00:09:38,120 --> 00:09:39,840
假设现在以蓝色为例

233
00:09:39,840 --> 00:09:44,120
转换成为一个 IC 乘以 OC 的矩阵

234
00:09:44,360 --> 00:09:45,320
这里面是蓝色

235
00:09:45,320 --> 00:09:47,600
把它全部都重排

236
00:09:47,880 --> 00:09:49,600
展开成为这幺一列

237
00:09:49,600 --> 00:09:50,800
OC 乘以 IC

238
00:09:50,800 --> 00:09:52,080
四乘四乘以 16

239
00:09:52,080 --> 00:09:54,760
这幺一个具体的矩阵

240
00:09:54,760 --> 00:09:56,440
那转换成为这个矩阵

241
00:09:56,600 --> 00:09:58,520
只是为了后面的矩阵层

242
00:09:58,520 --> 00:09:59,760
方便去运算

243
00:10:00,080 --> 00:10:02,160
第二个步骤是对 feature map

244
00:10:02,160 --> 00:10:04,520
就输入的数据进行转换

245
00:10:04,520 --> 00:10:05,560
同样这个数据

246
00:10:05,720 --> 00:10:07,840
有一个大 B 还有个 B T

247
00:10:08,000 --> 00:10:09,880
进行一个具体的相乘之后

248
00:10:10,120 --> 00:10:12,640
就会对它进行重新的转换

249
00:10:12,640 --> 00:10:15,320
成为另外一个张量的形式

250
00:10:15,320 --> 00:10:17,720
同样的对张量的形式

251
00:10:18,080 --> 00:10:20,360
进行一个数据的重排

252
00:10:20,360 --> 00:10:21,680
这边有一个 relayout

253
00:10:21,680 --> 00:10:24,040
就是确实需要进行数据的重排

254
00:10:24,040 --> 00:10:24,920
重排完之后

255
00:10:25,120 --> 00:10:27,880
同样这里面是四乘四乘以 16

256
00:10:27,880 --> 00:10:29,120
的这种方式

257
00:10:29,120 --> 00:10:31,320
下面假设 A 就是 feature map 的输入

258
00:10:31,320 --> 00:10:32,880
B 就是权重

259
00:10:33,120 --> 00:10:35,600
这两个矩阵进行一个相乘之后

260
00:10:35,760 --> 00:10:37,720
就得到一个新的矩阵

261
00:10:37,720 --> 00:10:39,960
新的矩阵确实也需要进行一个

262
00:10:39,960 --> 00:10:40,720
relayout

263
00:10:40,720 --> 00:10:43,200
relayout 就是数据的重排

264
00:10:43,200 --> 00:10:44,200
数据重排之后

265
00:10:44,360 --> 00:10:46,880
就得到最终的接近最终的结果

266
00:10:46,880 --> 00:10:47,800
最终结果之前

267
00:10:48,200 --> 00:10:49,480
A 也是提前算出来

268
00:10:49,480 --> 00:10:51,840
对它进行一个转换

269
00:10:51,840 --> 00:10:53,360
或者一个相乘

270
00:10:53,360 --> 00:10:55,320
得到新的数据的方式

271
00:10:55,320 --> 00:10:56,240
新的数据方式

272
00:10:56,560 --> 00:10:57,880
对它进行 rewrite

273
00:10:57,880 --> 00:10:59,280
write 成 output

274
00:10:59,280 --> 00:11:02,040
这个就是卷积的最终的输出了

275
00:11:02,040 --> 00:11:03,000
整体这个流程

276
00:11:03,200 --> 00:11:05,480
就是 winograd 的算法了

277
00:11:05,680 --> 00:11:09,160
下面简单的对 winograd 这个算法

278
00:11:09,160 --> 00:11:11,280
进行一个回顾和思考

279
00:11:12,000 --> 00:11:14,040
虽然从原理看上去

280
00:11:14,360 --> 00:11:15,640
乘法减少了

281
00:11:15,640 --> 00:11:18,920
但好像算法的复杂度上升了

282
00:11:19,200 --> 00:11:22,920
下面看一下它整体的一个约束和缺点

283
00:11:22,920 --> 00:11:24,120
就是它的一些问题

284
00:11:24,640 --> 00:11:26,360
第一个点就是 winograd 这个算法

285
00:11:26,880 --> 00:11:29,680
非常不推荐在一些非常小的卷积核

286
00:11:29,680 --> 00:11:32,640
或者一些非常小的一些卷积的方法里面去用的

287
00:11:32,640 --> 00:11:33,800
因为可以看到

288
00:11:33,800 --> 00:11:36,320
有大量的辅助的矩阵

289
00:11:36,320 --> 00:11:38,200
就刚才的 GBA

290
00:11:38,200 --> 00:11:40,000
这些辅助矩阵是非常大的

291
00:11:40,000 --> 00:11:41,680
会影响实际的效果

292
00:11:42,040 --> 00:11:44,400
第二点就是不同规模的卷积

293
00:11:44,400 --> 00:11:47,400
需要使用不同规模的辅助矩阵

294
00:11:47,640 --> 00:11:51,280
实际上实时计算这些辅助矩阵是不现实的

295
00:11:51,280 --> 00:11:53,160
所以都会把它存起来

296
00:11:53,160 --> 00:11:54,080
而预存起来

297
00:11:54,200 --> 00:11:56,280
有可能会导致存储

298
00:11:56,280 --> 00:11:58,880
或者程序爆炸

299
00:11:59,240 --> 00:12:00,400
虽然 winograd 这个算法

300
00:12:00,560 --> 00:12:02,080
减少了乘法的次数

301
00:12:02,080 --> 00:12:05,040
但是加法的数量也会相对应的增加

302
00:12:05,040 --> 00:12:08,560
而且内存要存储辅助矩阵

303
00:12:08,560 --> 00:12:10,960
确实增加了内存

304
00:12:10,960 --> 00:12:13,520
而随着卷积核的分块的尺寸增加

305
00:12:13,520 --> 00:12:16,400
还要考虑更多的加法和转换的代价

306
00:12:16,400 --> 00:12:18,760
而且每个切分的块越大

307
00:12:18,760 --> 00:12:20,200
转换矩阵就越大

308
00:12:20,200 --> 00:12:22,880
整体的计算精度也会有所损失

309
00:12:22,880 --> 00:12:25,640
所以说 winograd 这个算法

310
00:12:26,280 --> 00:12:29,800
基本上只适用于一些比较小的卷积核和 TIE

311
00:12:30,600 --> 00:12:32,480
这个时候就很有意思了

312
00:12:32,480 --> 00:12:34,560
在实际的工程当中

313
00:12:34,560 --> 00:12:35,960
winograd 这个算法

314
00:12:35,960 --> 00:12:38,640
基本上只会对一些有限的

315
00:12:38,640 --> 00:12:41,400
3x3 的卷积进行一个运算

316
00:12:41,400 --> 00:12:43,280
1x1 的卷积不是用 winograd

317
00:12:43,280 --> 00:12:47,600
7x7 5x5 的卷积也不会启动 winograd 这个 kernel

318
00:12:47,600 --> 00:12:49,880
所以说还是很有意思的

319
00:12:49,880 --> 00:12:50,960
在 runtime 的时候

320
00:12:51,120 --> 00:12:54,760
就会去决定到底用哪个 kernel

321
00:12:55,160 --> 00:12:58,560
那下面在具体实现上面的约束

322
00:12:58,600 --> 00:13:00,000
其实也是有的

323
00:13:00,400 --> 00:13:01,920
在实际实践当中

324
00:13:02,040 --> 00:13:03,240
最普遍的算法

325
00:13:03,240 --> 00:13:05,320
就是希望能够提前算出来

326
00:13:05,320 --> 00:13:06,680
提前能够固定的数据

327
00:13:07,160 --> 00:13:08,760
就提前把它做好

328
00:13:08,760 --> 00:13:10,600
所以会有一个预编译的阶段

329
00:13:10,600 --> 00:13:12,760
或者离线模块转换的阶段

330
00:13:12,760 --> 00:13:15,920
就是为了把一些能算的提前算出来

331
00:13:15,920 --> 00:13:17,120
在推理引擎里面

332
00:13:17,240 --> 00:13:20,040
基本上不需要能够处理一些长尾的问题

333
00:13:20,040 --> 00:13:21,640
而是一些常用的

334
00:13:21,640 --> 00:13:23,680
或者一些很通用的算法问题

335
00:13:23,680 --> 00:13:25,640
或者一些通用的网络模型结构

336
00:13:25,640 --> 00:13:27,760
所以对于一些特定的网络模型结构

337
00:13:27,880 --> 00:13:29,120
假设 G 是固定的

338
00:13:29,120 --> 00:13:30,760
所以会把特定网络的 G

339
00:13:31,000 --> 00:13:34,000
直接把它提前的算出来

340
00:13:34,000 --> 00:13:34,720
算好之后

341
00:13:34,720 --> 00:13:36,080
下一次直接运算就行了

342
00:13:36,080 --> 00:13:39,640
就不需要每一次我都需要重新的计算

343
00:13:39,640 --> 00:13:41,240
另外一个很自然的想法

344
00:13:41,240 --> 00:13:42,760
就是像刚才所说的

345
00:13:42,760 --> 00:13:45,880
它利用了空间的组织的方式

346
00:13:45,880 --> 00:13:47,280
跟 Img2Col

347
00:13:47,280 --> 00:13:50,040
进行分片拆分

348
00:13:50,040 --> 00:13:51,520
将 input 的数据拆分成

349
00:13:51,520 --> 00:13:54,200
多个小规模的卷积

350
00:13:54,200 --> 00:13:56,200
这也是一个很好的优化方法

351
00:13:56,800 --> 00:13:59,160
好了,今天的内容就到这里为止

352
00:13:59,160 --> 00:14:00,200
今天主要是讲了

353
00:14:00,200 --> 00:14:03,440
winograd 怎幺去加速二维卷积的计算

354
00:14:03,440 --> 00:14:05,960
而这套公式就是 winograd 这个算法

355
00:14:05,960 --> 00:14:08,440
原来的论文推导出来的

356
00:14:08,440 --> 00:14:09,480
至于为什幺这幺推导

357
00:14:09,480 --> 00:14:11,920
在上面其实已经简单的介绍过

358
00:14:11,920 --> 00:14:13,480
可能我讲得不太清楚

359
00:14:13,480 --> 00:14:16,160
也希望欢迎大家去写更多的文章

360
00:14:16,160 --> 00:14:19,120
或者引发大家一个更好的一些思考

361
00:14:19,120 --> 00:14:21,120
今天的内容就先到这里为止

362
00:14:21,120 --> 00:14:22,640
谢谢各位,拜拜

363
00:14:22,640 --> 00:14:24,920
卷得不行了

364
00:14:24,960 --> 00:14:26,760
记得一键三连加关注哦

365
00:14:26,760 --> 00:14:28,360
所有的内容都会开源在

366
00:14:28,360 --> 00:14:30,360
下面这条链接里面

367
00:14:30,360 --> 00:14:31,600
拜拜

